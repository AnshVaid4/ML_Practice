{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e2614afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Dense, SimpleRNN, Dropout, LSTM, GRU\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c986c6df",
   "metadata": {},
   "source": [
    "# Text prediction using SimpleRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3045a9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus=\"\"\"\n",
    "[ nominal delivery draft, 6 August 2014 ]\n",
    "\n",
    "Cybersecurity as Realpolitik\n",
    "Dan Geer\n",
    "\n",
    "\n",
    "Good morning and thank you for the invitation to speak with you\n",
    "today.  The plaintext of this talk has been made available to the\n",
    "organizers.  While I will not be taking questions today, you are\n",
    "welcome to contact me later and I will do what I can to reply.  For\n",
    "simple clarity, let me repeat the abstract for this talk:\n",
    "\n",
    "   Power exists to be used.  Some wish for cyber safety, which they\n",
    "   will not get.  Others wish for cyber order, which they will not\n",
    "   get.  Some have the eye to discern cyber policies that are \"the\n",
    "   least worst thing;\" may they fill the vacuum of wishful thinking.\n",
    "\n",
    "There are three professions that beat their practitioners into a\n",
    "state of humility: farming, weather forecasting, and cyber security.\n",
    "I practice two of those, and, as such, let me assure you that the\n",
    "recommendations which follow are presented in all humility.  Humility\n",
    "does not mean timidity.  Rather, it means that when a strongly held\n",
    "belief is proven wrong, that the humble person changes their mind.\n",
    "I expect that my proposals will result in considerable push-back,\n",
    "and changing my mind may well follow.  Though I will say it again\n",
    "later, this speech is me talking for myself.\n",
    "\n",
    "As if it needed saying, cyber security is now a riveting concern,\n",
    "a top issue in many venues more important than this one.  This is\n",
    "not to insult Black Hat; rather it is to note that every speaker,\n",
    "every writer, every practitioner in the field of cyber security who\n",
    "has wished that its topic, and us with it, were taken seriously has\n",
    "gotten their wish.  Cyber security *is* being taken seriously,\n",
    "which, as you well know is not the same as being taken usefully,\n",
    "coherently, or lastingly.  Whether we are talking about laws like\n",
    "the Digital Millenium Copyright Act or the Computer Fraud and Abuse\n",
    "Act, or the non-lawmaking but perhaps even more significant actions\n",
    "that the Executive agencies are undertaking, \"we\" and the cyber\n",
    "security issue have never been more at the forefront of policy.\n",
    "And you ain't seen nothing yet.\n",
    "\n",
    "I wish that I could tell you that it is still possible for one\n",
    "person to hold the big picture firmly in their mind's eye, to track\n",
    "everything important that is going on in our field, to make few if\n",
    "any sins of omission.  It is not possible; that phase passed sometime\n",
    "in the last six years.  I have certainly tried to keep up but I\n",
    "would be less than candid if I were not to say that I know that I\n",
    "am not keeping up, not even keeping up with what is going on in my\n",
    "own country much less all countries.  Not only has cybersecurity\n",
    "reached the highest levels of attention, it has spread into nearly\n",
    "every corner.  If area is the product of height and width, then the\n",
    "footprint of cybersecurity has surpassed the grasp of any one of us.\n",
    "\n",
    "The rate of technological change is certainly a part of it.  When\n",
    "younger people ask my advice on what they should do or study to\n",
    "make a career in cyber security, I can only advise specialization.\n",
    "Those of us who were in the game early enough and who have managed\n",
    "to retain an over-arching generalist knowledge can't be replaced\n",
    "very easily because while absorbing most new information most of\n",
    "the time may have been possible when we began practice, no person\n",
    "starting from scratch can do that now.  Serial specialization is\n",
    "now all that can be done in any practical way.  Just looking at the\n",
    "Black Hat program will confirm that being really good at any one\n",
    "of the many topics presented here all but requires shutting out the\n",
    "demands of being good at any others.\n",
    "\n",
    "Why does that matter?  Speaking for myself, I am not interested in\n",
    "the advantages or disadvantages of some bit of technology unless I\n",
    "can grasp how it is that that technology works.  Whenever I see\n",
    "marketing material that tells me all the good things that adopting\n",
    "this or that technology makes possible, I remember what George\n",
    "Santayana said, that \"Scepticism is the chastity of the intellect;\n",
    "it is shameful to give it up too soon, or to the first comer.\" I\n",
    "suspect that a majority of you have similar skepticism -- \"It's\n",
    "magic!\" is not the answer a security person will ever accept.  By\n",
    "and large, I can tell *what* something is good for once I know *how*\n",
    "it works.  Tell me how it works and then, but only then, tell me\n",
    "why you have chosen to use those particular mechanisms for the\n",
    "things you have chosen to use them for.\n",
    "\n",
    "Part of my feeling stems from a long-held and well-substantiated\n",
    "belief that all cyber security technology is dual use.  Perhaps\n",
    "dual use is a truism for any and all tools from the scalpel to the\n",
    "hammer to the gas can -- they can be used for good or ill -- but I\n",
    "know that dual use is inherent in cyber security tools.  If your\n",
    "definition of \"tool\" is wide enough, I suggest that the cyber\n",
    "security tool-set favors offense these days.  Chris Inglis, recently\n",
    "retired NSA Deputy Director, remarked that if we were to score cyber\n",
    "the way we score soccer, the tally would be 462-456 twenty minutes\n",
    "into the game,[CI] i.e., all offense.  I will take his comment as\n",
    "confirming at the highest level not only the dual use nature of\n",
    "cybersecurity but also confirming that offense is where the innovations\n",
    "that only States can afford is going on.\n",
    "\n",
    "Nevertheless, this essay is an outgrowth from, an extension of,\n",
    "that increasing importance of cybersecurity.  With the humility of\n",
    "which I spoke, I do not claim that I have the last word.  What I\n",
    "do claim is that when we speak about cybersecurity policy we are\n",
    "no longer engaging in some sort of parlor game.  I claim that policy\n",
    "matters are now the most important matters, that once a topic area,\n",
    "like cybersecurity, becomes interlaced with nearly every aspect of\n",
    "life for nearly everybody, the outcome differential between good\n",
    "policies and bad policies broadens, and the ease of finding answers\n",
    "falls.  As H.L. Mencken so trenchantly put it, \"For every complex\n",
    "problem there is a solution that is clear, simple, and wrong.\"\n",
    "\n",
    "The four verities of government are these:\n",
    ". Most important ideas are unappealing\n",
    ". Most appealing ideas are unimportant\n",
    ". Not every problem has a good solution\n",
    ". Every solution has side effects\n",
    "\"\"\"\n",
    "corpus=corpus.replace('\\n',' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08f3e4f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' [ nominal delivery draft, 6 August 2014 ]  Cybersecurity as Realpolitik Dan Geer   Good morning and thank you for the invitation to speak with you today.',\n",
       " 'The plaintext of this talk has been made available to the organizers.',\n",
       " 'While I will not be taking questions today, you are welcome to contact me later and I will do what I can to reply.',\n",
       " 'For simple clarity, let me repeat the abstract for this talk:     Power exists to be used.',\n",
       " 'Some wish for cyber safety, which they    will not get.',\n",
       " 'Others wish for cyber order, which they will not    get.',\n",
       " 'Some have the eye to discern cyber policies that are \"the    least worst thing;\" may they fill the vacuum of wishful thinking.',\n",
       " 'There are three professions that beat their practitioners into a state of humility: farming, weather forecasting, and cyber security.',\n",
       " 'I practice two of those, and, as such, let me assure you that the recommendations which follow are presented in all humility.',\n",
       " 'Humility does not mean timidity.',\n",
       " 'Rather, it means that when a strongly held belief is proven wrong, that the humble person changes their mind.',\n",
       " 'I expect that my proposals will result in considerable push-back, and changing my mind may well follow.',\n",
       " 'Though I will say it again later, this speech is me talking for myself.',\n",
       " 'As if it needed saying, cyber security is now a riveting concern, a top issue in many venues more important than this one.',\n",
       " 'This is not to insult Black Hat; rather it is to note that every speaker, every writer, every practitioner in the field of cyber security who has wished that its topic, and us with it, were taken seriously has gotten their wish.',\n",
       " 'Cyber security *is* being taken seriously, which, as you well know is not the same as being taken usefully, coherently, or lastingly.',\n",
       " 'Whether we are talking about laws like the Digital Millenium Copyright Act or the Computer Fraud and Abuse Act, or the non-lawmaking but perhaps even more significant actions that the Executive agencies are undertaking, \"we\" and the cyber security issue have never been more at the forefront of policy.',\n",
       " \"And you ain't seen nothing yet.\",\n",
       " \"I wish that I could tell you that it is still possible for one person to hold the big picture firmly in their mind's eye, to track everything important that is going on in our field, to make few if any sins of omission.\",\n",
       " 'It is not possible; that phase passed sometime in the last six years.',\n",
       " 'I have certainly tried to keep up but I would be less than candid if I were not to say that I know that I am not keeping up, not even keeping up with what is going on in my own country much less all countries.',\n",
       " 'Not only has cybersecurity reached the highest levels of attention, it has spread into nearly every corner.',\n",
       " 'If area is the product of height and width, then the footprint of cybersecurity has surpassed the grasp of any one of us.',\n",
       " 'The rate of technological change is certainly a part of it.',\n",
       " 'When younger people ask my advice on what they should do or study to make a career in cyber security, I can only advise specialization.',\n",
       " \"Those of us who were in the game early enough and who have managed to retain an over-arching generalist knowledge can't be replaced very easily because while absorbing most new information most of the time may have been possible when we began practice, no person starting from scratch can do that now.\",\n",
       " 'Serial specialization is now all that can be done in any practical way.',\n",
       " 'Just looking at the Black Hat program will confirm that being really good at any one of the many topics presented here all but requires shutting out the demands of being good at any others.',\n",
       " 'Why does that matter?',\n",
       " 'Speaking for myself, I am not interested in the advantages or disadvantages of some bit of technology unless I can grasp how it is that that technology works.',\n",
       " 'Whenever I see marketing material that tells me all the good things that adopting this or that technology makes possible, I remember what George Santayana said, that \"Scepticism is the chastity of the intellect; it is shameful to give it up too soon, or to the first comer.\"',\n",
       " 'I suspect that a majority of you have similar skepticism -- \"It\\'s magic!\"',\n",
       " 'is not the answer a security person will ever accept.',\n",
       " 'By and large, I can tell *what* something is good for once I know *how* it works.',\n",
       " 'Tell me how it works and then, but only then, tell me why you have chosen to use those particular mechanisms for the things you have chosen to use them for.',\n",
       " 'Part of my feeling stems from a long-held and well-substantiated belief that all cyber security technology is dual use.',\n",
       " 'Perhaps dual use is a truism for any and all tools from the scalpel to the hammer to the gas can -- they can be used for good or ill -- but I know that dual use is inherent in cyber security tools.',\n",
       " 'If your definition of \"tool\" is wide enough, I suggest that the cyber security tool-set favors offense these days.',\n",
       " 'Chris Inglis, recently retired NSA Deputy Director, remarked that if we were to score cyber the way we score soccer, the tally would be 462-456 twenty minutes into the game,[CI] i.e., all offense.',\n",
       " 'I will take his comment as confirming at the highest level not only the dual use nature of cybersecurity but also confirming that offense is where the innovations that only States can afford is going on.',\n",
       " 'Nevertheless, this essay is an outgrowth from, an extension of, that increasing importance of cybersecurity.',\n",
       " 'With the humility of which I spoke, I do not claim that I have the last word.',\n",
       " 'What I do claim is that when we speak about cybersecurity policy we are no longer engaging in some sort of parlor game.',\n",
       " 'I claim that policy matters are now the most important matters, that once a topic area, like cybersecurity, becomes interlaced with nearly every aspect of life for nearly everybody, the outcome differential between good policies and bad policies broadens, and the ease of finding answers falls.',\n",
       " 'As H.L.',\n",
       " 'Mencken so trenchantly put it, \"For every complex problem there is a solution that is clear, simple, and wrong.\"',\n",
       " 'The four verities of government are these: .',\n",
       " 'Most important ideas are unappealing .',\n",
       " 'Most appealing ideas are unimportant .',\n",
       " 'Not every problem has a good solution .',\n",
       " 'Every solution has side effects']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "sentences=sent_tokenize(corpus)\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "619b6a64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(457,\n",
       " {'the': 1,\n",
       "  'that': 2,\n",
       "  'of': 3,\n",
       "  'i': 4,\n",
       "  'is': 5,\n",
       "  'to': 6,\n",
       "  'and': 7,\n",
       "  'not': 8,\n",
       "  'for': 9,\n",
       "  'it': 10,\n",
       "  'in': 11,\n",
       "  'cyber': 12,\n",
       "  'a': 13,\n",
       "  'are': 14,\n",
       "  'you': 15,\n",
       "  'security': 16,\n",
       "  'will': 17,\n",
       "  'can': 18,\n",
       "  'have': 19,\n",
       "  'good': 20,\n",
       "  'has': 21,\n",
       "  'all': 22,\n",
       "  'every': 23,\n",
       "  'or': 24,\n",
       "  'cybersecurity': 25,\n",
       "  'as': 26,\n",
       "  'this': 27,\n",
       "  'be': 28,\n",
       "  'me': 29,\n",
       "  'we': 30,\n",
       "  'what': 31,\n",
       "  'if': 32,\n",
       "  'but': 33,\n",
       "  'any': 34,\n",
       "  'use': 35,\n",
       "  'with': 36,\n",
       "  'do': 37,\n",
       "  'which': 38,\n",
       "  'they': 39,\n",
       "  'my': 40,\n",
       "  'at': 41,\n",
       "  'only': 42,\n",
       "  'most': 43,\n",
       "  'some': 44,\n",
       "  'wish': 45,\n",
       "  'their': 46,\n",
       "  'humility': 47,\n",
       "  'when': 48,\n",
       "  'person': 49,\n",
       "  'now': 50,\n",
       "  'important': 51,\n",
       "  'one': 52,\n",
       "  'were': 53,\n",
       "  'being': 54,\n",
       "  'know': 55,\n",
       "  'tell': 56,\n",
       "  'possible': 57,\n",
       "  'on': 58,\n",
       "  'up': 59,\n",
       "  'from': 60,\n",
       "  'technology': 61,\n",
       "  'dual': 62,\n",
       "  'been': 63,\n",
       "  'policies': 64,\n",
       "  'may': 65,\n",
       "  'into': 66,\n",
       "  'those': 67,\n",
       "  'well': 68,\n",
       "  'more': 69,\n",
       "  'who': 70,\n",
       "  'us': 71,\n",
       "  'taken': 72,\n",
       "  'policy': 73,\n",
       "  'going': 74,\n",
       "  'nearly': 75,\n",
       "  'then': 76,\n",
       "  'game': 77,\n",
       "  'an': 78,\n",
       "  'how': 79,\n",
       "  'works': 80,\n",
       "  'offense': 81,\n",
       "  'claim': 82,\n",
       "  'solution': 83,\n",
       "  'speak': 84,\n",
       "  'today': 85,\n",
       "  'talk': 86,\n",
       "  'while': 87,\n",
       "  'later': 88,\n",
       "  'simple': 89,\n",
       "  'let': 90,\n",
       "  'used': 91,\n",
       "  'get': 92,\n",
       "  'others': 93,\n",
       "  'eye': 94,\n",
       "  'there': 95,\n",
       "  'practice': 96,\n",
       "  'follow': 97,\n",
       "  'presented': 98,\n",
       "  'does': 99,\n",
       "  'rather': 100,\n",
       "  'held': 101,\n",
       "  'belief': 102,\n",
       "  'wrong': 103,\n",
       "  'mind': 104,\n",
       "  'say': 105,\n",
       "  'talking': 106,\n",
       "  'myself': 107,\n",
       "  'issue': 108,\n",
       "  'many': 109,\n",
       "  'than': 110,\n",
       "  'black': 111,\n",
       "  'hat': 112,\n",
       "  'field': 113,\n",
       "  'topic': 114,\n",
       "  'seriously': 115,\n",
       "  'about': 116,\n",
       "  'like': 117,\n",
       "  'act': 118,\n",
       "  'perhaps': 119,\n",
       "  'even': 120,\n",
       "  'make': 121,\n",
       "  'last': 122,\n",
       "  'certainly': 123,\n",
       "  'would': 124,\n",
       "  'less': 125,\n",
       "  'am': 126,\n",
       "  'keeping': 127,\n",
       "  'highest': 128,\n",
       "  'area': 129,\n",
       "  'grasp': 130,\n",
       "  'part': 131,\n",
       "  'specialization': 132,\n",
       "  'enough': 133,\n",
       "  'no': 134,\n",
       "  'way': 135,\n",
       "  'why': 136,\n",
       "  'things': 137,\n",
       "  'once': 138,\n",
       "  'chosen': 139,\n",
       "  'tools': 140,\n",
       "  'tool': 141,\n",
       "  'these': 142,\n",
       "  'score': 143,\n",
       "  'confirming': 144,\n",
       "  'matters': 145,\n",
       "  'problem': 146,\n",
       "  'ideas': 147,\n",
       "  'nominal': 148,\n",
       "  'delivery': 149,\n",
       "  'draft': 150,\n",
       "  '6': 151,\n",
       "  'august': 152,\n",
       "  '2014': 153,\n",
       "  'realpolitik': 154,\n",
       "  'dan': 155,\n",
       "  'geer': 156,\n",
       "  'morning': 157,\n",
       "  'thank': 158,\n",
       "  'invitation': 159,\n",
       "  'plaintext': 160,\n",
       "  'made': 161,\n",
       "  'available': 162,\n",
       "  'organizers': 163,\n",
       "  'taking': 164,\n",
       "  'questions': 165,\n",
       "  'welcome': 166,\n",
       "  'contact': 167,\n",
       "  'reply': 168,\n",
       "  'clarity': 169,\n",
       "  'repeat': 170,\n",
       "  'abstract': 171,\n",
       "  'power': 172,\n",
       "  'exists': 173,\n",
       "  'safety': 174,\n",
       "  'order': 175,\n",
       "  'discern': 176,\n",
       "  'least': 177,\n",
       "  'worst': 178,\n",
       "  'thing': 179,\n",
       "  'fill': 180,\n",
       "  'vacuum': 181,\n",
       "  'wishful': 182,\n",
       "  'thinking': 183,\n",
       "  'three': 184,\n",
       "  'professions': 185,\n",
       "  'beat': 186,\n",
       "  'practitioners': 187,\n",
       "  'state': 188,\n",
       "  'farming': 189,\n",
       "  'weather': 190,\n",
       "  'forecasting': 191,\n",
       "  'two': 192,\n",
       "  'such': 193,\n",
       "  'assure': 194,\n",
       "  'recommendations': 195,\n",
       "  'mean': 196,\n",
       "  'timidity': 197,\n",
       "  'means': 198,\n",
       "  'strongly': 199,\n",
       "  'proven': 200,\n",
       "  'humble': 201,\n",
       "  'changes': 202,\n",
       "  'expect': 203,\n",
       "  'proposals': 204,\n",
       "  'result': 205,\n",
       "  'considerable': 206,\n",
       "  'push': 207,\n",
       "  'back': 208,\n",
       "  'changing': 209,\n",
       "  'though': 210,\n",
       "  'again': 211,\n",
       "  'speech': 212,\n",
       "  'needed': 213,\n",
       "  'saying': 214,\n",
       "  'riveting': 215,\n",
       "  'concern': 216,\n",
       "  'top': 217,\n",
       "  'venues': 218,\n",
       "  'insult': 219,\n",
       "  'note': 220,\n",
       "  'speaker': 221,\n",
       "  'writer': 222,\n",
       "  'practitioner': 223,\n",
       "  'wished': 224,\n",
       "  'its': 225,\n",
       "  'gotten': 226,\n",
       "  'same': 227,\n",
       "  'usefully': 228,\n",
       "  'coherently': 229,\n",
       "  'lastingly': 230,\n",
       "  'whether': 231,\n",
       "  'laws': 232,\n",
       "  'digital': 233,\n",
       "  'millenium': 234,\n",
       "  'copyright': 235,\n",
       "  'computer': 236,\n",
       "  'fraud': 237,\n",
       "  'abuse': 238,\n",
       "  'non': 239,\n",
       "  'lawmaking': 240,\n",
       "  'significant': 241,\n",
       "  'actions': 242,\n",
       "  'executive': 243,\n",
       "  'agencies': 244,\n",
       "  'undertaking': 245,\n",
       "  'never': 246,\n",
       "  'forefront': 247,\n",
       "  \"ain't\": 248,\n",
       "  'seen': 249,\n",
       "  'nothing': 250,\n",
       "  'yet': 251,\n",
       "  'could': 252,\n",
       "  'still': 253,\n",
       "  'hold': 254,\n",
       "  'big': 255,\n",
       "  'picture': 256,\n",
       "  'firmly': 257,\n",
       "  \"mind's\": 258,\n",
       "  'track': 259,\n",
       "  'everything': 260,\n",
       "  'our': 261,\n",
       "  'few': 262,\n",
       "  'sins': 263,\n",
       "  'omission': 264,\n",
       "  'phase': 265,\n",
       "  'passed': 266,\n",
       "  'sometime': 267,\n",
       "  'six': 268,\n",
       "  'years': 269,\n",
       "  'tried': 270,\n",
       "  'keep': 271,\n",
       "  'candid': 272,\n",
       "  'own': 273,\n",
       "  'country': 274,\n",
       "  'much': 275,\n",
       "  'countries': 276,\n",
       "  'reached': 277,\n",
       "  'levels': 278,\n",
       "  'attention': 279,\n",
       "  'spread': 280,\n",
       "  'corner': 281,\n",
       "  'product': 282,\n",
       "  'height': 283,\n",
       "  'width': 284,\n",
       "  'footprint': 285,\n",
       "  'surpassed': 286,\n",
       "  'rate': 287,\n",
       "  'technological': 288,\n",
       "  'change': 289,\n",
       "  'younger': 290,\n",
       "  'people': 291,\n",
       "  'ask': 292,\n",
       "  'advice': 293,\n",
       "  'should': 294,\n",
       "  'study': 295,\n",
       "  'career': 296,\n",
       "  'advise': 297,\n",
       "  'early': 298,\n",
       "  'managed': 299,\n",
       "  'retain': 300,\n",
       "  'over': 301,\n",
       "  'arching': 302,\n",
       "  'generalist': 303,\n",
       "  'knowledge': 304,\n",
       "  \"can't\": 305,\n",
       "  'replaced': 306,\n",
       "  'very': 307,\n",
       "  'easily': 308,\n",
       "  'because': 309,\n",
       "  'absorbing': 310,\n",
       "  'new': 311,\n",
       "  'information': 312,\n",
       "  'time': 313,\n",
       "  'began': 314,\n",
       "  'starting': 315,\n",
       "  'scratch': 316,\n",
       "  'serial': 317,\n",
       "  'done': 318,\n",
       "  'practical': 319,\n",
       "  'just': 320,\n",
       "  'looking': 321,\n",
       "  'program': 322,\n",
       "  'confirm': 323,\n",
       "  'really': 324,\n",
       "  'topics': 325,\n",
       "  'here': 326,\n",
       "  'requires': 327,\n",
       "  'shutting': 328,\n",
       "  'out': 329,\n",
       "  'demands': 330,\n",
       "  'matter': 331,\n",
       "  'speaking': 332,\n",
       "  'interested': 333,\n",
       "  'advantages': 334,\n",
       "  'disadvantages': 335,\n",
       "  'bit': 336,\n",
       "  'unless': 337,\n",
       "  'whenever': 338,\n",
       "  'see': 339,\n",
       "  'marketing': 340,\n",
       "  'material': 341,\n",
       "  'tells': 342,\n",
       "  'adopting': 343,\n",
       "  'makes': 344,\n",
       "  'remember': 345,\n",
       "  'george': 346,\n",
       "  'santayana': 347,\n",
       "  'said': 348,\n",
       "  'scepticism': 349,\n",
       "  'chastity': 350,\n",
       "  'intellect': 351,\n",
       "  'shameful': 352,\n",
       "  'give': 353,\n",
       "  'too': 354,\n",
       "  'soon': 355,\n",
       "  'first': 356,\n",
       "  'comer': 357,\n",
       "  'suspect': 358,\n",
       "  'majority': 359,\n",
       "  'similar': 360,\n",
       "  'skepticism': 361,\n",
       "  \"it's\": 362,\n",
       "  'magic': 363,\n",
       "  'answer': 364,\n",
       "  'ever': 365,\n",
       "  'accept': 366,\n",
       "  'by': 367,\n",
       "  'large': 368,\n",
       "  'something': 369,\n",
       "  'particular': 370,\n",
       "  'mechanisms': 371,\n",
       "  'them': 372,\n",
       "  'feeling': 373,\n",
       "  'stems': 374,\n",
       "  'long': 375,\n",
       "  'substantiated': 376,\n",
       "  'truism': 377,\n",
       "  'scalpel': 378,\n",
       "  'hammer': 379,\n",
       "  'gas': 380,\n",
       "  'ill': 381,\n",
       "  'inherent': 382,\n",
       "  'your': 383,\n",
       "  'definition': 384,\n",
       "  'wide': 385,\n",
       "  'suggest': 386,\n",
       "  'set': 387,\n",
       "  'favors': 388,\n",
       "  'days': 389,\n",
       "  'chris': 390,\n",
       "  'inglis': 391,\n",
       "  'recently': 392,\n",
       "  'retired': 393,\n",
       "  'nsa': 394,\n",
       "  'deputy': 395,\n",
       "  'director': 396,\n",
       "  'remarked': 397,\n",
       "  'soccer': 398,\n",
       "  'tally': 399,\n",
       "  '462': 400,\n",
       "  '456': 401,\n",
       "  'twenty': 402,\n",
       "  'minutes': 403,\n",
       "  'ci': 404,\n",
       "  'e': 405,\n",
       "  'take': 406,\n",
       "  'his': 407,\n",
       "  'comment': 408,\n",
       "  'level': 409,\n",
       "  'nature': 410,\n",
       "  'also': 411,\n",
       "  'where': 412,\n",
       "  'innovations': 413,\n",
       "  'states': 414,\n",
       "  'afford': 415,\n",
       "  'nevertheless': 416,\n",
       "  'essay': 417,\n",
       "  'outgrowth': 418,\n",
       "  'extension': 419,\n",
       "  'increasing': 420,\n",
       "  'importance': 421,\n",
       "  'spoke': 422,\n",
       "  'word': 423,\n",
       "  'longer': 424,\n",
       "  'engaging': 425,\n",
       "  'sort': 426,\n",
       "  'parlor': 427,\n",
       "  'becomes': 428,\n",
       "  'interlaced': 429,\n",
       "  'aspect': 430,\n",
       "  'life': 431,\n",
       "  'everybody': 432,\n",
       "  'outcome': 433,\n",
       "  'differential': 434,\n",
       "  'between': 435,\n",
       "  'bad': 436,\n",
       "  'broadens': 437,\n",
       "  'ease': 438,\n",
       "  'finding': 439,\n",
       "  'answers': 440,\n",
       "  'falls': 441,\n",
       "  'h': 442,\n",
       "  'l': 443,\n",
       "  'mencken': 444,\n",
       "  'so': 445,\n",
       "  'trenchantly': 446,\n",
       "  'put': 447,\n",
       "  'complex': 448,\n",
       "  'clear': 449,\n",
       "  'four': 450,\n",
       "  'verities': 451,\n",
       "  'government': 452,\n",
       "  'unappealing': 453,\n",
       "  'appealing': 454,\n",
       "  'unimportant': 455,\n",
       "  'side': 456,\n",
       "  'effects': 457})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "len(tokenizer.word_index),tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c59622b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' [ nominal delivery draft, 6 August 2014 ]  Cybersecurity as Realpolitik Dan Geer   Good morning and thank you for the invitation to speak with you today.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7dfa5c61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[148, 149, 150, 151, 152, 153, 25, 26, 154, 155, 156, 20, 157, 7, 158, 15, 9, 1, 159, 6, 84, 36, 15, 85]\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.texts_to_sequences([sentences[0]])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9ec6811",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([148], 149),\n",
       " ([148, 149], 150),\n",
       " ([148, 149, 150], 151),\n",
       " ([148, 149, 150, 151], 152),\n",
       " ([148, 149, 150, 151, 152], 153),\n",
       " ([1], 160),\n",
       " ([1, 160], 3),\n",
       " ([1, 160, 3], 27),\n",
       " ([1, 160, 3, 27], 86),\n",
       " ([1, 160, 3, 27, 86], 21),\n",
       " ([87], 4),\n",
       " ([87, 4], 17),\n",
       " ([87, 4, 17], 8),\n",
       " ([87, 4, 17, 8], 28),\n",
       " ([87, 4, 17, 8, 28], 164),\n",
       " ([9], 89),\n",
       " ([9, 89], 169),\n",
       " ([9, 89, 169], 90),\n",
       " ([9, 89, 169, 90], 29),\n",
       " ([9, 89, 169, 90, 29], 170),\n",
       " ([44], 45),\n",
       " ([44, 45], 9),\n",
       " ([44, 45, 9], 12),\n",
       " ([44, 45, 9, 12], 174),\n",
       " ([44, 45, 9, 12, 174], 38),\n",
       " ([93], 45),\n",
       " ([93, 45], 9),\n",
       " ([93, 45, 9], 12),\n",
       " ([93, 45, 9, 12], 175),\n",
       " ([93, 45, 9, 12, 175], 38),\n",
       " ([44], 19),\n",
       " ([44, 19], 1),\n",
       " ([44, 19, 1], 94),\n",
       " ([44, 19, 1, 94], 6),\n",
       " ([44, 19, 1, 94, 6], 176),\n",
       " ([95], 14),\n",
       " ([95, 14], 184),\n",
       " ([95, 14, 184], 185),\n",
       " ([95, 14, 184, 185], 2),\n",
       " ([95, 14, 184, 185, 2], 186),\n",
       " ([4], 96),\n",
       " ([4, 96], 192),\n",
       " ([4, 96, 192], 3),\n",
       " ([4, 96, 192, 3], 67),\n",
       " ([4, 96, 192, 3, 67], 7),\n",
       " ([47], 99),\n",
       " ([47, 99], 8),\n",
       " ([47, 99, 8], 196),\n",
       " ([100], 10),\n",
       " ([100, 10], 198),\n",
       " ([100, 10, 198], 2),\n",
       " ([100, 10, 198, 2], 48),\n",
       " ([100, 10, 198, 2, 48], 13),\n",
       " ([4], 203),\n",
       " ([4, 203], 2),\n",
       " ([4, 203, 2], 40),\n",
       " ([4, 203, 2, 40], 204),\n",
       " ([4, 203, 2, 40, 204], 17),\n",
       " ([210], 4),\n",
       " ([210, 4], 17),\n",
       " ([210, 4, 17], 105),\n",
       " ([210, 4, 17, 105], 10),\n",
       " ([210, 4, 17, 105, 10], 211),\n",
       " ([26], 32),\n",
       " ([26, 32], 10),\n",
       " ([26, 32, 10], 213),\n",
       " ([26, 32, 10, 213], 214),\n",
       " ([26, 32, 10, 213, 214], 12),\n",
       " ([27], 5),\n",
       " ([27, 5], 8),\n",
       " ([27, 5, 8], 6),\n",
       " ([27, 5, 8, 6], 219),\n",
       " ([27, 5, 8, 6, 219], 111),\n",
       " ([12], 16),\n",
       " ([12, 16], 5),\n",
       " ([12, 16, 5], 54),\n",
       " ([12, 16, 5, 54], 72),\n",
       " ([12, 16, 5, 54, 72], 115),\n",
       " ([231], 30),\n",
       " ([231, 30], 14),\n",
       " ([231, 30, 14], 106),\n",
       " ([231, 30, 14, 106], 116),\n",
       " ([231, 30, 14, 106, 116], 232),\n",
       " ([7], 15),\n",
       " ([7, 15], 248),\n",
       " ([7, 15, 248], 249),\n",
       " ([7, 15, 248, 249], 250),\n",
       " ([4], 45),\n",
       " ([4, 45], 2),\n",
       " ([4, 45, 2], 4),\n",
       " ([4, 45, 2, 4], 252),\n",
       " ([4, 45, 2, 4, 252], 56),\n",
       " ([10], 5),\n",
       " ([10, 5], 8),\n",
       " ([10, 5, 8], 57),\n",
       " ([10, 5, 8, 57], 2),\n",
       " ([10, 5, 8, 57, 2], 265),\n",
       " ([4], 19),\n",
       " ([4, 19], 123),\n",
       " ([4, 19, 123], 270),\n",
       " ([4, 19, 123, 270], 6),\n",
       " ([4, 19, 123, 270, 6], 271),\n",
       " ([8], 42),\n",
       " ([8, 42], 21),\n",
       " ([8, 42, 21], 25),\n",
       " ([8, 42, 21, 25], 277),\n",
       " ([8, 42, 21, 25, 277], 1),\n",
       " ([32], 129),\n",
       " ([32, 129], 5),\n",
       " ([32, 129, 5], 1),\n",
       " ([32, 129, 5, 1], 282),\n",
       " ([32, 129, 5, 1, 282], 3),\n",
       " ([1], 287),\n",
       " ([1, 287], 3),\n",
       " ([1, 287, 3], 288),\n",
       " ([1, 287, 3, 288], 289),\n",
       " ([1, 287, 3, 288, 289], 5),\n",
       " ([48], 290),\n",
       " ([48, 290], 291),\n",
       " ([48, 290, 291], 292),\n",
       " ([48, 290, 291, 292], 40),\n",
       " ([48, 290, 291, 292, 40], 293),\n",
       " ([67], 3),\n",
       " ([67, 3], 71),\n",
       " ([67, 3, 71], 70),\n",
       " ([67, 3, 71, 70], 53),\n",
       " ([67, 3, 71, 70, 53], 11),\n",
       " ([317], 132),\n",
       " ([317, 132], 5),\n",
       " ([317, 132, 5], 50),\n",
       " ([317, 132, 5, 50], 22),\n",
       " ([317, 132, 5, 50, 22], 2),\n",
       " ([320], 321),\n",
       " ([320, 321], 41),\n",
       " ([320, 321, 41], 1),\n",
       " ([320, 321, 41, 1], 111),\n",
       " ([320, 321, 41, 1, 111], 112),\n",
       " ([136], 99),\n",
       " ([136, 99], 2),\n",
       " ([332], 9),\n",
       " ([332, 9], 107),\n",
       " ([332, 9, 107], 4),\n",
       " ([332, 9, 107, 4], 126),\n",
       " ([332, 9, 107, 4, 126], 8),\n",
       " ([338], 4),\n",
       " ([338, 4], 339),\n",
       " ([338, 4, 339], 340),\n",
       " ([338, 4, 339, 340], 341),\n",
       " ([338, 4, 339, 340, 341], 2),\n",
       " ([4], 358),\n",
       " ([4, 358], 2),\n",
       " ([4, 358, 2], 13),\n",
       " ([4, 358, 2, 13], 359),\n",
       " ([4, 358, 2, 13, 359], 3),\n",
       " ([5], 8),\n",
       " ([5, 8], 1),\n",
       " ([5, 8, 1], 364),\n",
       " ([5, 8, 1, 364], 13),\n",
       " ([5, 8, 1, 364, 13], 16),\n",
       " ([367], 7),\n",
       " ([367, 7], 368),\n",
       " ([367, 7, 368], 4),\n",
       " ([367, 7, 368, 4], 18),\n",
       " ([367, 7, 368, 4, 18], 56),\n",
       " ([56], 29),\n",
       " ([56, 29], 79),\n",
       " ([56, 29, 79], 10),\n",
       " ([56, 29, 79, 10], 80),\n",
       " ([56, 29, 79, 10, 80], 7),\n",
       " ([131], 3),\n",
       " ([131, 3], 40),\n",
       " ([131, 3, 40], 373),\n",
       " ([131, 3, 40, 373], 374),\n",
       " ([131, 3, 40, 373, 374], 60),\n",
       " ([119], 62),\n",
       " ([119, 62], 35),\n",
       " ([119, 62, 35], 5),\n",
       " ([119, 62, 35, 5], 13),\n",
       " ([119, 62, 35, 5, 13], 377),\n",
       " ([32], 383),\n",
       " ([32, 383], 384),\n",
       " ([32, 383, 384], 3),\n",
       " ([32, 383, 384, 3], 141),\n",
       " ([32, 383, 384, 3, 141], 5),\n",
       " ([390], 391),\n",
       " ([390, 391], 392),\n",
       " ([390, 391, 392], 393),\n",
       " ([390, 391, 392, 393], 394),\n",
       " ([390, 391, 392, 393, 394], 395),\n",
       " ([4], 17),\n",
       " ([4, 17], 406),\n",
       " ([4, 17, 406], 407),\n",
       " ([4, 17, 406, 407], 408),\n",
       " ([4, 17, 406, 407, 408], 26),\n",
       " ([416], 27),\n",
       " ([416, 27], 417),\n",
       " ([416, 27, 417], 5),\n",
       " ([416, 27, 417, 5], 78),\n",
       " ([416, 27, 417, 5, 78], 418),\n",
       " ([36], 1),\n",
       " ([36, 1], 47),\n",
       " ([36, 1, 47], 3),\n",
       " ([36, 1, 47, 3], 38),\n",
       " ([36, 1, 47, 3, 38], 4),\n",
       " ([31], 4),\n",
       " ([31, 4], 37),\n",
       " ([31, 4, 37], 82),\n",
       " ([31, 4, 37, 82], 5),\n",
       " ([31, 4, 37, 82, 5], 2),\n",
       " ([4], 82),\n",
       " ([4, 82], 2),\n",
       " ([4, 82, 2], 73),\n",
       " ([4, 82, 2, 73], 145),\n",
       " ([4, 82, 2, 73, 145], 14),\n",
       " ([26], 442),\n",
       " ([444], 445),\n",
       " ([444, 445], 446),\n",
       " ([444, 445, 446], 447),\n",
       " ([444, 445, 446, 447], 10),\n",
       " ([444, 445, 446, 447, 10], 9),\n",
       " ([1], 450),\n",
       " ([1, 450], 451),\n",
       " ([1, 450, 451], 3),\n",
       " ([1, 450, 451, 3], 452),\n",
       " ([1, 450, 451, 3, 452], 14),\n",
       " ([43], 51),\n",
       " ([43, 51], 147),\n",
       " ([43, 51, 147], 14),\n",
       " ([43], 454),\n",
       " ([43, 454], 147),\n",
       " ([43, 454, 147], 14),\n",
       " ([8], 23),\n",
       " ([8, 23], 146),\n",
       " ([8, 23, 146], 21),\n",
       " ([8, 23, 146, 21], 13),\n",
       " ([8, 23, 146, 21, 13], 20),\n",
       " ([23], 83),\n",
       " ([23, 83], 21),\n",
       " ([23, 83, 21], 456)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encodedSentences = []\n",
    "for sentence in sentences:\n",
    "    encoded = tokenizer.texts_to_sequences([sentence])[0]\n",
    "    # Create input-output pairs for next word prediction\n",
    "    for i in range(len(encoded)-1):\n",
    "        if i != 0 and i<=5:\n",
    "            seq = encoded[:i]          # input sequence\n",
    "            target = encoded[i]        # next word to predict\n",
    "            encodedSentences.append((seq, target))\n",
    "\n",
    "encodedSentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b7a9420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[148],\n",
       "  [148, 149],\n",
       "  [148, 149, 150],\n",
       "  [148, 149, 150, 151],\n",
       "  [148, 149, 150, 151, 152],\n",
       "  [1],\n",
       "  [1, 160],\n",
       "  [1, 160, 3],\n",
       "  [1, 160, 3, 27],\n",
       "  [1, 160, 3, 27, 86]],\n",
       " [149, 150, 151, 152, 153, 160, 3, 27, 86, 21])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = []\n",
    "y = []\n",
    "for seq, target in encodedSentences:\n",
    "    x.append(seq)\n",
    "    y.append(target)\n",
    "x[:10], y[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6067e594",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0, 148],\n",
       "       [  0,   0,   0, 148, 149],\n",
       "       [  0,   0, 148, 149, 150],\n",
       "       ...,\n",
       "       [  0,   0,   0,   0,  23],\n",
       "       [  0,   0,   0,  23,  83],\n",
       "       [  0,   0,  23,  83,  21]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "x = np.array(pad_sequences(x, maxlen=5, padding='pre'))\n",
    "y=np.array(y)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ecb883c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(239, 5)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8c482a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\DeepLearning\\Code\\env\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)          │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,580</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ simple_rnn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,376</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">458</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">15,114</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m10\u001b[0m)          │         \u001b[38;5;34m4,580\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ simple_rnn (\u001b[38;5;33mSimpleRNN\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m1,376\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m458\u001b[0m)            │        \u001b[38;5;34m15,114\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,070</span> (82.30 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m21,070\u001b[0m (82.30 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,070</span> (82.30 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m21,070\u001b[0m (82.30 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Embedding(input_dim=len(tokenizer.word_index)+1, output_dim=10, input_length=5),\n",
    "    SimpleRNN(32,activation='relu'),\n",
    "    Dropout(0.05),\n",
    "    Dense(len(tokenizer.word_index)+1, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.build(input_shape=(None, 5))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bdd705e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.0202 - loss: 6.1261   \n",
      "Epoch 2/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0559 - loss: 6.1138 \n",
      "Epoch 3/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0515 - loss: 6.0988 \n",
      "Epoch 4/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\DeepLearning\\Code\\env\\Lib\\site-packages\\keras\\src\\callbacks\\early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: accuracy,loss\n",
      "  current = self.get_monitor_value(logs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0388 - loss: 6.0742 \n",
      "Epoch 5/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0554 - loss: 6.0106 \n",
      "Epoch 6/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0518 - loss: 5.8455 \n",
      "Epoch 7/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0327 - loss: 5.4691     \n",
      "Epoch 8/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0389 - loss: 5.1182 \n",
      "Epoch 9/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0344 - loss: 4.9345 \n",
      "Epoch 10/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0413 - loss: 4.9472 \n",
      "Epoch 11/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0639 - loss: 4.8043 \n",
      "Epoch 12/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0452 - loss: 4.6915 \n",
      "Epoch 13/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0524 - loss: 4.6879 \n",
      "Epoch 14/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0360 - loss: 4.6958 \n",
      "Epoch 15/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0634 - loss: 4.6759 \n",
      "Epoch 16/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0471 - loss: 4.6750 \n",
      "Epoch 17/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0771 - loss: 4.6221 \n",
      "Epoch 18/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0609 - loss: 4.6039 \n",
      "Epoch 19/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0417 - loss: 4.5215 \n",
      "Epoch 20/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1075 - loss: 4.5099 \n",
      "Epoch 21/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0648 - loss: 4.5011 \n",
      "Epoch 22/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0486 - loss: 4.4707 \n",
      "Epoch 23/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0679 - loss: 4.3234 \n",
      "Epoch 24/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0443 - loss: 4.3478     \n",
      "Epoch 25/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0572 - loss: 4.2720 \n",
      "Epoch 26/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0422 - loss: 4.3176 \n",
      "Epoch 27/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0514 - loss: 4.2625 \n",
      "Epoch 28/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0540 - loss: 4.2416     \n",
      "Epoch 29/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0783 - loss: 4.1200 \n",
      "Epoch 30/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0867 - loss: 4.0506 \n",
      "Epoch 31/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0803 - loss: 4.0330 \n",
      "Epoch 32/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0703 - loss: 3.9705 \n",
      "Epoch 33/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0875 - loss: 3.9382     \n",
      "Epoch 34/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0932 - loss: 3.8326 \n",
      "Epoch 35/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0866 - loss: 3.8431 \n",
      "Epoch 36/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1045 - loss: 3.7427 \n",
      "Epoch 37/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0814 - loss: 3.7462 \n",
      "Epoch 38/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0976 - loss: 3.6795 \n",
      "Epoch 39/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1135 - loss: 3.5847 \n",
      "Epoch 40/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0988 - loss: 3.5167 \n",
      "Epoch 41/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1433 - loss: 3.4652 \n",
      "Epoch 42/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1557 - loss: 3.3895 \n",
      "Epoch 43/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1590 - loss: 3.3725 \n",
      "Epoch 44/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1604 - loss: 3.3809 \n",
      "Epoch 45/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1790 - loss: 3.3111 \n",
      "Epoch 46/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1641 - loss: 3.1962 \n",
      "Epoch 47/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1789 - loss: 3.1336 \n",
      "Epoch 48/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1843 - loss: 3.1456 \n",
      "Epoch 49/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1808 - loss: 3.2072 \n",
      "Epoch 50/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2174 - loss: 3.0673 \n",
      "Epoch 51/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2331 - loss: 3.0490 \n",
      "Epoch 52/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2384 - loss: 2.9523 \n",
      "Epoch 53/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2792 - loss: 2.9206 \n",
      "Epoch 54/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2623 - loss: 2.9002 \n",
      "Epoch 55/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2977 - loss: 2.8341 \n",
      "Epoch 56/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2361 - loss: 2.8855 \n",
      "Epoch 57/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3166 - loss: 2.7310 \n",
      "Epoch 58/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2580 - loss: 2.7385 \n",
      "Epoch 59/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2830 - loss: 2.7577 \n",
      "Epoch 60/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3925 - loss: 2.5903 \n",
      "Epoch 61/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2975 - loss: 2.7705 \n",
      "Epoch 62/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3168 - loss: 2.6944 \n",
      "Epoch 63/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3474 - loss: 2.5207 \n",
      "Epoch 64/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3169 - loss: 2.5813 \n",
      "Epoch 65/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3918 - loss: 2.4952 \n",
      "Epoch 66/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3642 - loss: 2.4640 \n",
      "Epoch 67/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3837 - loss: 2.3349 \n",
      "Epoch 68/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3947 - loss: 2.3295 \n",
      "Epoch 69/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4340 - loss: 2.2660 \n",
      "Epoch 70/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3953 - loss: 2.4334 \n",
      "Epoch 71/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4207 - loss: 2.2603 \n",
      "Epoch 72/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4303 - loss: 2.2813 \n",
      "Epoch 73/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4149 - loss: 2.3363 \n",
      "Epoch 74/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4499 - loss: 2.1658 \n",
      "Epoch 75/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5170 - loss: 2.0804 \n",
      "Epoch 76/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4702 - loss: 2.0433 \n",
      "Epoch 77/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4517 - loss: 2.1944 \n",
      "Epoch 78/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4974 - loss: 2.0491 \n",
      "Epoch 79/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5632 - loss: 1.8874 \n",
      "Epoch 80/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4885 - loss: 2.0864 \n",
      "Epoch 81/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5113 - loss: 2.0298 \n",
      "Epoch 82/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5498 - loss: 1.8128 \n",
      "Epoch 83/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5123 - loss: 1.8550 \n",
      "Epoch 84/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5364 - loss: 1.8992 \n",
      "Epoch 85/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5123 - loss: 1.8828 \n",
      "Epoch 86/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4680 - loss: 1.9539 \n",
      "Epoch 87/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5428 - loss: 1.8114 \n",
      "Epoch 88/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4915 - loss: 1.8392 \n",
      "Epoch 89/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5388 - loss: 1.7897 \n",
      "Epoch 90/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5895 - loss: 1.6583 \n",
      "Epoch 91/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5458 - loss: 1.7740 \n",
      "Epoch 92/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5552 - loss: 1.6993 \n",
      "Epoch 93/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6201 - loss: 1.5959 \n",
      "Epoch 94/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6153 - loss: 1.6062 \n",
      "Epoch 95/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6169 - loss: 1.5398 \n",
      "Epoch 96/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5967 - loss: 1.6222 \n",
      "Epoch 97/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6609 - loss: 1.4904 \n",
      "Epoch 98/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5717 - loss: 1.6490 \n",
      "Epoch 99/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6610 - loss: 1.4305 \n",
      "Epoch 100/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6213 - loss: 1.4913 \n",
      "Epoch 101/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6317 - loss: 1.5112 \n",
      "Epoch 102/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5862 - loss: 1.4992 \n",
      "Epoch 103/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6317 - loss: 1.4854 \n",
      "Epoch 104/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6185 - loss: 1.5091 \n",
      "Epoch 105/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6233 - loss: 1.5429 \n",
      "Epoch 106/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6344 - loss: 1.4152 \n",
      "Epoch 107/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6684 - loss: 1.3197 \n",
      "Epoch 108/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6922 - loss: 1.3460 \n",
      "Epoch 109/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6317 - loss: 1.4109 \n",
      "Epoch 110/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6102 - loss: 1.4646 \n",
      "Epoch 111/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6006 - loss: 1.4871 \n",
      "Epoch 112/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6540 - loss: 1.3527 \n",
      "Epoch 113/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6525 - loss: 1.2934 \n",
      "Epoch 114/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6286 - loss: 1.4072 \n",
      "Epoch 115/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6398 - loss: 1.3129 \n",
      "Epoch 116/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6786 - loss: 1.2661 \n",
      "Epoch 117/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6649 - loss: 1.1749 \n",
      "Epoch 118/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6684 - loss: 1.2236 \n",
      "Epoch 119/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6822 - loss: 1.1990 \n",
      "Epoch 120/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6018 - loss: 1.3306 \n",
      "Epoch 121/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6928 - loss: 1.2082 \n",
      "Epoch 122/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6887 - loss: 1.1003 \n",
      "Epoch 123/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6692 - loss: 1.2516 \n",
      "Epoch 124/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6624 - loss: 1.1964 \n",
      "Epoch 125/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6947 - loss: 1.1359 \n",
      "Epoch 126/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7284 - loss: 1.1515 \n",
      "Epoch 127/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6825 - loss: 1.1856 \n",
      "Epoch 128/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7136 - loss: 1.1601 \n",
      "Epoch 129/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7478 - loss: 1.0421 \n",
      "Epoch 130/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7099 - loss: 1.1144 \n",
      "Epoch 131/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7163 - loss: 1.1325 \n",
      "Epoch 132/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6700 - loss: 1.2778 \n",
      "Epoch 133/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7226 - loss: 1.0285 \n",
      "Epoch 134/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7404 - loss: 1.0398 \n",
      "Epoch 135/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7117 - loss: 1.0828 \n",
      "Epoch 136/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7706 - loss: 0.9940 \n",
      "Epoch 137/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7189 - loss: 1.0824 \n",
      "Epoch 138/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7430 - loss: 1.0048 \n",
      "Epoch 139/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7615 - loss: 0.9702 \n",
      "Epoch 140/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7214 - loss: 0.9951 \n",
      "Epoch 141/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7464 - loss: 0.9940 \n",
      "Epoch 142/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7019 - loss: 1.0653 \n",
      "Epoch 143/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6946 - loss: 1.1406 \n",
      "Epoch 144/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7919 - loss: 0.8972 \n",
      "Epoch 145/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7575 - loss: 0.8939 \n",
      "Epoch 146/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7582 - loss: 0.9735 \n",
      "Epoch 147/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7624 - loss: 0.9677 \n",
      "Epoch 148/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7213 - loss: 0.9730 \n",
      "Epoch 149/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7697 - loss: 0.9204 \n",
      "Epoch 150/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8017 - loss: 0.8104 \n",
      "Epoch 151/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7272 - loss: 0.9804 \n",
      "Epoch 152/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7739 - loss: 0.9145 \n",
      "Epoch 153/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7569 - loss: 0.9618 \n",
      "Epoch 154/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7973 - loss: 0.9125 \n",
      "Epoch 155/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7799 - loss: 0.9023 \n",
      "Epoch 156/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7709 - loss: 0.8914 \n",
      "Epoch 157/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7899 - loss: 0.7861 \n",
      "Epoch 158/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7635 - loss: 0.8752 \n",
      "Epoch 159/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7215 - loss: 0.9634 \n",
      "Epoch 160/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7594 - loss: 0.9582 \n",
      "Epoch 161/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7529 - loss: 0.9431 \n",
      "Epoch 162/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7646 - loss: 0.8660 \n",
      "Epoch 163/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8044 - loss: 0.8027 \n",
      "Epoch 164/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8470 - loss: 0.7152 \n",
      "Epoch 165/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8042 - loss: 0.7651 \n",
      "Epoch 166/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8033 - loss: 0.8224 \n",
      "Epoch 167/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7931 - loss: 0.7459 \n",
      "Epoch 168/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7881 - loss: 0.7713 \n",
      "Epoch 169/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8052 - loss: 0.7459 \n",
      "Epoch 170/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7879 - loss: 0.8127 \n",
      "Epoch 171/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7770 - loss: 0.8293 \n",
      "Epoch 172/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8069 - loss: 0.8730 \n",
      "Epoch 173/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7789 - loss: 0.8163 \n",
      "Epoch 174/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7927 - loss: 0.8145 \n",
      "Epoch 175/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7990 - loss: 0.7339 \n",
      "Epoch 176/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7990 - loss: 0.7854 \n",
      "Epoch 177/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7855 - loss: 0.7299 \n",
      "Epoch 178/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8078 - loss: 0.7543 \n",
      "Epoch 179/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7916 - loss: 0.8310 \n",
      "Epoch 180/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7987 - loss: 0.7451 \n",
      "Epoch 181/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8163 - loss: 0.7441 \n",
      "Epoch 182/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8028 - loss: 0.7536 \n",
      "Epoch 183/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7901 - loss: 0.7268 \n",
      "Epoch 184/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8130 - loss: 0.7263 \n",
      "Epoch 185/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7962 - loss: 0.7530 \n",
      "Epoch 186/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7752 - loss: 0.7996 \n",
      "Epoch 187/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8012 - loss: 0.7435 \n",
      "Epoch 188/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8212 - loss: 0.6626 \n",
      "Epoch 189/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8305 - loss: 0.6734 \n",
      "Epoch 190/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8468 - loss: 0.6910 \n",
      "Epoch 191/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8513 - loss: 0.6085 \n",
      "Epoch 192/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8222 - loss: 0.6830 \n",
      "Epoch 193/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8477 - loss: 0.5956 \n",
      "Epoch 194/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8301 - loss: 0.6343 \n",
      "Epoch 195/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8046 - loss: 0.6992 \n",
      "Epoch 196/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8489 - loss: 0.6313 \n",
      "Epoch 197/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8135 - loss: 0.6798 \n",
      "Epoch 198/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8570 - loss: 0.5757 \n",
      "Epoch 199/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8614 - loss: 0.6202 \n",
      "Epoch 200/200\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8347 - loss: 0.6461 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x168bb846ab0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "earlystopping=EarlyStopping(monitor='val_loss',patience=20,restore_best_weights=True)\n",
    "model.fit(x, y, batch_size=32, epochs=200, callbacks=[earlystopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe76ac8e",
   "metadata": {},
   "source": [
    "- Those of us who are backing out our remaining dependencies on digital goods and services are being entirely rational and are likely to survive.\n",
    "- I say that because the root cause of risk is dependence, and most especially dependence on expectations of system state.\n",
    "- If I don't use my trademark, then my rights go over to those who use what was and could have remained mine.\n",
    "- For better or poorer, the only two products not covered by product liability today are religion and software, and software should not escape for much longer.\n",
    "\n",
    "<bR><br>\n",
    "\n",
    "- There are three professions that beat their practitioners into a state of humility: farming, weather forecasting, and cyber security. I practice two of those, and, as such, let me assure you that the recommendations which follow are presented in all humility.  Humility does not mean timidity.  Rather, it means that when a strongly held belief is proven wrong, that the humble person changes their mind. I expect that my proposals will result in considerable push-back, and changing my mind may well follow.  Though I will say it again later, this speech is me talking for myself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5fefca36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Whether we are talking about laws\n",
      "[30, 14, 106, 116, 232]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step\n",
      "Top predictions:\n",
      "that: 0.9517\n",
      "a: 0.0482\n",
      "tell: 0.0000\n",
      "advice: 0.0000\n",
      "seriously: 0.0000\n",
      "\n",
      " Whether we are talking about\n",
      "[231, 30, 14, 106, 116]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "Top predictions:\n",
      "laws: 0.9986\n",
      "to: 0.0004\n",
      "be: 0.0002\n",
      "taken: 0.0002\n",
      "can: 0.0002\n",
      "\n",
      " Whether we are talking\n",
      "[[  0 231  30  14 106]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "Top predictions:\n",
      "about: 0.9957\n",
      "my: 0.0030\n",
      "a: 0.0009\n",
      "to: 0.0002\n",
      "an: 0.0001\n",
      "\n",
      " Whether we are\n",
      "[[  0   0 231  30  14]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "Top predictions:\n",
      "talking: 0.9829\n",
      "has: 0.0080\n",
      "his: 0.0052\n",
      "mean: 0.0018\n",
      "my: 0.0007\n",
      "\n",
      " Whether we\n",
      "[[  0   0   0 231  30]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "Top predictions:\n",
      "are: 0.8230\n",
      "i: 0.0453\n",
      "trenchantly: 0.0334\n",
      "has: 0.0200\n",
      "for: 0.0095\n",
      "\n",
      " Whether\n",
      "[[  0   0   0   0 231]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "Top predictions:\n",
      "we: 0.1797\n",
      "if: 0.0759\n",
      "this: 0.0758\n",
      "so: 0.0546\n",
      "does: 0.0544\n"
     ]
    }
   ],
   "source": [
    "input=[\"Whether we are talking about laws\",\"Whether we are talking about\",\"Whether we are talking\",\"Whether we are\",\"Whether we\",\"Whether\"]\n",
    "for line in input:\n",
    "    print('\\n',line)\n",
    "    input=line.split(' ')\n",
    "    if len(input) >=5:\n",
    "        input=tokenizer.texts_to_sequences([input[-5:]])[0]\n",
    "        print(input)\n",
    "        input=np.array(input).reshape(1,5)\n",
    "    else:\n",
    "        input=tokenizer.texts_to_sequences([input])[0]\n",
    "        input=np.array(pad_sequences([input], maxlen=5, padding='pre'))\n",
    "        print(input)\n",
    "        input=np.array(input).reshape(1,5)\n",
    "    # model.predict(input)\n",
    "    prediction = model.predict(input)\n",
    "    top_n = 5\n",
    "    top_indices = prediction[0].argsort()[-top_n:][::-1]\n",
    "    top_words = [(tokenizer.index_word.get(i, \"<UNK>\"), prediction[0][i]) for i in top_indices]\n",
    "\n",
    "    print(\"Top predictions:\")\n",
    "    for word, score in top_words:\n",
    "        print(f\"{word}: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01495136",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea95f3d0",
   "metadata": {},
   "source": [
    "# Without Embedding Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "77b1cdaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' [ nominal delivery draft, 6 August 2014 ]  Cybersecurity as Realpolitik Dan Geer   Good morning and thank you for the invitation to speak with you today.',\n",
       " 'The plaintext of this talk has been made available to the organizers.',\n",
       " 'While I will not be taking questions today, you are welcome to contact me later and I will do what I can to reply.',\n",
       " 'For simple clarity, let me repeat the abstract for this talk:     Power exists to be used.',\n",
       " 'Some wish for cyber safety, which they    will not get.',\n",
       " 'Others wish for cyber order, which they will not    get.',\n",
       " 'Some have the eye to discern cyber policies that are \"the    least worst thing;\" may they fill the vacuum of wishful thinking.',\n",
       " 'There are three professions that beat their practitioners into a state of humility: farming, weather forecasting, and cyber security.',\n",
       " 'I practice two of those, and, as such, let me assure you that the recommendations which follow are presented in all humility.',\n",
       " 'Humility does not mean timidity.',\n",
       " 'Rather, it means that when a strongly held belief is proven wrong, that the humble person changes their mind.',\n",
       " 'I expect that my proposals will result in considerable push-back, and changing my mind may well follow.',\n",
       " 'Though I will say it again later, this speech is me talking for myself.',\n",
       " 'As if it needed saying, cyber security is now a riveting concern, a top issue in many venues more important than this one.',\n",
       " 'This is not to insult Black Hat; rather it is to note that every speaker, every writer, every practitioner in the field of cyber security who has wished that its topic, and us with it, were taken seriously has gotten their wish.',\n",
       " 'Cyber security *is* being taken seriously, which, as you well know is not the same as being taken usefully, coherently, or lastingly.',\n",
       " 'Whether we are talking about laws like the Digital Millenium Copyright Act or the Computer Fraud and Abuse Act, or the non-lawmaking but perhaps even more significant actions that the Executive agencies are undertaking, \"we\" and the cyber security issue have never been more at the forefront of policy.',\n",
       " \"And you ain't seen nothing yet.\",\n",
       " \"I wish that I could tell you that it is still possible for one person to hold the big picture firmly in their mind's eye, to track everything important that is going on in our field, to make few if any sins of omission.\",\n",
       " 'It is not possible; that phase passed sometime in the last six years.',\n",
       " 'I have certainly tried to keep up but I would be less than candid if I were not to say that I know that I am not keeping up, not even keeping up with what is going on in my own country much less all countries.',\n",
       " 'Not only has cybersecurity reached the highest levels of attention, it has spread into nearly every corner.',\n",
       " 'If area is the product of height and width, then the footprint of cybersecurity has surpassed the grasp of any one of us.',\n",
       " 'The rate of technological change is certainly a part of it.',\n",
       " 'When younger people ask my advice on what they should do or study to make a career in cyber security, I can only advise specialization.',\n",
       " \"Those of us who were in the game early enough and who have managed to retain an over-arching generalist knowledge can't be replaced very easily because while absorbing most new information most of the time may have been possible when we began practice, no person starting from scratch can do that now.\",\n",
       " 'Serial specialization is now all that can be done in any practical way.',\n",
       " 'Just looking at the Black Hat program will confirm that being really good at any one of the many topics presented here all but requires shutting out the demands of being good at any others.',\n",
       " 'Why does that matter?',\n",
       " 'Speaking for myself, I am not interested in the advantages or disadvantages of some bit of technology unless I can grasp how it is that that technology works.',\n",
       " 'Whenever I see marketing material that tells me all the good things that adopting this or that technology makes possible, I remember what George Santayana said, that \"Scepticism is the chastity of the intellect; it is shameful to give it up too soon, or to the first comer.\"',\n",
       " 'I suspect that a majority of you have similar skepticism -- \"It\\'s magic!\"',\n",
       " 'is not the answer a security person will ever accept.',\n",
       " 'By and large, I can tell *what* something is good for once I know *how* it works.',\n",
       " 'Tell me how it works and then, but only then, tell me why you have chosen to use those particular mechanisms for the things you have chosen to use them for.',\n",
       " 'Part of my feeling stems from a long-held and well-substantiated belief that all cyber security technology is dual use.',\n",
       " 'Perhaps dual use is a truism for any and all tools from the scalpel to the hammer to the gas can -- they can be used for good or ill -- but I know that dual use is inherent in cyber security tools.',\n",
       " 'If your definition of \"tool\" is wide enough, I suggest that the cyber security tool-set favors offense these days.',\n",
       " 'Chris Inglis, recently retired NSA Deputy Director, remarked that if we were to score cyber the way we score soccer, the tally would be 462-456 twenty minutes into the game,[CI] i.e., all offense.',\n",
       " 'I will take his comment as confirming at the highest level not only the dual use nature of cybersecurity but also confirming that offense is where the innovations that only States can afford is going on.',\n",
       " 'Nevertheless, this essay is an outgrowth from, an extension of, that increasing importance of cybersecurity.',\n",
       " 'With the humility of which I spoke, I do not claim that I have the last word.',\n",
       " 'What I do claim is that when we speak about cybersecurity policy we are no longer engaging in some sort of parlor game.',\n",
       " 'I claim that policy matters are now the most important matters, that once a topic area, like cybersecurity, becomes interlaced with nearly every aspect of life for nearly everybody, the outcome differential between good policies and bad policies broadens, and the ease of finding answers falls.',\n",
       " 'As H.L.',\n",
       " 'Mencken so trenchantly put it, \"For every complex problem there is a solution that is clear, simple, and wrong.\"',\n",
       " 'The four verities of government are these: .',\n",
       " 'Most important ideas are unappealing .',\n",
       " 'Most appealing ideas are unimportant .',\n",
       " 'Not every problem has a good solution .',\n",
       " 'Every solution has side effects']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "sentences=sent_tokenize(corpus)\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c3566f39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' [ nominal delivery draft, 6 August 2014 ]  Cybersecurity as Realpolitik Dan Geer   Good morning and thank you for the invitation to speak with you today.'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "212945f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[', 'nominal', 'delivery', 'draft', ',', '6', 'August', '2014', ']', 'Cybersecurity', 'as', 'Realpolitik', 'Dan', 'Geer', 'Good', 'morning', 'and', 'thank', 'you', 'for', 'the', 'invitation', 'to', 'speak', 'with', 'you', 'today', '.']\n",
      "['[', 'nominal'] => delivery\n",
      "['[', 'nominal', 'delivery'] => draft\n",
      "['[', 'nominal', 'delivery', 'draft'] => ,\n",
      "['[', 'nominal', 'delivery', 'draft', ','] => 6\n",
      "['[', 'nominal', 'delivery', 'draft', ',', '6'] => August\n",
      "['nominal', 'delivery'] => draft\n",
      "['nominal', 'delivery', 'draft'] => ,\n",
      "['nominal', 'delivery', 'draft', ','] => 6\n",
      "['nominal', 'delivery', 'draft', ',', '6'] => August\n",
      "['delivery', 'draft'] => ,\n",
      "['delivery', 'draft', ','] => 6\n",
      "['delivery', 'draft', ',', '6'] => August\n",
      "['draft', ','] => 6\n",
      "['draft', ',', '6'] => August\n",
      "[',', '6'] => August\n",
      "['The', 'plaintext', 'of', 'this', 'talk', 'has', 'been', 'made', 'available', 'to', 'the', 'organizers', '.']\n",
      "['The', 'plaintext'] => of\n",
      "['The', 'plaintext', 'of'] => this\n",
      "['The', 'plaintext', 'of', 'this'] => talk\n",
      "['The', 'plaintext', 'of', 'this', 'talk'] => has\n",
      "['The', 'plaintext', 'of', 'this', 'talk', 'has'] => been\n",
      "['plaintext', 'of'] => this\n",
      "['plaintext', 'of', 'this'] => talk\n",
      "['plaintext', 'of', 'this', 'talk'] => has\n",
      "['plaintext', 'of', 'this', 'talk', 'has'] => been\n",
      "['of', 'this'] => talk\n",
      "['of', 'this', 'talk'] => has\n",
      "['of', 'this', 'talk', 'has'] => been\n",
      "['this', 'talk'] => has\n",
      "['this', 'talk', 'has'] => been\n",
      "['talk', 'has'] => been\n",
      "['While', 'I', 'will', 'not', 'be', 'taking', 'questions', 'today', ',', 'you', 'are', 'welcome', 'to', 'contact', 'me', 'later', 'and', 'I', 'will', 'do', 'what', 'I', 'can', 'to', 'reply', '.']\n",
      "['While', 'I'] => will\n",
      "['While', 'I', 'will'] => not\n",
      "['While', 'I', 'will', 'not'] => be\n",
      "['While', 'I', 'will', 'not', 'be'] => taking\n",
      "['While', 'I', 'will', 'not', 'be', 'taking'] => questions\n",
      "['I', 'will'] => not\n",
      "['I', 'will', 'not'] => be\n",
      "['I', 'will', 'not', 'be'] => taking\n",
      "['I', 'will', 'not', 'be', 'taking'] => questions\n",
      "['will', 'not'] => be\n",
      "['will', 'not', 'be'] => taking\n",
      "['will', 'not', 'be', 'taking'] => questions\n",
      "['not', 'be'] => taking\n",
      "['not', 'be', 'taking'] => questions\n",
      "['be', 'taking'] => questions\n",
      "['For', 'simple', 'clarity', ',', 'let', 'me', 'repeat', 'the', 'abstract', 'for', 'this', 'talk', ':', 'Power', 'exists', 'to', 'be', 'used', '.']\n",
      "['For', 'simple'] => clarity\n",
      "['For', 'simple', 'clarity'] => ,\n",
      "['For', 'simple', 'clarity', ','] => let\n",
      "['For', 'simple', 'clarity', ',', 'let'] => me\n",
      "['For', 'simple', 'clarity', ',', 'let', 'me'] => repeat\n",
      "['simple', 'clarity'] => ,\n",
      "['simple', 'clarity', ','] => let\n",
      "['simple', 'clarity', ',', 'let'] => me\n",
      "['simple', 'clarity', ',', 'let', 'me'] => repeat\n",
      "['clarity', ','] => let\n",
      "['clarity', ',', 'let'] => me\n",
      "['clarity', ',', 'let', 'me'] => repeat\n",
      "[',', 'let'] => me\n",
      "[',', 'let', 'me'] => repeat\n",
      "['let', 'me'] => repeat\n",
      "['Some', 'wish', 'for', 'cyber', 'safety', ',', 'which', 'they', 'will', 'not', 'get', '.']\n",
      "['Some', 'wish'] => for\n",
      "['Some', 'wish', 'for'] => cyber\n",
      "['Some', 'wish', 'for', 'cyber'] => safety\n",
      "['Some', 'wish', 'for', 'cyber', 'safety'] => ,\n",
      "['Some', 'wish', 'for', 'cyber', 'safety', ','] => which\n",
      "['wish', 'for'] => cyber\n",
      "['wish', 'for', 'cyber'] => safety\n",
      "['wish', 'for', 'cyber', 'safety'] => ,\n",
      "['wish', 'for', 'cyber', 'safety', ','] => which\n",
      "['for', 'cyber'] => safety\n",
      "['for', 'cyber', 'safety'] => ,\n",
      "['for', 'cyber', 'safety', ','] => which\n",
      "['cyber', 'safety'] => ,\n",
      "['cyber', 'safety', ','] => which\n",
      "['safety', ','] => which\n",
      "['Others', 'wish', 'for', 'cyber', 'order', ',', 'which', 'they', 'will', 'not', 'get', '.']\n",
      "['Others', 'wish'] => for\n",
      "['Others', 'wish', 'for'] => cyber\n",
      "['Others', 'wish', 'for', 'cyber'] => order\n",
      "['Others', 'wish', 'for', 'cyber', 'order'] => ,\n",
      "['Others', 'wish', 'for', 'cyber', 'order', ','] => which\n",
      "['wish', 'for'] => cyber\n",
      "['wish', 'for', 'cyber'] => order\n",
      "['wish', 'for', 'cyber', 'order'] => ,\n",
      "['wish', 'for', 'cyber', 'order', ','] => which\n",
      "['for', 'cyber'] => order\n",
      "['for', 'cyber', 'order'] => ,\n",
      "['for', 'cyber', 'order', ','] => which\n",
      "['cyber', 'order'] => ,\n",
      "['cyber', 'order', ','] => which\n",
      "['order', ','] => which\n",
      "['Some', 'have', 'the', 'eye', 'to', 'discern', 'cyber', 'policies', 'that', 'are', '``', 'the', 'least', 'worst', 'thing', ';', \"''\", 'may', 'they', 'fill', 'the', 'vacuum', 'of', 'wishful', 'thinking', '.']\n",
      "['Some', 'have'] => the\n",
      "['Some', 'have', 'the'] => eye\n",
      "['Some', 'have', 'the', 'eye'] => to\n",
      "['Some', 'have', 'the', 'eye', 'to'] => discern\n",
      "['Some', 'have', 'the', 'eye', 'to', 'discern'] => cyber\n",
      "['have', 'the'] => eye\n",
      "['have', 'the', 'eye'] => to\n",
      "['have', 'the', 'eye', 'to'] => discern\n",
      "['have', 'the', 'eye', 'to', 'discern'] => cyber\n",
      "['the', 'eye'] => to\n",
      "['the', 'eye', 'to'] => discern\n",
      "['the', 'eye', 'to', 'discern'] => cyber\n",
      "['eye', 'to'] => discern\n",
      "['eye', 'to', 'discern'] => cyber\n",
      "['to', 'discern'] => cyber\n",
      "['There', 'are', 'three', 'professions', 'that', 'beat', 'their', 'practitioners', 'into', 'a', 'state', 'of', 'humility', ':', 'farming', ',', 'weather', 'forecasting', ',', 'and', 'cyber', 'security', '.']\n",
      "['There', 'are'] => three\n",
      "['There', 'are', 'three'] => professions\n",
      "['There', 'are', 'three', 'professions'] => that\n",
      "['There', 'are', 'three', 'professions', 'that'] => beat\n",
      "['There', 'are', 'three', 'professions', 'that', 'beat'] => their\n",
      "['are', 'three'] => professions\n",
      "['are', 'three', 'professions'] => that\n",
      "['are', 'three', 'professions', 'that'] => beat\n",
      "['are', 'three', 'professions', 'that', 'beat'] => their\n",
      "['three', 'professions'] => that\n",
      "['three', 'professions', 'that'] => beat\n",
      "['three', 'professions', 'that', 'beat'] => their\n",
      "['professions', 'that'] => beat\n",
      "['professions', 'that', 'beat'] => their\n",
      "['that', 'beat'] => their\n",
      "['I', 'practice', 'two', 'of', 'those', ',', 'and', ',', 'as', 'such', ',', 'let', 'me', 'assure', 'you', 'that', 'the', 'recommendations', 'which', 'follow', 'are', 'presented', 'in', 'all', 'humility', '.']\n",
      "['I', 'practice'] => two\n",
      "['I', 'practice', 'two'] => of\n",
      "['I', 'practice', 'two', 'of'] => those\n",
      "['I', 'practice', 'two', 'of', 'those'] => ,\n",
      "['I', 'practice', 'two', 'of', 'those', ','] => and\n",
      "['practice', 'two'] => of\n",
      "['practice', 'two', 'of'] => those\n",
      "['practice', 'two', 'of', 'those'] => ,\n",
      "['practice', 'two', 'of', 'those', ','] => and\n",
      "['two', 'of'] => those\n",
      "['two', 'of', 'those'] => ,\n",
      "['two', 'of', 'those', ','] => and\n",
      "['of', 'those'] => ,\n",
      "['of', 'those', ','] => and\n",
      "['those', ','] => and\n",
      "['Humility', 'does', 'not', 'mean', 'timidity', '.']\n",
      "['Humility', 'does'] => not\n",
      "['Humility', 'does', 'not'] => mean\n",
      "['Humility', 'does', 'not', 'mean'] => timidity\n",
      "['Humility', 'does', 'not', 'mean', 'timidity'] => .\n",
      "['does', 'not'] => mean\n",
      "['does', 'not', 'mean'] => timidity\n",
      "['does', 'not', 'mean', 'timidity'] => .\n",
      "['not', 'mean'] => timidity\n",
      "['not', 'mean', 'timidity'] => .\n",
      "['mean', 'timidity'] => .\n",
      "['Rather', ',', 'it', 'means', 'that', 'when', 'a', 'strongly', 'held', 'belief', 'is', 'proven', 'wrong', ',', 'that', 'the', 'humble', 'person', 'changes', 'their', 'mind', '.']\n",
      "['Rather', ','] => it\n",
      "['Rather', ',', 'it'] => means\n",
      "['Rather', ',', 'it', 'means'] => that\n",
      "['Rather', ',', 'it', 'means', 'that'] => when\n",
      "['Rather', ',', 'it', 'means', 'that', 'when'] => a\n",
      "[',', 'it'] => means\n",
      "[',', 'it', 'means'] => that\n",
      "[',', 'it', 'means', 'that'] => when\n",
      "[',', 'it', 'means', 'that', 'when'] => a\n",
      "['it', 'means'] => that\n",
      "['it', 'means', 'that'] => when\n",
      "['it', 'means', 'that', 'when'] => a\n",
      "['means', 'that'] => when\n",
      "['means', 'that', 'when'] => a\n",
      "['that', 'when'] => a\n",
      "['I', 'expect', 'that', 'my', 'proposals', 'will', 'result', 'in', 'considerable', 'push-back', ',', 'and', 'changing', 'my', 'mind', 'may', 'well', 'follow', '.']\n",
      "['I', 'expect'] => that\n",
      "['I', 'expect', 'that'] => my\n",
      "['I', 'expect', 'that', 'my'] => proposals\n",
      "['I', 'expect', 'that', 'my', 'proposals'] => will\n",
      "['I', 'expect', 'that', 'my', 'proposals', 'will'] => result\n",
      "['expect', 'that'] => my\n",
      "['expect', 'that', 'my'] => proposals\n",
      "['expect', 'that', 'my', 'proposals'] => will\n",
      "['expect', 'that', 'my', 'proposals', 'will'] => result\n",
      "['that', 'my'] => proposals\n",
      "['that', 'my', 'proposals'] => will\n",
      "['that', 'my', 'proposals', 'will'] => result\n",
      "['my', 'proposals'] => will\n",
      "['my', 'proposals', 'will'] => result\n",
      "['proposals', 'will'] => result\n",
      "['Though', 'I', 'will', 'say', 'it', 'again', 'later', ',', 'this', 'speech', 'is', 'me', 'talking', 'for', 'myself', '.']\n",
      "['Though', 'I'] => will\n",
      "['Though', 'I', 'will'] => say\n",
      "['Though', 'I', 'will', 'say'] => it\n",
      "['Though', 'I', 'will', 'say', 'it'] => again\n",
      "['Though', 'I', 'will', 'say', 'it', 'again'] => later\n",
      "['I', 'will'] => say\n",
      "['I', 'will', 'say'] => it\n",
      "['I', 'will', 'say', 'it'] => again\n",
      "['I', 'will', 'say', 'it', 'again'] => later\n",
      "['will', 'say'] => it\n",
      "['will', 'say', 'it'] => again\n",
      "['will', 'say', 'it', 'again'] => later\n",
      "['say', 'it'] => again\n",
      "['say', 'it', 'again'] => later\n",
      "['it', 'again'] => later\n",
      "['As', 'if', 'it', 'needed', 'saying', ',', 'cyber', 'security', 'is', 'now', 'a', 'riveting', 'concern', ',', 'a', 'top', 'issue', 'in', 'many', 'venues', 'more', 'important', 'than', 'this', 'one', '.']\n",
      "['As', 'if'] => it\n",
      "['As', 'if', 'it'] => needed\n",
      "['As', 'if', 'it', 'needed'] => saying\n",
      "['As', 'if', 'it', 'needed', 'saying'] => ,\n",
      "['As', 'if', 'it', 'needed', 'saying', ','] => cyber\n",
      "['if', 'it'] => needed\n",
      "['if', 'it', 'needed'] => saying\n",
      "['if', 'it', 'needed', 'saying'] => ,\n",
      "['if', 'it', 'needed', 'saying', ','] => cyber\n",
      "['it', 'needed'] => saying\n",
      "['it', 'needed', 'saying'] => ,\n",
      "['it', 'needed', 'saying', ','] => cyber\n",
      "['needed', 'saying'] => ,\n",
      "['needed', 'saying', ','] => cyber\n",
      "['saying', ','] => cyber\n",
      "['This', 'is', 'not', 'to', 'insult', 'Black', 'Hat', ';', 'rather', 'it', 'is', 'to', 'note', 'that', 'every', 'speaker', ',', 'every', 'writer', ',', 'every', 'practitioner', 'in', 'the', 'field', 'of', 'cyber', 'security', 'who', 'has', 'wished', 'that', 'its', 'topic', ',', 'and', 'us', 'with', 'it', ',', 'were', 'taken', 'seriously', 'has', 'gotten', 'their', 'wish', '.']\n",
      "['This', 'is'] => not\n",
      "['This', 'is', 'not'] => to\n",
      "['This', 'is', 'not', 'to'] => insult\n",
      "['This', 'is', 'not', 'to', 'insult'] => Black\n",
      "['This', 'is', 'not', 'to', 'insult', 'Black'] => Hat\n",
      "['is', 'not'] => to\n",
      "['is', 'not', 'to'] => insult\n",
      "['is', 'not', 'to', 'insult'] => Black\n",
      "['is', 'not', 'to', 'insult', 'Black'] => Hat\n",
      "['not', 'to'] => insult\n",
      "['not', 'to', 'insult'] => Black\n",
      "['not', 'to', 'insult', 'Black'] => Hat\n",
      "['to', 'insult'] => Black\n",
      "['to', 'insult', 'Black'] => Hat\n",
      "['insult', 'Black'] => Hat\n",
      "['Cyber', 'security', '*', 'is', '*', 'being', 'taken', 'seriously', ',', 'which', ',', 'as', 'you', 'well', 'know', 'is', 'not', 'the', 'same', 'as', 'being', 'taken', 'usefully', ',', 'coherently', ',', 'or', 'lastingly', '.']\n",
      "['Cyber', 'security'] => *\n",
      "['Cyber', 'security', '*'] => is\n",
      "['Cyber', 'security', '*', 'is'] => *\n",
      "['Cyber', 'security', '*', 'is', '*'] => being\n",
      "['Cyber', 'security', '*', 'is', '*', 'being'] => taken\n",
      "['security', '*'] => is\n",
      "['security', '*', 'is'] => *\n",
      "['security', '*', 'is', '*'] => being\n",
      "['security', '*', 'is', '*', 'being'] => taken\n",
      "['*', 'is'] => *\n",
      "['*', 'is', '*'] => being\n",
      "['*', 'is', '*', 'being'] => taken\n",
      "['is', '*'] => being\n",
      "['is', '*', 'being'] => taken\n",
      "['*', 'being'] => taken\n",
      "['Whether', 'we', 'are', 'talking', 'about', 'laws', 'like', 'the', 'Digital', 'Millenium', 'Copyright', 'Act', 'or', 'the', 'Computer', 'Fraud', 'and', 'Abuse', 'Act', ',', 'or', 'the', 'non-lawmaking', 'but', 'perhaps', 'even', 'more', 'significant', 'actions', 'that', 'the', 'Executive', 'agencies', 'are', 'undertaking', ',', '``', 'we', \"''\", 'and', 'the', 'cyber', 'security', 'issue', 'have', 'never', 'been', 'more', 'at', 'the', 'forefront', 'of', 'policy', '.']\n",
      "['Whether', 'we'] => are\n",
      "['Whether', 'we', 'are'] => talking\n",
      "['Whether', 'we', 'are', 'talking'] => about\n",
      "['Whether', 'we', 'are', 'talking', 'about'] => laws\n",
      "['Whether', 'we', 'are', 'talking', 'about', 'laws'] => like\n",
      "['we', 'are'] => talking\n",
      "['we', 'are', 'talking'] => about\n",
      "['we', 'are', 'talking', 'about'] => laws\n",
      "['we', 'are', 'talking', 'about', 'laws'] => like\n",
      "['are', 'talking'] => about\n",
      "['are', 'talking', 'about'] => laws\n",
      "['are', 'talking', 'about', 'laws'] => like\n",
      "['talking', 'about'] => laws\n",
      "['talking', 'about', 'laws'] => like\n",
      "['about', 'laws'] => like\n",
      "['And', 'you', 'ai', \"n't\", 'seen', 'nothing', 'yet', '.']\n",
      "['And', 'you'] => ai\n",
      "['And', 'you', 'ai'] => n't\n",
      "['And', 'you', 'ai', \"n't\"] => seen\n",
      "['And', 'you', 'ai', \"n't\", 'seen'] => nothing\n",
      "['And', 'you', 'ai', \"n't\", 'seen', 'nothing'] => yet\n",
      "['you', 'ai'] => n't\n",
      "['you', 'ai', \"n't\"] => seen\n",
      "['you', 'ai', \"n't\", 'seen'] => nothing\n",
      "['you', 'ai', \"n't\", 'seen', 'nothing'] => yet\n",
      "['ai', \"n't\"] => seen\n",
      "['ai', \"n't\", 'seen'] => nothing\n",
      "['ai', \"n't\", 'seen', 'nothing'] => yet\n",
      "[\"n't\", 'seen'] => nothing\n",
      "[\"n't\", 'seen', 'nothing'] => yet\n",
      "['seen', 'nothing'] => yet\n",
      "['I', 'wish', 'that', 'I', 'could', 'tell', 'you', 'that', 'it', 'is', 'still', 'possible', 'for', 'one', 'person', 'to', 'hold', 'the', 'big', 'picture', 'firmly', 'in', 'their', 'mind', \"'s\", 'eye', ',', 'to', 'track', 'everything', 'important', 'that', 'is', 'going', 'on', 'in', 'our', 'field', ',', 'to', 'make', 'few', 'if', 'any', 'sins', 'of', 'omission', '.']\n",
      "['I', 'wish'] => that\n",
      "['I', 'wish', 'that'] => I\n",
      "['I', 'wish', 'that', 'I'] => could\n",
      "['I', 'wish', 'that', 'I', 'could'] => tell\n",
      "['I', 'wish', 'that', 'I', 'could', 'tell'] => you\n",
      "['wish', 'that'] => I\n",
      "['wish', 'that', 'I'] => could\n",
      "['wish', 'that', 'I', 'could'] => tell\n",
      "['wish', 'that', 'I', 'could', 'tell'] => you\n",
      "['that', 'I'] => could\n",
      "['that', 'I', 'could'] => tell\n",
      "['that', 'I', 'could', 'tell'] => you\n",
      "['I', 'could'] => tell\n",
      "['I', 'could', 'tell'] => you\n",
      "['could', 'tell'] => you\n",
      "['It', 'is', 'not', 'possible', ';', 'that', 'phase', 'passed', 'sometime', 'in', 'the', 'last', 'six', 'years', '.']\n",
      "['It', 'is'] => not\n",
      "['It', 'is', 'not'] => possible\n",
      "['It', 'is', 'not', 'possible'] => ;\n",
      "['It', 'is', 'not', 'possible', ';'] => that\n",
      "['It', 'is', 'not', 'possible', ';', 'that'] => phase\n",
      "['is', 'not'] => possible\n",
      "['is', 'not', 'possible'] => ;\n",
      "['is', 'not', 'possible', ';'] => that\n",
      "['is', 'not', 'possible', ';', 'that'] => phase\n",
      "['not', 'possible'] => ;\n",
      "['not', 'possible', ';'] => that\n",
      "['not', 'possible', ';', 'that'] => phase\n",
      "['possible', ';'] => that\n",
      "['possible', ';', 'that'] => phase\n",
      "[';', 'that'] => phase\n",
      "['I', 'have', 'certainly', 'tried', 'to', 'keep', 'up', 'but', 'I', 'would', 'be', 'less', 'than', 'candid', 'if', 'I', 'were', 'not', 'to', 'say', 'that', 'I', 'know', 'that', 'I', 'am', 'not', 'keeping', 'up', ',', 'not', 'even', 'keeping', 'up', 'with', 'what', 'is', 'going', 'on', 'in', 'my', 'own', 'country', 'much', 'less', 'all', 'countries', '.']\n",
      "['I', 'have'] => certainly\n",
      "['I', 'have', 'certainly'] => tried\n",
      "['I', 'have', 'certainly', 'tried'] => to\n",
      "['I', 'have', 'certainly', 'tried', 'to'] => keep\n",
      "['I', 'have', 'certainly', 'tried', 'to', 'keep'] => up\n",
      "['have', 'certainly'] => tried\n",
      "['have', 'certainly', 'tried'] => to\n",
      "['have', 'certainly', 'tried', 'to'] => keep\n",
      "['have', 'certainly', 'tried', 'to', 'keep'] => up\n",
      "['certainly', 'tried'] => to\n",
      "['certainly', 'tried', 'to'] => keep\n",
      "['certainly', 'tried', 'to', 'keep'] => up\n",
      "['tried', 'to'] => keep\n",
      "['tried', 'to', 'keep'] => up\n",
      "['to', 'keep'] => up\n",
      "['Not', 'only', 'has', 'cybersecurity', 'reached', 'the', 'highest', 'levels', 'of', 'attention', ',', 'it', 'has', 'spread', 'into', 'nearly', 'every', 'corner', '.']\n",
      "['Not', 'only'] => has\n",
      "['Not', 'only', 'has'] => cybersecurity\n",
      "['Not', 'only', 'has', 'cybersecurity'] => reached\n",
      "['Not', 'only', 'has', 'cybersecurity', 'reached'] => the\n",
      "['Not', 'only', 'has', 'cybersecurity', 'reached', 'the'] => highest\n",
      "['only', 'has'] => cybersecurity\n",
      "['only', 'has', 'cybersecurity'] => reached\n",
      "['only', 'has', 'cybersecurity', 'reached'] => the\n",
      "['only', 'has', 'cybersecurity', 'reached', 'the'] => highest\n",
      "['has', 'cybersecurity'] => reached\n",
      "['has', 'cybersecurity', 'reached'] => the\n",
      "['has', 'cybersecurity', 'reached', 'the'] => highest\n",
      "['cybersecurity', 'reached'] => the\n",
      "['cybersecurity', 'reached', 'the'] => highest\n",
      "['reached', 'the'] => highest\n",
      "['If', 'area', 'is', 'the', 'product', 'of', 'height', 'and', 'width', ',', 'then', 'the', 'footprint', 'of', 'cybersecurity', 'has', 'surpassed', 'the', 'grasp', 'of', 'any', 'one', 'of', 'us', '.']\n",
      "['If', 'area'] => is\n",
      "['If', 'area', 'is'] => the\n",
      "['If', 'area', 'is', 'the'] => product\n",
      "['If', 'area', 'is', 'the', 'product'] => of\n",
      "['If', 'area', 'is', 'the', 'product', 'of'] => height\n",
      "['area', 'is'] => the\n",
      "['area', 'is', 'the'] => product\n",
      "['area', 'is', 'the', 'product'] => of\n",
      "['area', 'is', 'the', 'product', 'of'] => height\n",
      "['is', 'the'] => product\n",
      "['is', 'the', 'product'] => of\n",
      "['is', 'the', 'product', 'of'] => height\n",
      "['the', 'product'] => of\n",
      "['the', 'product', 'of'] => height\n",
      "['product', 'of'] => height\n",
      "['The', 'rate', 'of', 'technological', 'change', 'is', 'certainly', 'a', 'part', 'of', 'it', '.']\n",
      "['The', 'rate'] => of\n",
      "['The', 'rate', 'of'] => technological\n",
      "['The', 'rate', 'of', 'technological'] => change\n",
      "['The', 'rate', 'of', 'technological', 'change'] => is\n",
      "['The', 'rate', 'of', 'technological', 'change', 'is'] => certainly\n",
      "['rate', 'of'] => technological\n",
      "['rate', 'of', 'technological'] => change\n",
      "['rate', 'of', 'technological', 'change'] => is\n",
      "['rate', 'of', 'technological', 'change', 'is'] => certainly\n",
      "['of', 'technological'] => change\n",
      "['of', 'technological', 'change'] => is\n",
      "['of', 'technological', 'change', 'is'] => certainly\n",
      "['technological', 'change'] => is\n",
      "['technological', 'change', 'is'] => certainly\n",
      "['change', 'is'] => certainly\n",
      "['When', 'younger', 'people', 'ask', 'my', 'advice', 'on', 'what', 'they', 'should', 'do', 'or', 'study', 'to', 'make', 'a', 'career', 'in', 'cyber', 'security', ',', 'I', 'can', 'only', 'advise', 'specialization', '.']\n",
      "['When', 'younger'] => people\n",
      "['When', 'younger', 'people'] => ask\n",
      "['When', 'younger', 'people', 'ask'] => my\n",
      "['When', 'younger', 'people', 'ask', 'my'] => advice\n",
      "['When', 'younger', 'people', 'ask', 'my', 'advice'] => on\n",
      "['younger', 'people'] => ask\n",
      "['younger', 'people', 'ask'] => my\n",
      "['younger', 'people', 'ask', 'my'] => advice\n",
      "['younger', 'people', 'ask', 'my', 'advice'] => on\n",
      "['people', 'ask'] => my\n",
      "['people', 'ask', 'my'] => advice\n",
      "['people', 'ask', 'my', 'advice'] => on\n",
      "['ask', 'my'] => advice\n",
      "['ask', 'my', 'advice'] => on\n",
      "['my', 'advice'] => on\n",
      "['Those', 'of', 'us', 'who', 'were', 'in', 'the', 'game', 'early', 'enough', 'and', 'who', 'have', 'managed', 'to', 'retain', 'an', 'over-arching', 'generalist', 'knowledge', 'ca', \"n't\", 'be', 'replaced', 'very', 'easily', 'because', 'while', 'absorbing', 'most', 'new', 'information', 'most', 'of', 'the', 'time', 'may', 'have', 'been', 'possible', 'when', 'we', 'began', 'practice', ',', 'no', 'person', 'starting', 'from', 'scratch', 'can', 'do', 'that', 'now', '.']\n",
      "['Those', 'of'] => us\n",
      "['Those', 'of', 'us'] => who\n",
      "['Those', 'of', 'us', 'who'] => were\n",
      "['Those', 'of', 'us', 'who', 'were'] => in\n",
      "['Those', 'of', 'us', 'who', 'were', 'in'] => the\n",
      "['of', 'us'] => who\n",
      "['of', 'us', 'who'] => were\n",
      "['of', 'us', 'who', 'were'] => in\n",
      "['of', 'us', 'who', 'were', 'in'] => the\n",
      "['us', 'who'] => were\n",
      "['us', 'who', 'were'] => in\n",
      "['us', 'who', 'were', 'in'] => the\n",
      "['who', 'were'] => in\n",
      "['who', 'were', 'in'] => the\n",
      "['were', 'in'] => the\n",
      "['Serial', 'specialization', 'is', 'now', 'all', 'that', 'can', 'be', 'done', 'in', 'any', 'practical', 'way', '.']\n",
      "['Serial', 'specialization'] => is\n",
      "['Serial', 'specialization', 'is'] => now\n",
      "['Serial', 'specialization', 'is', 'now'] => all\n",
      "['Serial', 'specialization', 'is', 'now', 'all'] => that\n",
      "['Serial', 'specialization', 'is', 'now', 'all', 'that'] => can\n",
      "['specialization', 'is'] => now\n",
      "['specialization', 'is', 'now'] => all\n",
      "['specialization', 'is', 'now', 'all'] => that\n",
      "['specialization', 'is', 'now', 'all', 'that'] => can\n",
      "['is', 'now'] => all\n",
      "['is', 'now', 'all'] => that\n",
      "['is', 'now', 'all', 'that'] => can\n",
      "['now', 'all'] => that\n",
      "['now', 'all', 'that'] => can\n",
      "['all', 'that'] => can\n",
      "['Just', 'looking', 'at', 'the', 'Black', 'Hat', 'program', 'will', 'confirm', 'that', 'being', 'really', 'good', 'at', 'any', 'one', 'of', 'the', 'many', 'topics', 'presented', 'here', 'all', 'but', 'requires', 'shutting', 'out', 'the', 'demands', 'of', 'being', 'good', 'at', 'any', 'others', '.']\n",
      "['Just', 'looking'] => at\n",
      "['Just', 'looking', 'at'] => the\n",
      "['Just', 'looking', 'at', 'the'] => Black\n",
      "['Just', 'looking', 'at', 'the', 'Black'] => Hat\n",
      "['Just', 'looking', 'at', 'the', 'Black', 'Hat'] => program\n",
      "['looking', 'at'] => the\n",
      "['looking', 'at', 'the'] => Black\n",
      "['looking', 'at', 'the', 'Black'] => Hat\n",
      "['looking', 'at', 'the', 'Black', 'Hat'] => program\n",
      "['at', 'the'] => Black\n",
      "['at', 'the', 'Black'] => Hat\n",
      "['at', 'the', 'Black', 'Hat'] => program\n",
      "['the', 'Black'] => Hat\n",
      "['the', 'Black', 'Hat'] => program\n",
      "['Black', 'Hat'] => program\n",
      "['Why', 'does', 'that', 'matter', '?']\n",
      "['Why', 'does'] => that\n",
      "['Why', 'does', 'that'] => matter\n",
      "['Why', 'does', 'that', 'matter'] => ?\n",
      "['does', 'that'] => matter\n",
      "['does', 'that', 'matter'] => ?\n",
      "['that', 'matter'] => ?\n",
      "['Speaking', 'for', 'myself', ',', 'I', 'am', 'not', 'interested', 'in', 'the', 'advantages', 'or', 'disadvantages', 'of', 'some', 'bit', 'of', 'technology', 'unless', 'I', 'can', 'grasp', 'how', 'it', 'is', 'that', 'that', 'technology', 'works', '.']\n",
      "['Speaking', 'for'] => myself\n",
      "['Speaking', 'for', 'myself'] => ,\n",
      "['Speaking', 'for', 'myself', ','] => I\n",
      "['Speaking', 'for', 'myself', ',', 'I'] => am\n",
      "['Speaking', 'for', 'myself', ',', 'I', 'am'] => not\n",
      "['for', 'myself'] => ,\n",
      "['for', 'myself', ','] => I\n",
      "['for', 'myself', ',', 'I'] => am\n",
      "['for', 'myself', ',', 'I', 'am'] => not\n",
      "['myself', ','] => I\n",
      "['myself', ',', 'I'] => am\n",
      "['myself', ',', 'I', 'am'] => not\n",
      "[',', 'I'] => am\n",
      "[',', 'I', 'am'] => not\n",
      "['I', 'am'] => not\n",
      "['Whenever', 'I', 'see', 'marketing', 'material', 'that', 'tells', 'me', 'all', 'the', 'good', 'things', 'that', 'adopting', 'this', 'or', 'that', 'technology', 'makes', 'possible', ',', 'I', 'remember', 'what', 'George', 'Santayana', 'said', ',', 'that', '``', 'Scepticism', 'is', 'the', 'chastity', 'of', 'the', 'intellect', ';', 'it', 'is', 'shameful', 'to', 'give', 'it', 'up', 'too', 'soon', ',', 'or', 'to', 'the', 'first', 'comer', '.', \"''\"]\n",
      "['Whenever', 'I'] => see\n",
      "['Whenever', 'I', 'see'] => marketing\n",
      "['Whenever', 'I', 'see', 'marketing'] => material\n",
      "['Whenever', 'I', 'see', 'marketing', 'material'] => that\n",
      "['Whenever', 'I', 'see', 'marketing', 'material', 'that'] => tells\n",
      "['I', 'see'] => marketing\n",
      "['I', 'see', 'marketing'] => material\n",
      "['I', 'see', 'marketing', 'material'] => that\n",
      "['I', 'see', 'marketing', 'material', 'that'] => tells\n",
      "['see', 'marketing'] => material\n",
      "['see', 'marketing', 'material'] => that\n",
      "['see', 'marketing', 'material', 'that'] => tells\n",
      "['marketing', 'material'] => that\n",
      "['marketing', 'material', 'that'] => tells\n",
      "['material', 'that'] => tells\n",
      "['I', 'suspect', 'that', 'a', 'majority', 'of', 'you', 'have', 'similar', 'skepticism', '--', '``', 'It', \"'s\", 'magic', '!', \"''\"]\n",
      "['I', 'suspect'] => that\n",
      "['I', 'suspect', 'that'] => a\n",
      "['I', 'suspect', 'that', 'a'] => majority\n",
      "['I', 'suspect', 'that', 'a', 'majority'] => of\n",
      "['I', 'suspect', 'that', 'a', 'majority', 'of'] => you\n",
      "['suspect', 'that'] => a\n",
      "['suspect', 'that', 'a'] => majority\n",
      "['suspect', 'that', 'a', 'majority'] => of\n",
      "['suspect', 'that', 'a', 'majority', 'of'] => you\n",
      "['that', 'a'] => majority\n",
      "['that', 'a', 'majority'] => of\n",
      "['that', 'a', 'majority', 'of'] => you\n",
      "['a', 'majority'] => of\n",
      "['a', 'majority', 'of'] => you\n",
      "['majority', 'of'] => you\n",
      "['is', 'not', 'the', 'answer', 'a', 'security', 'person', 'will', 'ever', 'accept', '.']\n",
      "['is', 'not'] => the\n",
      "['is', 'not', 'the'] => answer\n",
      "['is', 'not', 'the', 'answer'] => a\n",
      "['is', 'not', 'the', 'answer', 'a'] => security\n",
      "['is', 'not', 'the', 'answer', 'a', 'security'] => person\n",
      "['not', 'the'] => answer\n",
      "['not', 'the', 'answer'] => a\n",
      "['not', 'the', 'answer', 'a'] => security\n",
      "['not', 'the', 'answer', 'a', 'security'] => person\n",
      "['the', 'answer'] => a\n",
      "['the', 'answer', 'a'] => security\n",
      "['the', 'answer', 'a', 'security'] => person\n",
      "['answer', 'a'] => security\n",
      "['answer', 'a', 'security'] => person\n",
      "['a', 'security'] => person\n",
      "['By', 'and', 'large', ',', 'I', 'can', 'tell', '*', 'what', '*', 'something', 'is', 'good', 'for', 'once', 'I', 'know', '*', 'how', '*', 'it', 'works', '.']\n",
      "['By', 'and'] => large\n",
      "['By', 'and', 'large'] => ,\n",
      "['By', 'and', 'large', ','] => I\n",
      "['By', 'and', 'large', ',', 'I'] => can\n",
      "['By', 'and', 'large', ',', 'I', 'can'] => tell\n",
      "['and', 'large'] => ,\n",
      "['and', 'large', ','] => I\n",
      "['and', 'large', ',', 'I'] => can\n",
      "['and', 'large', ',', 'I', 'can'] => tell\n",
      "['large', ','] => I\n",
      "['large', ',', 'I'] => can\n",
      "['large', ',', 'I', 'can'] => tell\n",
      "[',', 'I'] => can\n",
      "[',', 'I', 'can'] => tell\n",
      "['I', 'can'] => tell\n",
      "['Tell', 'me', 'how', 'it', 'works', 'and', 'then', ',', 'but', 'only', 'then', ',', 'tell', 'me', 'why', 'you', 'have', 'chosen', 'to', 'use', 'those', 'particular', 'mechanisms', 'for', 'the', 'things', 'you', 'have', 'chosen', 'to', 'use', 'them', 'for', '.']\n",
      "['Tell', 'me'] => how\n",
      "['Tell', 'me', 'how'] => it\n",
      "['Tell', 'me', 'how', 'it'] => works\n",
      "['Tell', 'me', 'how', 'it', 'works'] => and\n",
      "['Tell', 'me', 'how', 'it', 'works', 'and'] => then\n",
      "['me', 'how'] => it\n",
      "['me', 'how', 'it'] => works\n",
      "['me', 'how', 'it', 'works'] => and\n",
      "['me', 'how', 'it', 'works', 'and'] => then\n",
      "['how', 'it'] => works\n",
      "['how', 'it', 'works'] => and\n",
      "['how', 'it', 'works', 'and'] => then\n",
      "['it', 'works'] => and\n",
      "['it', 'works', 'and'] => then\n",
      "['works', 'and'] => then\n",
      "['Part', 'of', 'my', 'feeling', 'stems', 'from', 'a', 'long-held', 'and', 'well-substantiated', 'belief', 'that', 'all', 'cyber', 'security', 'technology', 'is', 'dual', 'use', '.']\n",
      "['Part', 'of'] => my\n",
      "['Part', 'of', 'my'] => feeling\n",
      "['Part', 'of', 'my', 'feeling'] => stems\n",
      "['Part', 'of', 'my', 'feeling', 'stems'] => from\n",
      "['Part', 'of', 'my', 'feeling', 'stems', 'from'] => a\n",
      "['of', 'my'] => feeling\n",
      "['of', 'my', 'feeling'] => stems\n",
      "['of', 'my', 'feeling', 'stems'] => from\n",
      "['of', 'my', 'feeling', 'stems', 'from'] => a\n",
      "['my', 'feeling'] => stems\n",
      "['my', 'feeling', 'stems'] => from\n",
      "['my', 'feeling', 'stems', 'from'] => a\n",
      "['feeling', 'stems'] => from\n",
      "['feeling', 'stems', 'from'] => a\n",
      "['stems', 'from'] => a\n",
      "['Perhaps', 'dual', 'use', 'is', 'a', 'truism', 'for', 'any', 'and', 'all', 'tools', 'from', 'the', 'scalpel', 'to', 'the', 'hammer', 'to', 'the', 'gas', 'can', '--', 'they', 'can', 'be', 'used', 'for', 'good', 'or', 'ill', '--', 'but', 'I', 'know', 'that', 'dual', 'use', 'is', 'inherent', 'in', 'cyber', 'security', 'tools', '.']\n",
      "['Perhaps', 'dual'] => use\n",
      "['Perhaps', 'dual', 'use'] => is\n",
      "['Perhaps', 'dual', 'use', 'is'] => a\n",
      "['Perhaps', 'dual', 'use', 'is', 'a'] => truism\n",
      "['Perhaps', 'dual', 'use', 'is', 'a', 'truism'] => for\n",
      "['dual', 'use'] => is\n",
      "['dual', 'use', 'is'] => a\n",
      "['dual', 'use', 'is', 'a'] => truism\n",
      "['dual', 'use', 'is', 'a', 'truism'] => for\n",
      "['use', 'is'] => a\n",
      "['use', 'is', 'a'] => truism\n",
      "['use', 'is', 'a', 'truism'] => for\n",
      "['is', 'a'] => truism\n",
      "['is', 'a', 'truism'] => for\n",
      "['a', 'truism'] => for\n",
      "['If', 'your', 'definition', 'of', '``', 'tool', \"''\", 'is', 'wide', 'enough', ',', 'I', 'suggest', 'that', 'the', 'cyber', 'security', 'tool-set', 'favors', 'offense', 'these', 'days', '.']\n",
      "['If', 'your'] => definition\n",
      "['If', 'your', 'definition'] => of\n",
      "['If', 'your', 'definition', 'of'] => ``\n",
      "['If', 'your', 'definition', 'of', '``'] => tool\n",
      "['If', 'your', 'definition', 'of', '``', 'tool'] => ''\n",
      "['your', 'definition'] => of\n",
      "['your', 'definition', 'of'] => ``\n",
      "['your', 'definition', 'of', '``'] => tool\n",
      "['your', 'definition', 'of', '``', 'tool'] => ''\n",
      "['definition', 'of'] => ``\n",
      "['definition', 'of', '``'] => tool\n",
      "['definition', 'of', '``', 'tool'] => ''\n",
      "['of', '``'] => tool\n",
      "['of', '``', 'tool'] => ''\n",
      "['``', 'tool'] => ''\n",
      "['Chris', 'Inglis', ',', 'recently', 'retired', 'NSA', 'Deputy', 'Director', ',', 'remarked', 'that', 'if', 'we', 'were', 'to', 'score', 'cyber', 'the', 'way', 'we', 'score', 'soccer', ',', 'the', 'tally', 'would', 'be', '462-456', 'twenty', 'minutes', 'into', 'the', 'game', ',', '[', 'CI', ']', 'i.e.', ',', 'all', 'offense', '.']\n",
      "['Chris', 'Inglis'] => ,\n",
      "['Chris', 'Inglis', ','] => recently\n",
      "['Chris', 'Inglis', ',', 'recently'] => retired\n",
      "['Chris', 'Inglis', ',', 'recently', 'retired'] => NSA\n",
      "['Chris', 'Inglis', ',', 'recently', 'retired', 'NSA'] => Deputy\n",
      "['Inglis', ','] => recently\n",
      "['Inglis', ',', 'recently'] => retired\n",
      "['Inglis', ',', 'recently', 'retired'] => NSA\n",
      "['Inglis', ',', 'recently', 'retired', 'NSA'] => Deputy\n",
      "[',', 'recently'] => retired\n",
      "[',', 'recently', 'retired'] => NSA\n",
      "[',', 'recently', 'retired', 'NSA'] => Deputy\n",
      "['recently', 'retired'] => NSA\n",
      "['recently', 'retired', 'NSA'] => Deputy\n",
      "['retired', 'NSA'] => Deputy\n",
      "['I', 'will', 'take', 'his', 'comment', 'as', 'confirming', 'at', 'the', 'highest', 'level', 'not', 'only', 'the', 'dual', 'use', 'nature', 'of', 'cybersecurity', 'but', 'also', 'confirming', 'that', 'offense', 'is', 'where', 'the', 'innovations', 'that', 'only', 'States', 'can', 'afford', 'is', 'going', 'on', '.']\n",
      "['I', 'will'] => take\n",
      "['I', 'will', 'take'] => his\n",
      "['I', 'will', 'take', 'his'] => comment\n",
      "['I', 'will', 'take', 'his', 'comment'] => as\n",
      "['I', 'will', 'take', 'his', 'comment', 'as'] => confirming\n",
      "['will', 'take'] => his\n",
      "['will', 'take', 'his'] => comment\n",
      "['will', 'take', 'his', 'comment'] => as\n",
      "['will', 'take', 'his', 'comment', 'as'] => confirming\n",
      "['take', 'his'] => comment\n",
      "['take', 'his', 'comment'] => as\n",
      "['take', 'his', 'comment', 'as'] => confirming\n",
      "['his', 'comment'] => as\n",
      "['his', 'comment', 'as'] => confirming\n",
      "['comment', 'as'] => confirming\n",
      "['Nevertheless', ',', 'this', 'essay', 'is', 'an', 'outgrowth', 'from', ',', 'an', 'extension', 'of', ',', 'that', 'increasing', 'importance', 'of', 'cybersecurity', '.']\n",
      "['Nevertheless', ','] => this\n",
      "['Nevertheless', ',', 'this'] => essay\n",
      "['Nevertheless', ',', 'this', 'essay'] => is\n",
      "['Nevertheless', ',', 'this', 'essay', 'is'] => an\n",
      "['Nevertheless', ',', 'this', 'essay', 'is', 'an'] => outgrowth\n",
      "[',', 'this'] => essay\n",
      "[',', 'this', 'essay'] => is\n",
      "[',', 'this', 'essay', 'is'] => an\n",
      "[',', 'this', 'essay', 'is', 'an'] => outgrowth\n",
      "['this', 'essay'] => is\n",
      "['this', 'essay', 'is'] => an\n",
      "['this', 'essay', 'is', 'an'] => outgrowth\n",
      "['essay', 'is'] => an\n",
      "['essay', 'is', 'an'] => outgrowth\n",
      "['is', 'an'] => outgrowth\n",
      "['With', 'the', 'humility', 'of', 'which', 'I', 'spoke', ',', 'I', 'do', 'not', 'claim', 'that', 'I', 'have', 'the', 'last', 'word', '.']\n",
      "['With', 'the'] => humility\n",
      "['With', 'the', 'humility'] => of\n",
      "['With', 'the', 'humility', 'of'] => which\n",
      "['With', 'the', 'humility', 'of', 'which'] => I\n",
      "['With', 'the', 'humility', 'of', 'which', 'I'] => spoke\n",
      "['the', 'humility'] => of\n",
      "['the', 'humility', 'of'] => which\n",
      "['the', 'humility', 'of', 'which'] => I\n",
      "['the', 'humility', 'of', 'which', 'I'] => spoke\n",
      "['humility', 'of'] => which\n",
      "['humility', 'of', 'which'] => I\n",
      "['humility', 'of', 'which', 'I'] => spoke\n",
      "['of', 'which'] => I\n",
      "['of', 'which', 'I'] => spoke\n",
      "['which', 'I'] => spoke\n",
      "['What', 'I', 'do', 'claim', 'is', 'that', 'when', 'we', 'speak', 'about', 'cybersecurity', 'policy', 'we', 'are', 'no', 'longer', 'engaging', 'in', 'some', 'sort', 'of', 'parlor', 'game', '.']\n",
      "['What', 'I'] => do\n",
      "['What', 'I', 'do'] => claim\n",
      "['What', 'I', 'do', 'claim'] => is\n",
      "['What', 'I', 'do', 'claim', 'is'] => that\n",
      "['What', 'I', 'do', 'claim', 'is', 'that'] => when\n",
      "['I', 'do'] => claim\n",
      "['I', 'do', 'claim'] => is\n",
      "['I', 'do', 'claim', 'is'] => that\n",
      "['I', 'do', 'claim', 'is', 'that'] => when\n",
      "['do', 'claim'] => is\n",
      "['do', 'claim', 'is'] => that\n",
      "['do', 'claim', 'is', 'that'] => when\n",
      "['claim', 'is'] => that\n",
      "['claim', 'is', 'that'] => when\n",
      "['is', 'that'] => when\n",
      "['I', 'claim', 'that', 'policy', 'matters', 'are', 'now', 'the', 'most', 'important', 'matters', ',', 'that', 'once', 'a', 'topic', 'area', ',', 'like', 'cybersecurity', ',', 'becomes', 'interlaced', 'with', 'nearly', 'every', 'aspect', 'of', 'life', 'for', 'nearly', 'everybody', ',', 'the', 'outcome', 'differential', 'between', 'good', 'policies', 'and', 'bad', 'policies', 'broadens', ',', 'and', 'the', 'ease', 'of', 'finding', 'answers', 'falls', '.']\n",
      "['I', 'claim'] => that\n",
      "['I', 'claim', 'that'] => policy\n",
      "['I', 'claim', 'that', 'policy'] => matters\n",
      "['I', 'claim', 'that', 'policy', 'matters'] => are\n",
      "['I', 'claim', 'that', 'policy', 'matters', 'are'] => now\n",
      "['claim', 'that'] => policy\n",
      "['claim', 'that', 'policy'] => matters\n",
      "['claim', 'that', 'policy', 'matters'] => are\n",
      "['claim', 'that', 'policy', 'matters', 'are'] => now\n",
      "['that', 'policy'] => matters\n",
      "['that', 'policy', 'matters'] => are\n",
      "['that', 'policy', 'matters', 'are'] => now\n",
      "['policy', 'matters'] => are\n",
      "['policy', 'matters', 'are'] => now\n",
      "['matters', 'are'] => now\n",
      "['As', 'H.L', '.']\n",
      "['As', 'H.L'] => .\n",
      "['Mencken', 'so', 'trenchantly', 'put', 'it', ',', '``', 'For', 'every', 'complex', 'problem', 'there', 'is', 'a', 'solution', 'that', 'is', 'clear', ',', 'simple', ',', 'and', 'wrong', '.', \"''\"]\n",
      "['Mencken', 'so'] => trenchantly\n",
      "['Mencken', 'so', 'trenchantly'] => put\n",
      "['Mencken', 'so', 'trenchantly', 'put'] => it\n",
      "['Mencken', 'so', 'trenchantly', 'put', 'it'] => ,\n",
      "['Mencken', 'so', 'trenchantly', 'put', 'it', ','] => ``\n",
      "['so', 'trenchantly'] => put\n",
      "['so', 'trenchantly', 'put'] => it\n",
      "['so', 'trenchantly', 'put', 'it'] => ,\n",
      "['so', 'trenchantly', 'put', 'it', ','] => ``\n",
      "['trenchantly', 'put'] => it\n",
      "['trenchantly', 'put', 'it'] => ,\n",
      "['trenchantly', 'put', 'it', ','] => ``\n",
      "['put', 'it'] => ,\n",
      "['put', 'it', ','] => ``\n",
      "['it', ','] => ``\n",
      "['The', 'four', 'verities', 'of', 'government', 'are', 'these', ':', '.']\n",
      "['The', 'four'] => verities\n",
      "['The', 'four', 'verities'] => of\n",
      "['The', 'four', 'verities', 'of'] => government\n",
      "['The', 'four', 'verities', 'of', 'government'] => are\n",
      "['The', 'four', 'verities', 'of', 'government', 'are'] => these\n",
      "['four', 'verities'] => of\n",
      "['four', 'verities', 'of'] => government\n",
      "['four', 'verities', 'of', 'government'] => are\n",
      "['four', 'verities', 'of', 'government', 'are'] => these\n",
      "['verities', 'of'] => government\n",
      "['verities', 'of', 'government'] => are\n",
      "['verities', 'of', 'government', 'are'] => these\n",
      "['of', 'government'] => are\n",
      "['of', 'government', 'are'] => these\n",
      "['government', 'are'] => these\n",
      "['Most', 'important', 'ideas', 'are', 'unappealing', '.']\n",
      "['Most', 'important'] => ideas\n",
      "['Most', 'important', 'ideas'] => are\n",
      "['Most', 'important', 'ideas', 'are'] => unappealing\n",
      "['Most', 'important', 'ideas', 'are', 'unappealing'] => .\n",
      "['important', 'ideas'] => are\n",
      "['important', 'ideas', 'are'] => unappealing\n",
      "['important', 'ideas', 'are', 'unappealing'] => .\n",
      "['ideas', 'are'] => unappealing\n",
      "['ideas', 'are', 'unappealing'] => .\n",
      "['are', 'unappealing'] => .\n",
      "['Most', 'appealing', 'ideas', 'are', 'unimportant', '.']\n",
      "['Most', 'appealing'] => ideas\n",
      "['Most', 'appealing', 'ideas'] => are\n",
      "['Most', 'appealing', 'ideas', 'are'] => unimportant\n",
      "['Most', 'appealing', 'ideas', 'are', 'unimportant'] => .\n",
      "['appealing', 'ideas'] => are\n",
      "['appealing', 'ideas', 'are'] => unimportant\n",
      "['appealing', 'ideas', 'are', 'unimportant'] => .\n",
      "['ideas', 'are'] => unimportant\n",
      "['ideas', 'are', 'unimportant'] => .\n",
      "['are', 'unimportant'] => .\n",
      "['Not', 'every', 'problem', 'has', 'a', 'good', 'solution', '.']\n",
      "['Not', 'every'] => problem\n",
      "['Not', 'every', 'problem'] => has\n",
      "['Not', 'every', 'problem', 'has'] => a\n",
      "['Not', 'every', 'problem', 'has', 'a'] => good\n",
      "['Not', 'every', 'problem', 'has', 'a', 'good'] => solution\n",
      "['every', 'problem'] => has\n",
      "['every', 'problem', 'has'] => a\n",
      "['every', 'problem', 'has', 'a'] => good\n",
      "['every', 'problem', 'has', 'a', 'good'] => solution\n",
      "['problem', 'has'] => a\n",
      "['problem', 'has', 'a'] => good\n",
      "['problem', 'has', 'a', 'good'] => solution\n",
      "['has', 'a'] => good\n",
      "['has', 'a', 'good'] => solution\n",
      "['a', 'good'] => solution\n",
      "['Every', 'solution', 'has', 'side', 'effects']\n",
      "['Every', 'solution'] => has\n",
      "['Every', 'solution', 'has'] => side\n",
      "['Every', 'solution', 'has', 'side'] => effects\n",
      "['solution', 'has'] => side\n",
      "['solution', 'has', 'side'] => effects\n",
      "['has', 'side'] => effects\n"
     ]
    }
   ],
   "source": [
    "from nltk import word_tokenize\n",
    "wordTokenizedSentence=[]\n",
    "for sentence in sentences:\n",
    "    wordTokenizedSentence.append(word_tokenize(sentence))\n",
    "\n",
    "x=[]\n",
    "y=[]\n",
    "for sentence in wordTokenizedSentence:\n",
    "    print(sentence)\n",
    "    for i in range(len(sentence)):\n",
    "        j=i+1\n",
    "        while j <= 5:\n",
    "            try:\n",
    "                y.append(sentence[j])\n",
    "                x.append(sentence[i:j])\n",
    "                j+=1\n",
    "                print(sentence[i:j],'=>',sentence[j])\n",
    "            except:\n",
    "                j+=1\n",
    "                continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "df813312",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([['['],\n",
       "  ['[', 'nominal'],\n",
       "  ['[', 'nominal', 'delivery'],\n",
       "  ['[', 'nominal', 'delivery', 'draft'],\n",
       "  ['[', 'nominal', 'delivery', 'draft', ',']],\n",
       " ['nominal', 'delivery', 'draft', ',', '6'])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:5],y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "368d3b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "emeddingModel=Word2Vec(wordTokenizedSentence, vector_size=15, window=10, min_count=1, workers=4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5e1b12a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.06246194, -0.049209  ,  0.00407102, -0.02026014, -0.04346866,\n",
       "       -0.00748973, -0.0356756 ,  0.06222412, -0.03854244,  0.02709549,\n",
       "        0.00292689,  0.03292041,  0.01779463,  0.06369314,  0.00115686],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emeddingModel.wv['[']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a799eae8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.06246194, -0.049209  ,  0.00407102, -0.02026014, -0.04346866,\n",
       "        -0.00748973, -0.0356756 ,  0.06222412, -0.03854244,  0.02709549,\n",
       "         0.00292689,  0.03292041,  0.01779463,  0.06369314,  0.00115686]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "embeddings_x = []\n",
    "embeddings_y = []\n",
    "\n",
    "for sentence in x:\n",
    "    embeddings = []\n",
    "    for word in sentence:\n",
    "        try:\n",
    "            embeddings.append(emeddingModel.wv[word])  # Get the word2vec embedding\n",
    "        except:\n",
    "            continue\n",
    "    embeddings_x.append(np.array(embeddings))\n",
    "\n",
    "embeddings_x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "58416317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "459 {'that': 1, 'of': 2, 'the': 3, 'is': 4, 'i': 5, 'are': 6, 'it': 7, 'to': 8, 'a': 9, 'not': 10, 'has': 11, 'and': 12, 'will': 13, 'for': 14, 'cyber': 15, 'in': 16, 'my': 17, 'security': 18, 'black': 19, 'me': 20, 'can': 21, 'good': 22, 'as': 23, 'this': 24, 'all': 25, 'be': 26, 'when': 27, 'being': 28, 'tell': 29, 'from': 30, 'cybersecurity': 31, 'which': 32, 'have': 33, 'an': 34, 'you': 35, 'hat': 36, 'were': 37, 'am': 38, 'tool': 39, '6': 40, 'taking': 41, 'discern': 42, 'beat': 43, 'those': 44, 'again': 45, 'laws': 46, 'nothing': 47, 'keep': 48, 'advice': 49, 'works': 50, 'truism': 51, 'nsa': 52, 'claim': 53, 'talk': 54, 'let': 55, 'wish': 56, 'now': 57, 'every': 58, 'about': 59, 'possible': 60, 'use': 61, 'matters': 62, 'ideas': 63, 'do': 64, 'safety': 65, 'order': 66, 'timidity': 67, 'proposals': 68, 'saying': 69, 'insult': 70, 'who': 71, 'we': 72, 'at': 73, 'policy': 74, 'seen': 75, 'could': 76, 'reached': 77, 'product': 78, 'change': 79, 'material': 80, 'majority': 81, 'stems': 82, 'retired': 83, 'comment': 84, 'government': 85, 'unappealing': 86, 'unimportant': 87, 'effects': 88, 'eye': 89, 'humility': 90, 'say': 91, 'talking': 92, 'if': 93, 'or': 94, 'draft': 95, 'professions': 96, 'mean': 97, 'means': 98, 'needed': 99, 'us': 100, 'tried': 101, 'only': 102, 'technological': 103, 'ask': 104, 'matter': 105, 'how': 106, 'marketing': 107, 'answer': 108, 'feeling': 109, 'recently': 110, 'his': 111, 'essay': 112, 'put': 113, 'side': 114, 'what': 115, 'does': 116, 'myself': 117, 'important': 118, 'but': 119, 'any': 120, 'certainly': 121, 'dual': 122, 'problem': 123, \"n't\": 124, 'delivery': 125, 'with': 126, 'clarity': 127, 'they': 128, 'three': 129, 'two': 130, 'people': 131, 'most': 132, 'see': 133, 'large': 134, 'definition': 135, 'take': 136, 'trenchantly': 137, 'solution': 138, 'verities': 139, 'simple': 140, 'some': 141, 'their': 142, 'practice': 143, 'person': 144, 'one': 145, 'know': 146, 'on': 147, 'up': 148, 'area': 149, 'specialization': 150, 'technology': 151, 'ai': 152, 'nominal': 153, 'plaintext': 154, 'been': 155, 'policies': 156, 'may': 157, 'into': 158, 'expect': 159, 'well': 160, 'more': 161, 'taken': 162, 'going': 163, 'nearly': 164, 'then': 165, 'rate': 166, 'younger': 167, 'game': 168, 'looking': 169, 'suspect': 170, 'your': 171, 'offense': 172, 'inglis': 173, 'h': 174, 'l': 175, 'so': 176, 'four': 177, 'appealing': 178, 'speak': 179, 'today': 180, 'while': 181, 'later': 182, 'used': 183, 'get': 184, 'others': 185, 'there': 186, 'follow': 187, 'presented': 188, 'rather': 189, 'held': 190, 'belief': 191, 'wrong': 192, 'mind': 193, 'issue': 194, 'many': 195, 'than': 196, 'field': 197, 'topic': 198, 'seriously': 199, 'like': 200, 'act': 201, 'perhaps': 202, 'even': 203, 'make': 204, 'last': 205, 'would': 206, 'less': 207, 'keeping': 208, 'highest': 209, 'grasp': 210, 'part': 211, 'enough': 212, 'no': 213, 'way': 214, 'why': 215, 'things': 216, 'once': 217, 'chosen': 218, 'tools': 219, 'these': 220, 'score': 221, 'confirming': 222, 'august': 223, '2014': 224, 'realpolitik': 225, 'dan': 226, 'geer': 227, 'morning': 228, 'thank': 229, 'invitation': 230, 'made': 231, 'available': 232, 'organizers': 233, 'questions': 234, 'welcome': 235, 'contact': 236, 'reply': 237, 'repeat': 238, 'abstract': 239, 'power': 240, 'exists': 241, 'least': 242, 'worst': 243, 'thing': 244, 'fill': 245, 'vacuum': 246, 'wishful': 247, 'thinking': 248, 'practitioners': 249, 'state': 250, 'farming': 251, 'weather': 252, 'forecasting': 253, 'such': 254, 'assure': 255, 'recommendations': 256, 'strongly': 257, 'proven': 258, 'humble': 259, 'changes': 260, 'result': 261, 'considerable': 262, 'push': 263, 'back': 264, 'changing': 265, 'though': 266, 'speech': 267, 'riveting': 268, 'concern': 269, 'top': 270, 'venues': 271, 'note': 272, 'speaker': 273, 'writer': 274, 'practitioner': 275, 'wished': 276, 'its': 277, 'gotten': 278, 'same': 279, 'usefully': 280, 'coherently': 281, 'lastingly': 282, 'whether': 283, 'digital': 284, 'millenium': 285, 'copyright': 286, 'computer': 287, 'fraud': 288, 'abuse': 289, 'non': 290, 'lawmaking': 291, 'significant': 292, 'actions': 293, 'executive': 294, 'agencies': 295, 'undertaking': 296, 'never': 297, 'forefront': 298, \"ain't\": 299, 'yet': 300, 'still': 301, 'hold': 302, 'big': 303, 'picture': 304, 'firmly': 305, \"mind's\": 306, 'track': 307, 'everything': 308, 'our': 309, 'few': 310, 'sins': 311, 'omission': 312, 'phase': 313, 'passed': 314, 'sometime': 315, 'six': 316, 'years': 317, 'candid': 318, 'own': 319, 'country': 320, 'much': 321, 'countries': 322, 'levels': 323, 'attention': 324, 'spread': 325, 'corner': 326, 'height': 327, 'width': 328, 'footprint': 329, 'surpassed': 330, 'should': 331, 'study': 332, 'career': 333, 'advise': 334, 'early': 335, 'managed': 336, 'retain': 337, 'over': 338, 'arching': 339, 'generalist': 340, 'knowledge': 341, \"can't\": 342, 'replaced': 343, 'very': 344, 'easily': 345, 'because': 346, 'absorbing': 347, 'new': 348, 'information': 349, 'time': 350, 'began': 351, 'starting': 352, 'scratch': 353, 'serial': 354, 'done': 355, 'practical': 356, 'just': 357, 'program': 358, 'confirm': 359, 'really': 360, 'topics': 361, 'here': 362, 'requires': 363, 'shutting': 364, 'out': 365, 'demands': 366, 'speaking': 367, 'interested': 368, 'advantages': 369, 'disadvantages': 370, 'bit': 371, 'unless': 372, 'whenever': 373, 'tells': 374, 'adopting': 375, 'makes': 376, 'remember': 377, 'george': 378, 'santayana': 379, 'said': 380, 'scepticism': 381, 'chastity': 382, 'intellect': 383, 'shameful': 384, 'give': 385, 'too': 386, 'soon': 387, 'first': 388, 'comer': 389, 'similar': 390, 'skepticism': 391, \"it's\": 392, 'magic': 393, 'ever': 394, 'accept': 395, 'by': 396, 'something': 397, 'particular': 398, 'mechanisms': 399, 'them': 400, 'long': 401, 'substantiated': 402, 'scalpel': 403, 'hammer': 404, 'gas': 405, 'ill': 406, 'inherent': 407, 'wide': 408, 'suggest': 409, 'set': 410, 'favors': 411, 'days': 412, 'chris': 413, 'deputy': 414, 'director': 415, 'remarked': 416, 'soccer': 417, 'tally': 418, '462': 419, '456': 420, 'twenty': 421, 'minutes': 422, 'ci': 423, 'e': 424, 'level': 425, 'nature': 426, 'also': 427, 'where': 428, 'innovations': 429, 'states': 430, 'afford': 431, 'nevertheless': 432, 'outgrowth': 433, 'extension': 434, 'increasing': 435, 'importance': 436, 'spoke': 437, 'word': 438, 'longer': 439, 'engaging': 440, 'sort': 441, 'parlor': 442, 'becomes': 443, 'interlaced': 444, 'aspect': 445, 'life': 446, 'everybody': 447, 'outcome': 448, 'differential': 449, 'between': 450, 'bad': 451, 'broadens': 452, 'ease': 453, 'finding': 454, 'answers': 455, 'falls': 456, 'mencken': 457, 'complex': 458, 'clear': 459}\n"
     ]
    }
   ],
   "source": [
    "tokenizer.fit_on_texts(y)\n",
    "print(len(tokenizer.word_index),tokenizer.word_index)\n",
    "for word in y:\n",
    "    try:\n",
    "        e=tokenizer.texts_to_sequences([word])[0][0]\n",
    "    except:\n",
    "        e=0\n",
    "    embeddings_y.append(e)\n",
    "embeddings_y=np.array(embeddings_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f066229d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "743"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7f930551",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.06246194, -0.049209  ,  0.00407102, -0.02026014, -0.04346866,\n",
       "        -0.00748973, -0.0356756 ,  0.06222412, -0.03854244,  0.02709549,\n",
       "         0.00292689,  0.03292041,  0.01779463,  0.06369314,  0.00115686]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4e35965c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.06246194, -0.049209  ,  0.00407102, -0.02026014, -0.04346866,\n",
       "        -0.00748973, -0.0356756 ,  0.06222412, -0.03854244,  0.02709549,\n",
       "         0.00292689,  0.03292041,  0.01779463,  0.06369314,  0.00115686],\n",
       "       [-0.05683396,  0.05229538, -0.05341402,  0.0306057 ,  0.06263665,\n",
       "         0.03840695,  0.04100427,  0.05531496,  0.02296231, -0.0471125 ,\n",
       "         0.03942722, -0.05425759, -0.03720862,  0.03856581, -0.05377772]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_x[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "72cae71f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.06246194, -0.049209  ,  0.00407102, -0.02026014, -0.04346866,\n",
       "        -0.00748973, -0.0356756 ,  0.06222412, -0.03854244,  0.02709549,\n",
       "         0.00292689,  0.03292041,  0.01779463,  0.06369314,  0.00115686],\n",
       "       [-0.05683396,  0.05229538, -0.05341402,  0.0306057 ,  0.06263665,\n",
       "         0.03840695,  0.04100427,  0.05531496,  0.02296231, -0.0471125 ,\n",
       "         0.03942722, -0.05425759, -0.03720862,  0.03856581, -0.05377772],\n",
       "       [-0.03969079, -0.02383095,  0.02410348,  0.03382367,  0.01345079,\n",
       "         0.0347387 , -0.01769079,  0.02956779, -0.04704267, -0.01040189,\n",
       "        -0.05036606,  0.00243362,  0.03236112,  0.03101156, -0.03196787]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_x[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "88890329",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.06246194, -0.049209  ,  0.00407102, -0.02026014, -0.04346866,\n",
       "         -0.00748973, -0.0356756 ,  0.06222412, -0.03854244,  0.02709549,\n",
       "          0.00292689,  0.03292041,  0.01779463,  0.06369314,  0.00115686],\n",
       "        [-0.05683396,  0.05229538, -0.05341402,  0.0306057 ,  0.06263665,\n",
       "          0.03840695,  0.04100427,  0.05531496,  0.02296231, -0.0471125 ,\n",
       "          0.03942722, -0.05425759, -0.03720862,  0.03856581, -0.05377772],\n",
       "        [-0.03969079, -0.02383095,  0.02410348,  0.03382367,  0.01345079,\n",
       "          0.0347387 , -0.01769079,  0.02956779, -0.04704267, -0.01040189,\n",
       "         -0.05036606,  0.00243362,  0.03236112,  0.03101156, -0.03196787],\n",
       "        [ 0.01106247,  0.05192446, -0.03524574, -0.02650766, -0.00426547,\n",
       "         -0.03063049,  0.05779214,  0.05081302,  0.06144317,  0.06326098,\n",
       "         -0.05483432, -0.0015293 , -0.04956562, -0.03316838, -0.06006755]],\n",
       "       dtype=float32),\n",
       " 0)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_x[3],embeddings_y[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8089fa46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxsize=[]\n",
    "for i in embeddings_x:\n",
    "    maxsize.append(i.shape[0])\n",
    "max(maxsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "12ce1cd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 15)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_x[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "69fe3c8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.06246194, -0.049209  ,  0.00407102, ...,  0.01779463,\n",
       "          0.06369314,  0.00115686]],\n",
       "\n",
       "       [[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.06246194, -0.049209  ,  0.00407102, ...,  0.01779463,\n",
       "          0.06369314,  0.00115686],\n",
       "        [-0.05683396,  0.05229538, -0.05341402, ..., -0.03720862,\n",
       "          0.03856581, -0.05377772]],\n",
       "\n",
       "       [[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.06246194, -0.049209  ,  0.00407102, ...,  0.01779463,\n",
       "          0.06369314,  0.00115686],\n",
       "        [-0.05683396,  0.05229538, -0.05341402, ..., -0.03720862,\n",
       "          0.03856581, -0.05377772],\n",
       "        [-0.03969079, -0.02383095,  0.02410348, ...,  0.03236112,\n",
       "          0.03101156, -0.03196787]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [-0.00091926, -0.02648852, -0.03698023, ...,  0.05022385,\n",
       "         -0.0236564 ,  0.04158781]],\n",
       "\n",
       "       [[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [-0.00091926, -0.02648852, -0.03698023, ...,  0.05022385,\n",
       "         -0.0236564 ,  0.04158781],\n",
       "        [ 0.01310604,  0.01614948,  0.03378637, ..., -0.04875587,\n",
       "          0.03600669, -0.02195277]],\n",
       "\n",
       "       [[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.01310604,  0.01614948,  0.03378637, ..., -0.04875587,\n",
       "          0.03600669, -0.02195277]]], dtype=float32)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_sequences_padded_x = pad_sequences(\n",
    "    embeddings_x,\n",
    "    maxlen=5,\n",
    "    dtype='float32',\n",
    "    padding='pre'\n",
    ")\n",
    "embedding_sequences_padded_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ca3a27b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(embedding_sequences_padded_x)):\n",
    "    print(embeddings_x[i].shape, embedding_sequences_padded_x[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8cc5f8ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1229, (743, 5, 15))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emeddingModel.corpus_total_words,embedding_sequences_padded_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fd315d5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_7\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_7\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ simple_rnn_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,120</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ simple_rnn_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,104</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">744</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">24,552</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ simple_rnn_12 (\u001b[38;5;33mSimpleRNN\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │         \u001b[38;5;34m5,120\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ simple_rnn_13 (\u001b[38;5;33mSimpleRNN\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m3,104\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m744\u001b[0m)            │        \u001b[38;5;34m24,552\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">32,776</span> (128.03 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m32,776\u001b[0m (128.03 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">32,776</span> (128.03 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m32,776\u001b[0m (128.03 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    SimpleRNN(64,activation='relu', input_shape=(5, 15),return_sequences=True),\n",
    "    Dropout(0.05),\n",
    "    SimpleRNN(32,activation='relu'),\n",
    "    Dense(744,activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "077b49a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((743, 5, 15), (743,))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_sequences_padded_x.shape,embeddings_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5bcce731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7212 - loss: 0.9957\n",
      "Epoch 2/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7302 - loss: 0.9521\n",
      "Epoch 3/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7098 - loss: 1.0045\n",
      "Epoch 4/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7053 - loss: 0.9860\n",
      "Epoch 5/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6969 - loss: 0.9433\n",
      "Epoch 6/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7265 - loss: 0.9127\n",
      "Epoch 7/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7379 - loss: 0.9094\n",
      "Epoch 8/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7290 - loss: 0.9110\n",
      "Epoch 9/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6944 - loss: 0.9815\n",
      "Epoch 10/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7236 - loss: 0.9550\n",
      "Epoch 11/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7223 - loss: 0.9616\n",
      "Epoch 12/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7346 - loss: 0.9042\n",
      "Epoch 13/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7306 - loss: 0.9238\n",
      "Epoch 14/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7407 - loss: 0.8805\n",
      "Epoch 15/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7472 - loss: 0.9277\n",
      "Epoch 16/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6925 - loss: 0.9606\n",
      "Epoch 17/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7446 - loss: 0.8681\n",
      "Epoch 18/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7242 - loss: 0.8795\n",
      "Epoch 19/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7460 - loss: 0.8692\n",
      "Epoch 20/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7245 - loss: 0.9426\n",
      "Epoch 21/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7217 - loss: 0.9346\n",
      "Epoch 22/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7501 - loss: 0.8479\n",
      "Epoch 23/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7283 - loss: 0.8957\n",
      "Epoch 24/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7398 - loss: 0.8692\n",
      "Epoch 25/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7507 - loss: 0.8268\n",
      "Epoch 26/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7508 - loss: 0.8422\n",
      "Epoch 27/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7730 - loss: 0.8231\n",
      "Epoch 28/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7357 - loss: 0.8564\n",
      "Epoch 29/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7699 - loss: 0.8254\n",
      "Epoch 30/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7541 - loss: 0.8342\n",
      "Epoch 31/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7484 - loss: 0.8431\n",
      "Epoch 32/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7438 - loss: 0.8797\n",
      "Epoch 33/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7111 - loss: 0.9330\n",
      "Epoch 34/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7447 - loss: 0.8091\n",
      "Epoch 35/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7756 - loss: 0.7924\n",
      "Epoch 36/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7322 - loss: 0.8364\n",
      "Epoch 37/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7643 - loss: 0.8006\n",
      "Epoch 38/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7767 - loss: 0.7355\n",
      "Epoch 39/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7507 - loss: 0.8265\n",
      "Epoch 40/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7565 - loss: 0.8131\n",
      "Epoch 41/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7557 - loss: 0.7958\n",
      "Epoch 42/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7497 - loss: 0.8224\n",
      "Epoch 43/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7703 - loss: 0.7667 \n",
      "Epoch 44/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7553 - loss: 0.7808\n",
      "Epoch 45/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7451 - loss: 0.8714\n",
      "Epoch 46/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7509 - loss: 0.8132\n",
      "Epoch 47/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7608 - loss: 0.7772\n",
      "Epoch 48/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7538 - loss: 0.7484\n",
      "Epoch 49/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7457 - loss: 0.7890\n",
      "Epoch 50/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7333 - loss: 0.8559\n",
      "Epoch 51/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7557 - loss: 0.7841\n",
      "Epoch 52/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7354 - loss: 0.8124\n",
      "Epoch 53/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7500 - loss: 0.8452\n",
      "Epoch 54/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7566 - loss: 0.7809\n",
      "Epoch 55/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7689 - loss: 0.7321\n",
      "Epoch 56/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7790 - loss: 0.7711\n",
      "Epoch 57/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7850 - loss: 0.7521\n",
      "Epoch 58/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7956 - loss: 0.7150\n",
      "Epoch 59/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7629 - loss: 0.7152\n",
      "Epoch 60/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7685 - loss: 0.7702\n",
      "Epoch 61/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7334 - loss: 0.8283\n",
      "Epoch 62/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7514 - loss: 0.7476\n",
      "Epoch 63/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7608 - loss: 0.7853\n",
      "Epoch 64/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7636 - loss: 0.7922\n",
      "Epoch 65/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7568 - loss: 0.7579\n",
      "Epoch 66/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7692 - loss: 0.7522\n",
      "Epoch 67/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7429 - loss: 0.7932\n",
      "Epoch 68/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7463 - loss: 0.8042\n",
      "Epoch 69/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7727 - loss: 0.7444\n",
      "Epoch 70/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7662 - loss: 0.7064\n",
      "Epoch 71/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7717 - loss: 0.7057\n",
      "Epoch 72/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7835 - loss: 0.6809\n",
      "Epoch 73/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7800 - loss: 0.7057\n",
      "Epoch 74/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7578 - loss: 0.7530\n",
      "Epoch 75/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7992 - loss: 0.6761\n",
      "Epoch 76/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7655 - loss: 0.7457\n",
      "Epoch 77/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7911 - loss: 0.6808\n",
      "Epoch 78/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8201 - loss: 0.6397\n",
      "Epoch 79/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7638 - loss: 0.7295\n",
      "Epoch 80/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7663 - loss: 0.7150\n",
      "Epoch 81/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7952 - loss: 0.6789\n",
      "Epoch 82/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7925 - loss: 0.6403\n",
      "Epoch 83/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8102 - loss: 0.6432\n",
      "Epoch 84/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8043 - loss: 0.5981\n",
      "Epoch 85/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7723 - loss: 0.7160\n",
      "Epoch 86/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7766 - loss: 0.7053\n",
      "Epoch 87/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7814 - loss: 0.6585\n",
      "Epoch 88/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7788 - loss: 0.7205\n",
      "Epoch 89/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7912 - loss: 0.6433\n",
      "Epoch 90/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7873 - loss: 0.6893\n",
      "Epoch 91/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7843 - loss: 0.6757\n",
      "Epoch 92/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7803 - loss: 0.6828\n",
      "Epoch 93/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7838 - loss: 0.7007\n",
      "Epoch 94/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7808 - loss: 0.6484\n",
      "Epoch 95/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7963 - loss: 0.6364\n",
      "Epoch 96/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7943 - loss: 0.6829\n",
      "Epoch 97/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8119 - loss: 0.6233\n",
      "Epoch 98/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7836 - loss: 0.6380\n",
      "Epoch 99/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7568 - loss: 0.7073\n",
      "Epoch 100/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7933 - loss: 0.6565\n",
      "Epoch 101/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7832 - loss: 0.6449\n",
      "Epoch 102/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8005 - loss: 0.5991\n",
      "Epoch 103/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7885 - loss: 0.6349\n",
      "Epoch 104/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7778 - loss: 0.6671\n",
      "Epoch 105/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7862 - loss: 0.5938\n",
      "Epoch 106/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7976 - loss: 0.6607\n",
      "Epoch 107/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7721 - loss: 0.6768\n",
      "Epoch 108/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7973 - loss: 0.6279\n",
      "Epoch 109/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7925 - loss: 0.6106\n",
      "Epoch 110/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7606 - loss: 0.6949\n",
      "Epoch 111/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7761 - loss: 0.6729\n",
      "Epoch 112/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8018 - loss: 0.6065\n",
      "Epoch 113/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8114 - loss: 0.6022\n",
      "Epoch 114/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7958 - loss: 0.6444\n",
      "Epoch 115/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8056 - loss: 0.6393\n",
      "Epoch 116/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7825 - loss: 0.6852\n",
      "Epoch 117/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7882 - loss: 0.6339\n",
      "Epoch 118/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7920 - loss: 0.6658\n",
      "Epoch 119/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8026 - loss: 0.6326\n",
      "Epoch 120/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8043 - loss: 0.6151\n",
      "Epoch 121/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7941 - loss: 0.6267\n",
      "Epoch 122/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8195 - loss: 0.5961\n",
      "Epoch 123/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8176 - loss: 0.5809\n",
      "Epoch 124/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8053 - loss: 0.6110\n",
      "Epoch 125/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8119 - loss: 0.5621\n",
      "Epoch 126/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8000 - loss: 0.6117\n",
      "Epoch 127/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8195 - loss: 0.5680 \n",
      "Epoch 128/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7984 - loss: 0.6286\n",
      "Epoch 129/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8148 - loss: 0.5750\n",
      "Epoch 130/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7963 - loss: 0.6058 \n",
      "Epoch 131/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7951 - loss: 0.6269\n",
      "Epoch 132/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8174 - loss: 0.5825\n",
      "Epoch 133/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7829 - loss: 0.6410\n",
      "Epoch 134/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7935 - loss: 0.6231 \n",
      "Epoch 135/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8122 - loss: 0.5701\n",
      "Epoch 136/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8064 - loss: 0.6125\n",
      "Epoch 137/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8034 - loss: 0.5714\n",
      "Epoch 138/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8031 - loss: 0.6436\n",
      "Epoch 139/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8124 - loss: 0.5632\n",
      "Epoch 140/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7968 - loss: 0.5997\n",
      "Epoch 141/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8095 - loss: 0.5650\n",
      "Epoch 142/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7740 - loss: 0.6127\n",
      "Epoch 143/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7881 - loss: 0.6092\n",
      "Epoch 144/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8335 - loss: 0.5044\n",
      "Epoch 145/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7878 - loss: 0.6061\n",
      "Epoch 146/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7985 - loss: 0.6250\n",
      "Epoch 147/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8036 - loss: 0.5913\n",
      "Epoch 148/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8247 - loss: 0.5563\n",
      "Epoch 149/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8152 - loss: 0.5748\n",
      "Epoch 150/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8235 - loss: 0.5419\n",
      "Epoch 151/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8279 - loss: 0.5664\n",
      "Epoch 152/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8183 - loss: 0.5676\n",
      "Epoch 153/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8308 - loss: 0.5512\n",
      "Epoch 154/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8038 - loss: 0.5747\n",
      "Epoch 155/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7850 - loss: 0.6091\n",
      "Epoch 156/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8106 - loss: 0.5529\n",
      "Epoch 157/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8208 - loss: 0.5216\n",
      "Epoch 158/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8245 - loss: 0.5352 \n",
      "Epoch 159/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7992 - loss: 0.5812\n",
      "Epoch 160/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7972 - loss: 0.5924\n",
      "Epoch 161/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8140 - loss: 0.5691\n",
      "Epoch 162/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7825 - loss: 0.6304\n",
      "Epoch 163/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8203 - loss: 0.5345\n",
      "Epoch 164/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8093 - loss: 0.5414\n",
      "Epoch 165/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8215 - loss: 0.5556\n",
      "Epoch 166/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8361 - loss: 0.5184\n",
      "Epoch 167/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7882 - loss: 0.6004\n",
      "Epoch 168/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8147 - loss: 0.5510\n",
      "Epoch 169/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8011 - loss: 0.5524\n",
      "Epoch 170/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8169 - loss: 0.5602\n",
      "Epoch 171/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8020 - loss: 0.5414\n",
      "Epoch 172/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7934 - loss: 0.5765 \n",
      "Epoch 173/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8176 - loss: 0.5335\n",
      "Epoch 174/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8108 - loss: 0.5675\n",
      "Epoch 175/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8287 - loss: 0.5546\n",
      "Epoch 176/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8060 - loss: 0.5592\n",
      "Epoch 177/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8237 - loss: 0.5045\n",
      "Epoch 178/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8243 - loss: 0.5189\n",
      "Epoch 179/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8356 - loss: 0.4835\n",
      "Epoch 180/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7998 - loss: 0.5236\n",
      "Epoch 181/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8354 - loss: 0.5164\n",
      "Epoch 182/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7923 - loss: 0.5611\n",
      "Epoch 183/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8276 - loss: 0.5015\n",
      "Epoch 184/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7957 - loss: 0.5901 \n",
      "Epoch 185/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8039 - loss: 0.5479\n",
      "Epoch 186/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8162 - loss: 0.5087\n",
      "Epoch 187/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8103 - loss: 0.5449\n",
      "Epoch 188/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8101 - loss: 0.5559\n",
      "Epoch 189/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8162 - loss: 0.5554\n",
      "Epoch 190/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8151 - loss: 0.5300 \n",
      "Epoch 191/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7958 - loss: 0.5763 \n",
      "Epoch 192/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8242 - loss: 0.5174\n",
      "Epoch 193/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8370 - loss: 0.5039\n",
      "Epoch 194/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8134 - loss: 0.5317\n",
      "Epoch 195/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8076 - loss: 0.5603\n",
      "Epoch 196/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8143 - loss: 0.5492\n",
      "Epoch 197/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8175 - loss: 0.5248\n",
      "Epoch 198/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8056 - loss: 0.5043 \n",
      "Epoch 199/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8151 - loss: 0.5055\n",
      "Epoch 200/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8446 - loss: 0.4637\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x168bb221430>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "earlystopping=EarlyStopping(monitor='val_loss',patience=20,restore_best_weights=True)\n",
    "model.fit(embedding_sequences_padded_x, embeddings_y , batch_size=32, epochs=200, callbacks=[earlystopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb586d8",
   "metadata": {},
   "source": [
    "- Those of us who are backing out our remaining dependencies on digital goods and services are being entirely rational and are likely to survive.\n",
    "- I say that because the root cause of risk is dependence, and most especially dependence on expectations of system state.\n",
    "- If I don't use my trademark, then my rights go over to those who use what was and could have remained mine.\n",
    "- For better or poorer, the only two products not covered by product liability today are religion and software, and software should not escape for much longer.\n",
    "\n",
    "<bR><br>\n",
    "\n",
    "- There are three professions that beat their practitioners into a state of humility: farming, weather forecasting, and cyber security. I practice two of those, and, as such, let me assure you that the recommendations which follow are presented in all humility.  Humility does not mean timidity.  Rather, it means that when a strongly held belief is proven wrong, that the humble person changes their mind. I expect that my proposals will result in considerable push-back, and changing my mind may well follow.  Though I will say it again later, this speech is me talking for myself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0ee344e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Whether we are talking about laws\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "Top predictions:\n",
      "are: 0.9999\n",
      "of: 0.0000\n",
      "a: 0.0000\n",
      "i: 0.0000\n",
      "it: 0.0000\n",
      "\n",
      " Whether we are talking about\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "Top predictions:\n",
      "laws: 1.0000\n",
      "<UNK>: 0.0000\n",
      "does: 0.0000\n",
      "that: 0.0000\n",
      "put: 0.0000\n",
      "\n",
      " Whether we are talking\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "Top predictions:\n",
      "about: 1.0000\n",
      "<UNK>: 0.0000\n",
      "that: 0.0000\n",
      "of: 0.0000\n",
      "i: 0.0000\n",
      "\n",
      " Whether we are\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "Top predictions:\n",
      "talking: 0.9955\n",
      "unimportant: 0.0026\n",
      "unappealing: 0.0016\n",
      "now: 0.0002\n",
      "three: 0.0001\n",
      "\n",
      " Whether we\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "Top predictions:\n",
      "are: 0.9168\n",
      "my: 0.0356\n",
      "the: 0.0223\n",
      "of: 0.0113\n",
      "this: 0.0053\n",
      "\n",
      " Whether\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "Top predictions:\n",
      "we: 0.6891\n",
      "i: 0.0837\n",
      "my: 0.0512\n",
      "and: 0.0462\n",
      "is: 0.0408\n",
      "\n",
      " like the Digital Millenium\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "Top predictions:\n",
      "of: 0.7336\n",
      "<UNK>: 0.1594\n",
      "i: 0.0823\n",
      "will: 0.0230\n",
      "black: 0.0016\n"
     ]
    }
   ],
   "source": [
    "input=[\"Whether we are talking about laws\",\"Whether we are talking about\",\"Whether we are talking\",\"Whether we are\",\"Whether we\",\"Whether\",\"like the Digital Millenium\"]\n",
    "for line in input:\n",
    "    print('\\n',line)\n",
    "    input=line.split(' ')\n",
    "    embeddings=[]\n",
    "    if len(input) >=5:\n",
    "        for word in input[len(input)-5:]:\n",
    "            e=emeddingModel.wv[word]\n",
    "            embeddings.append(e)\n",
    "    else:\n",
    "        for word in input:\n",
    "            e=emeddingModel.wv[word]\n",
    "            embeddings.append(e)\n",
    "\n",
    "    embeddings=np.array(embeddings)\n",
    "    \n",
    "    if embeddings.shape[0] < 5:  # If embeddings has shape as (3,15)\n",
    "        diff=5-embeddings.shape[0]\n",
    "        arr=np.zeros((diff,15))\n",
    "        embeddings=np.vstack((arr,embeddings))\n",
    "\n",
    "\n",
    "    embeddings=embeddings.reshape(1, 5, 15)  # Had to reshape since the training shape was (743, 5, 15) for embedding_sequences_padded_x\n",
    "\n",
    "    prediction = model.predict(embeddings)\n",
    "    top_n = 5\n",
    "    top_indices = prediction[0].argsort()[-top_n:][::-1]\n",
    "    top_words = [(tokenizer.index_word.get(i, \"<UNK>\"), prediction[0][i]) for i in top_indices]\n",
    "\n",
    "    print(\"Top predictions:\")\n",
    "    for word, score in top_words:\n",
    "        print(f\"{word}: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b7349c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d22e6c45",
   "metadata": {},
   "source": [
    "<br><br><br><br>\n",
    "\n",
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4283e433",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' [ nominal delivery draft, 6 August 2014 ]  Cybersecurity as Realpolitik Dan Geer   Good morning and thank you for the invitation to speak with you today.',\n",
       " 'The plaintext of this talk has been made available to the organizers.',\n",
       " 'While I will not be taking questions today, you are welcome to contact me later and I will do what I can to reply.',\n",
       " 'For simple clarity, let me repeat the abstract for this talk:     Power exists to be used.',\n",
       " 'Some wish for cyber safety, which they    will not get.',\n",
       " 'Others wish for cyber order, which they will not    get.',\n",
       " 'Some have the eye to discern cyber policies that are \"the    least worst thing;\" may they fill the vacuum of wishful thinking.',\n",
       " 'There are three professions that beat their practitioners into a state of humility: farming, weather forecasting, and cyber security.',\n",
       " 'I practice two of those, and, as such, let me assure you that the recommendations which follow are presented in all humility.',\n",
       " 'Humility does not mean timidity.',\n",
       " 'Rather, it means that when a strongly held belief is proven wrong, that the humble person changes their mind.',\n",
       " 'I expect that my proposals will result in considerable push-back, and changing my mind may well follow.',\n",
       " 'Though I will say it again later, this speech is me talking for myself.',\n",
       " 'As if it needed saying, cyber security is now a riveting concern, a top issue in many venues more important than this one.',\n",
       " 'This is not to insult Black Hat; rather it is to note that every speaker, every writer, every practitioner in the field of cyber security who has wished that its topic, and us with it, were taken seriously has gotten their wish.',\n",
       " 'Cyber security *is* being taken seriously, which, as you well know is not the same as being taken usefully, coherently, or lastingly.',\n",
       " 'Whether we are talking about laws like the Digital Millenium Copyright Act or the Computer Fraud and Abuse Act, or the non-lawmaking but perhaps even more significant actions that the Executive agencies are undertaking, \"we\" and the cyber security issue have never been more at the forefront of policy.',\n",
       " \"And you ain't seen nothing yet.\",\n",
       " \"I wish that I could tell you that it is still possible for one person to hold the big picture firmly in their mind's eye, to track everything important that is going on in our field, to make few if any sins of omission.\",\n",
       " 'It is not possible; that phase passed sometime in the last six years.',\n",
       " 'I have certainly tried to keep up but I would be less than candid if I were not to say that I know that I am not keeping up, not even keeping up with what is going on in my own country much less all countries.',\n",
       " 'Not only has cybersecurity reached the highest levels of attention, it has spread into nearly every corner.',\n",
       " 'If area is the product of height and width, then the footprint of cybersecurity has surpassed the grasp of any one of us.',\n",
       " 'The rate of technological change is certainly a part of it.',\n",
       " 'When younger people ask my advice on what they should do or study to make a career in cyber security, I can only advise specialization.',\n",
       " \"Those of us who were in the game early enough and who have managed to retain an over-arching generalist knowledge can't be replaced very easily because while absorbing most new information most of the time may have been possible when we began practice, no person starting from scratch can do that now.\",\n",
       " 'Serial specialization is now all that can be done in any practical way.',\n",
       " 'Just looking at the Black Hat program will confirm that being really good at any one of the many topics presented here all but requires shutting out the demands of being good at any others.',\n",
       " 'Why does that matter?',\n",
       " 'Speaking for myself, I am not interested in the advantages or disadvantages of some bit of technology unless I can grasp how it is that that technology works.',\n",
       " 'Whenever I see marketing material that tells me all the good things that adopting this or that technology makes possible, I remember what George Santayana said, that \"Scepticism is the chastity of the intellect; it is shameful to give it up too soon, or to the first comer.\"',\n",
       " 'I suspect that a majority of you have similar skepticism -- \"It\\'s magic!\"',\n",
       " 'is not the answer a security person will ever accept.',\n",
       " 'By and large, I can tell *what* something is good for once I know *how* it works.',\n",
       " 'Tell me how it works and then, but only then, tell me why you have chosen to use those particular mechanisms for the things you have chosen to use them for.',\n",
       " 'Part of my feeling stems from a long-held and well-substantiated belief that all cyber security technology is dual use.',\n",
       " 'Perhaps dual use is a truism for any and all tools from the scalpel to the hammer to the gas can -- they can be used for good or ill -- but I know that dual use is inherent in cyber security tools.',\n",
       " 'If your definition of \"tool\" is wide enough, I suggest that the cyber security tool-set favors offense these days.',\n",
       " 'Chris Inglis, recently retired NSA Deputy Director, remarked that if we were to score cyber the way we score soccer, the tally would be 462-456 twenty minutes into the game,[CI] i.e., all offense.',\n",
       " 'I will take his comment as confirming at the highest level not only the dual use nature of cybersecurity but also confirming that offense is where the innovations that only States can afford is going on.',\n",
       " 'Nevertheless, this essay is an outgrowth from, an extension of, that increasing importance of cybersecurity.',\n",
       " 'With the humility of which I spoke, I do not claim that I have the last word.',\n",
       " 'What I do claim is that when we speak about cybersecurity policy we are no longer engaging in some sort of parlor game.',\n",
       " 'I claim that policy matters are now the most important matters, that once a topic area, like cybersecurity, becomes interlaced with nearly every aspect of life for nearly everybody, the outcome differential between good policies and bad policies broadens, and the ease of finding answers falls.',\n",
       " 'As H.L.',\n",
       " 'Mencken so trenchantly put it, \"For every complex problem there is a solution that is clear, simple, and wrong.\"',\n",
       " 'The four verities of government are these: .',\n",
       " 'Most important ideas are unappealing .',\n",
       " 'Most appealing ideas are unimportant .',\n",
       " 'Not every problem has a good solution .',\n",
       " 'Every solution has side effects']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "sentences=sent_tokenize(corpus)\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1d700858",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' [ nominal delivery draft, 6 August 2014 ]  Cybersecurity as Realpolitik Dan Geer   Good morning and thank you for the invitation to speak with you today.'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d82a52d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[', 'nominal', 'delivery', 'draft', ',', '6', 'August', '2014', ']', 'Cybersecurity', 'as', 'Realpolitik', 'Dan', 'Geer', 'Good', 'morning', 'and', 'thank', 'you', 'for', 'the', 'invitation', 'to', 'speak', 'with', 'you', 'today', '.']\n",
      "['[', 'nominal'] => delivery\n",
      "['[', 'nominal', 'delivery'] => draft\n",
      "['[', 'nominal', 'delivery', 'draft'] => ,\n",
      "['[', 'nominal', 'delivery', 'draft', ','] => 6\n",
      "['[', 'nominal', 'delivery', 'draft', ',', '6'] => August\n",
      "['nominal', 'delivery'] => draft\n",
      "['nominal', 'delivery', 'draft'] => ,\n",
      "['nominal', 'delivery', 'draft', ','] => 6\n",
      "['nominal', 'delivery', 'draft', ',', '6'] => August\n",
      "['delivery', 'draft'] => ,\n",
      "['delivery', 'draft', ','] => 6\n",
      "['delivery', 'draft', ',', '6'] => August\n",
      "['draft', ','] => 6\n",
      "['draft', ',', '6'] => August\n",
      "[',', '6'] => August\n",
      "['The', 'plaintext', 'of', 'this', 'talk', 'has', 'been', 'made', 'available', 'to', 'the', 'organizers', '.']\n",
      "['The', 'plaintext'] => of\n",
      "['The', 'plaintext', 'of'] => this\n",
      "['The', 'plaintext', 'of', 'this'] => talk\n",
      "['The', 'plaintext', 'of', 'this', 'talk'] => has\n",
      "['The', 'plaintext', 'of', 'this', 'talk', 'has'] => been\n",
      "['plaintext', 'of'] => this\n",
      "['plaintext', 'of', 'this'] => talk\n",
      "['plaintext', 'of', 'this', 'talk'] => has\n",
      "['plaintext', 'of', 'this', 'talk', 'has'] => been\n",
      "['of', 'this'] => talk\n",
      "['of', 'this', 'talk'] => has\n",
      "['of', 'this', 'talk', 'has'] => been\n",
      "['this', 'talk'] => has\n",
      "['this', 'talk', 'has'] => been\n",
      "['talk', 'has'] => been\n",
      "['While', 'I', 'will', 'not', 'be', 'taking', 'questions', 'today', ',', 'you', 'are', 'welcome', 'to', 'contact', 'me', 'later', 'and', 'I', 'will', 'do', 'what', 'I', 'can', 'to', 'reply', '.']\n",
      "['While', 'I'] => will\n",
      "['While', 'I', 'will'] => not\n",
      "['While', 'I', 'will', 'not'] => be\n",
      "['While', 'I', 'will', 'not', 'be'] => taking\n",
      "['While', 'I', 'will', 'not', 'be', 'taking'] => questions\n",
      "['I', 'will'] => not\n",
      "['I', 'will', 'not'] => be\n",
      "['I', 'will', 'not', 'be'] => taking\n",
      "['I', 'will', 'not', 'be', 'taking'] => questions\n",
      "['will', 'not'] => be\n",
      "['will', 'not', 'be'] => taking\n",
      "['will', 'not', 'be', 'taking'] => questions\n",
      "['not', 'be'] => taking\n",
      "['not', 'be', 'taking'] => questions\n",
      "['be', 'taking'] => questions\n",
      "['For', 'simple', 'clarity', ',', 'let', 'me', 'repeat', 'the', 'abstract', 'for', 'this', 'talk', ':', 'Power', 'exists', 'to', 'be', 'used', '.']\n",
      "['For', 'simple'] => clarity\n",
      "['For', 'simple', 'clarity'] => ,\n",
      "['For', 'simple', 'clarity', ','] => let\n",
      "['For', 'simple', 'clarity', ',', 'let'] => me\n",
      "['For', 'simple', 'clarity', ',', 'let', 'me'] => repeat\n",
      "['simple', 'clarity'] => ,\n",
      "['simple', 'clarity', ','] => let\n",
      "['simple', 'clarity', ',', 'let'] => me\n",
      "['simple', 'clarity', ',', 'let', 'me'] => repeat\n",
      "['clarity', ','] => let\n",
      "['clarity', ',', 'let'] => me\n",
      "['clarity', ',', 'let', 'me'] => repeat\n",
      "[',', 'let'] => me\n",
      "[',', 'let', 'me'] => repeat\n",
      "['let', 'me'] => repeat\n",
      "['Some', 'wish', 'for', 'cyber', 'safety', ',', 'which', 'they', 'will', 'not', 'get', '.']\n",
      "['Some', 'wish'] => for\n",
      "['Some', 'wish', 'for'] => cyber\n",
      "['Some', 'wish', 'for', 'cyber'] => safety\n",
      "['Some', 'wish', 'for', 'cyber', 'safety'] => ,\n",
      "['Some', 'wish', 'for', 'cyber', 'safety', ','] => which\n",
      "['wish', 'for'] => cyber\n",
      "['wish', 'for', 'cyber'] => safety\n",
      "['wish', 'for', 'cyber', 'safety'] => ,\n",
      "['wish', 'for', 'cyber', 'safety', ','] => which\n",
      "['for', 'cyber'] => safety\n",
      "['for', 'cyber', 'safety'] => ,\n",
      "['for', 'cyber', 'safety', ','] => which\n",
      "['cyber', 'safety'] => ,\n",
      "['cyber', 'safety', ','] => which\n",
      "['safety', ','] => which\n",
      "['Others', 'wish', 'for', 'cyber', 'order', ',', 'which', 'they', 'will', 'not', 'get', '.']\n",
      "['Others', 'wish'] => for\n",
      "['Others', 'wish', 'for'] => cyber\n",
      "['Others', 'wish', 'for', 'cyber'] => order\n",
      "['Others', 'wish', 'for', 'cyber', 'order'] => ,\n",
      "['Others', 'wish', 'for', 'cyber', 'order', ','] => which\n",
      "['wish', 'for'] => cyber\n",
      "['wish', 'for', 'cyber'] => order\n",
      "['wish', 'for', 'cyber', 'order'] => ,\n",
      "['wish', 'for', 'cyber', 'order', ','] => which\n",
      "['for', 'cyber'] => order\n",
      "['for', 'cyber', 'order'] => ,\n",
      "['for', 'cyber', 'order', ','] => which\n",
      "['cyber', 'order'] => ,\n",
      "['cyber', 'order', ','] => which\n",
      "['order', ','] => which\n",
      "['Some', 'have', 'the', 'eye', 'to', 'discern', 'cyber', 'policies', 'that', 'are', '``', 'the', 'least', 'worst', 'thing', ';', \"''\", 'may', 'they', 'fill', 'the', 'vacuum', 'of', 'wishful', 'thinking', '.']\n",
      "['Some', 'have'] => the\n",
      "['Some', 'have', 'the'] => eye\n",
      "['Some', 'have', 'the', 'eye'] => to\n",
      "['Some', 'have', 'the', 'eye', 'to'] => discern\n",
      "['Some', 'have', 'the', 'eye', 'to', 'discern'] => cyber\n",
      "['have', 'the'] => eye\n",
      "['have', 'the', 'eye'] => to\n",
      "['have', 'the', 'eye', 'to'] => discern\n",
      "['have', 'the', 'eye', 'to', 'discern'] => cyber\n",
      "['the', 'eye'] => to\n",
      "['the', 'eye', 'to'] => discern\n",
      "['the', 'eye', 'to', 'discern'] => cyber\n",
      "['eye', 'to'] => discern\n",
      "['eye', 'to', 'discern'] => cyber\n",
      "['to', 'discern'] => cyber\n",
      "['There', 'are', 'three', 'professions', 'that', 'beat', 'their', 'practitioners', 'into', 'a', 'state', 'of', 'humility', ':', 'farming', ',', 'weather', 'forecasting', ',', 'and', 'cyber', 'security', '.']\n",
      "['There', 'are'] => three\n",
      "['There', 'are', 'three'] => professions\n",
      "['There', 'are', 'three', 'professions'] => that\n",
      "['There', 'are', 'three', 'professions', 'that'] => beat\n",
      "['There', 'are', 'three', 'professions', 'that', 'beat'] => their\n",
      "['are', 'three'] => professions\n",
      "['are', 'three', 'professions'] => that\n",
      "['are', 'three', 'professions', 'that'] => beat\n",
      "['are', 'three', 'professions', 'that', 'beat'] => their\n",
      "['three', 'professions'] => that\n",
      "['three', 'professions', 'that'] => beat\n",
      "['three', 'professions', 'that', 'beat'] => their\n",
      "['professions', 'that'] => beat\n",
      "['professions', 'that', 'beat'] => their\n",
      "['that', 'beat'] => their\n",
      "['I', 'practice', 'two', 'of', 'those', ',', 'and', ',', 'as', 'such', ',', 'let', 'me', 'assure', 'you', 'that', 'the', 'recommendations', 'which', 'follow', 'are', 'presented', 'in', 'all', 'humility', '.']\n",
      "['I', 'practice'] => two\n",
      "['I', 'practice', 'two'] => of\n",
      "['I', 'practice', 'two', 'of'] => those\n",
      "['I', 'practice', 'two', 'of', 'those'] => ,\n",
      "['I', 'practice', 'two', 'of', 'those', ','] => and\n",
      "['practice', 'two'] => of\n",
      "['practice', 'two', 'of'] => those\n",
      "['practice', 'two', 'of', 'those'] => ,\n",
      "['practice', 'two', 'of', 'those', ','] => and\n",
      "['two', 'of'] => those\n",
      "['two', 'of', 'those'] => ,\n",
      "['two', 'of', 'those', ','] => and\n",
      "['of', 'those'] => ,\n",
      "['of', 'those', ','] => and\n",
      "['those', ','] => and\n",
      "['Humility', 'does', 'not', 'mean', 'timidity', '.']\n",
      "['Humility', 'does'] => not\n",
      "['Humility', 'does', 'not'] => mean\n",
      "['Humility', 'does', 'not', 'mean'] => timidity\n",
      "['Humility', 'does', 'not', 'mean', 'timidity'] => .\n",
      "['does', 'not'] => mean\n",
      "['does', 'not', 'mean'] => timidity\n",
      "['does', 'not', 'mean', 'timidity'] => .\n",
      "['not', 'mean'] => timidity\n",
      "['not', 'mean', 'timidity'] => .\n",
      "['mean', 'timidity'] => .\n",
      "['Rather', ',', 'it', 'means', 'that', 'when', 'a', 'strongly', 'held', 'belief', 'is', 'proven', 'wrong', ',', 'that', 'the', 'humble', 'person', 'changes', 'their', 'mind', '.']\n",
      "['Rather', ','] => it\n",
      "['Rather', ',', 'it'] => means\n",
      "['Rather', ',', 'it', 'means'] => that\n",
      "['Rather', ',', 'it', 'means', 'that'] => when\n",
      "['Rather', ',', 'it', 'means', 'that', 'when'] => a\n",
      "[',', 'it'] => means\n",
      "[',', 'it', 'means'] => that\n",
      "[',', 'it', 'means', 'that'] => when\n",
      "[',', 'it', 'means', 'that', 'when'] => a\n",
      "['it', 'means'] => that\n",
      "['it', 'means', 'that'] => when\n",
      "['it', 'means', 'that', 'when'] => a\n",
      "['means', 'that'] => when\n",
      "['means', 'that', 'when'] => a\n",
      "['that', 'when'] => a\n",
      "['I', 'expect', 'that', 'my', 'proposals', 'will', 'result', 'in', 'considerable', 'push-back', ',', 'and', 'changing', 'my', 'mind', 'may', 'well', 'follow', '.']\n",
      "['I', 'expect'] => that\n",
      "['I', 'expect', 'that'] => my\n",
      "['I', 'expect', 'that', 'my'] => proposals\n",
      "['I', 'expect', 'that', 'my', 'proposals'] => will\n",
      "['I', 'expect', 'that', 'my', 'proposals', 'will'] => result\n",
      "['expect', 'that'] => my\n",
      "['expect', 'that', 'my'] => proposals\n",
      "['expect', 'that', 'my', 'proposals'] => will\n",
      "['expect', 'that', 'my', 'proposals', 'will'] => result\n",
      "['that', 'my'] => proposals\n",
      "['that', 'my', 'proposals'] => will\n",
      "['that', 'my', 'proposals', 'will'] => result\n",
      "['my', 'proposals'] => will\n",
      "['my', 'proposals', 'will'] => result\n",
      "['proposals', 'will'] => result\n",
      "['Though', 'I', 'will', 'say', 'it', 'again', 'later', ',', 'this', 'speech', 'is', 'me', 'talking', 'for', 'myself', '.']\n",
      "['Though', 'I'] => will\n",
      "['Though', 'I', 'will'] => say\n",
      "['Though', 'I', 'will', 'say'] => it\n",
      "['Though', 'I', 'will', 'say', 'it'] => again\n",
      "['Though', 'I', 'will', 'say', 'it', 'again'] => later\n",
      "['I', 'will'] => say\n",
      "['I', 'will', 'say'] => it\n",
      "['I', 'will', 'say', 'it'] => again\n",
      "['I', 'will', 'say', 'it', 'again'] => later\n",
      "['will', 'say'] => it\n",
      "['will', 'say', 'it'] => again\n",
      "['will', 'say', 'it', 'again'] => later\n",
      "['say', 'it'] => again\n",
      "['say', 'it', 'again'] => later\n",
      "['it', 'again'] => later\n",
      "['As', 'if', 'it', 'needed', 'saying', ',', 'cyber', 'security', 'is', 'now', 'a', 'riveting', 'concern', ',', 'a', 'top', 'issue', 'in', 'many', 'venues', 'more', 'important', 'than', 'this', 'one', '.']\n",
      "['As', 'if'] => it\n",
      "['As', 'if', 'it'] => needed\n",
      "['As', 'if', 'it', 'needed'] => saying\n",
      "['As', 'if', 'it', 'needed', 'saying'] => ,\n",
      "['As', 'if', 'it', 'needed', 'saying', ','] => cyber\n",
      "['if', 'it'] => needed\n",
      "['if', 'it', 'needed'] => saying\n",
      "['if', 'it', 'needed', 'saying'] => ,\n",
      "['if', 'it', 'needed', 'saying', ','] => cyber\n",
      "['it', 'needed'] => saying\n",
      "['it', 'needed', 'saying'] => ,\n",
      "['it', 'needed', 'saying', ','] => cyber\n",
      "['needed', 'saying'] => ,\n",
      "['needed', 'saying', ','] => cyber\n",
      "['saying', ','] => cyber\n",
      "['This', 'is', 'not', 'to', 'insult', 'Black', 'Hat', ';', 'rather', 'it', 'is', 'to', 'note', 'that', 'every', 'speaker', ',', 'every', 'writer', ',', 'every', 'practitioner', 'in', 'the', 'field', 'of', 'cyber', 'security', 'who', 'has', 'wished', 'that', 'its', 'topic', ',', 'and', 'us', 'with', 'it', ',', 'were', 'taken', 'seriously', 'has', 'gotten', 'their', 'wish', '.']\n",
      "['This', 'is'] => not\n",
      "['This', 'is', 'not'] => to\n",
      "['This', 'is', 'not', 'to'] => insult\n",
      "['This', 'is', 'not', 'to', 'insult'] => Black\n",
      "['This', 'is', 'not', 'to', 'insult', 'Black'] => Hat\n",
      "['is', 'not'] => to\n",
      "['is', 'not', 'to'] => insult\n",
      "['is', 'not', 'to', 'insult'] => Black\n",
      "['is', 'not', 'to', 'insult', 'Black'] => Hat\n",
      "['not', 'to'] => insult\n",
      "['not', 'to', 'insult'] => Black\n",
      "['not', 'to', 'insult', 'Black'] => Hat\n",
      "['to', 'insult'] => Black\n",
      "['to', 'insult', 'Black'] => Hat\n",
      "['insult', 'Black'] => Hat\n",
      "['Cyber', 'security', '*', 'is', '*', 'being', 'taken', 'seriously', ',', 'which', ',', 'as', 'you', 'well', 'know', 'is', 'not', 'the', 'same', 'as', 'being', 'taken', 'usefully', ',', 'coherently', ',', 'or', 'lastingly', '.']\n",
      "['Cyber', 'security'] => *\n",
      "['Cyber', 'security', '*'] => is\n",
      "['Cyber', 'security', '*', 'is'] => *\n",
      "['Cyber', 'security', '*', 'is', '*'] => being\n",
      "['Cyber', 'security', '*', 'is', '*', 'being'] => taken\n",
      "['security', '*'] => is\n",
      "['security', '*', 'is'] => *\n",
      "['security', '*', 'is', '*'] => being\n",
      "['security', '*', 'is', '*', 'being'] => taken\n",
      "['*', 'is'] => *\n",
      "['*', 'is', '*'] => being\n",
      "['*', 'is', '*', 'being'] => taken\n",
      "['is', '*'] => being\n",
      "['is', '*', 'being'] => taken\n",
      "['*', 'being'] => taken\n",
      "['Whether', 'we', 'are', 'talking', 'about', 'laws', 'like', 'the', 'Digital', 'Millenium', 'Copyright', 'Act', 'or', 'the', 'Computer', 'Fraud', 'and', 'Abuse', 'Act', ',', 'or', 'the', 'non-lawmaking', 'but', 'perhaps', 'even', 'more', 'significant', 'actions', 'that', 'the', 'Executive', 'agencies', 'are', 'undertaking', ',', '``', 'we', \"''\", 'and', 'the', 'cyber', 'security', 'issue', 'have', 'never', 'been', 'more', 'at', 'the', 'forefront', 'of', 'policy', '.']\n",
      "['Whether', 'we'] => are\n",
      "['Whether', 'we', 'are'] => talking\n",
      "['Whether', 'we', 'are', 'talking'] => about\n",
      "['Whether', 'we', 'are', 'talking', 'about'] => laws\n",
      "['Whether', 'we', 'are', 'talking', 'about', 'laws'] => like\n",
      "['we', 'are'] => talking\n",
      "['we', 'are', 'talking'] => about\n",
      "['we', 'are', 'talking', 'about'] => laws\n",
      "['we', 'are', 'talking', 'about', 'laws'] => like\n",
      "['are', 'talking'] => about\n",
      "['are', 'talking', 'about'] => laws\n",
      "['are', 'talking', 'about', 'laws'] => like\n",
      "['talking', 'about'] => laws\n",
      "['talking', 'about', 'laws'] => like\n",
      "['about', 'laws'] => like\n",
      "['And', 'you', 'ai', \"n't\", 'seen', 'nothing', 'yet', '.']\n",
      "['And', 'you'] => ai\n",
      "['And', 'you', 'ai'] => n't\n",
      "['And', 'you', 'ai', \"n't\"] => seen\n",
      "['And', 'you', 'ai', \"n't\", 'seen'] => nothing\n",
      "['And', 'you', 'ai', \"n't\", 'seen', 'nothing'] => yet\n",
      "['you', 'ai'] => n't\n",
      "['you', 'ai', \"n't\"] => seen\n",
      "['you', 'ai', \"n't\", 'seen'] => nothing\n",
      "['you', 'ai', \"n't\", 'seen', 'nothing'] => yet\n",
      "['ai', \"n't\"] => seen\n",
      "['ai', \"n't\", 'seen'] => nothing\n",
      "['ai', \"n't\", 'seen', 'nothing'] => yet\n",
      "[\"n't\", 'seen'] => nothing\n",
      "[\"n't\", 'seen', 'nothing'] => yet\n",
      "['seen', 'nothing'] => yet\n",
      "['I', 'wish', 'that', 'I', 'could', 'tell', 'you', 'that', 'it', 'is', 'still', 'possible', 'for', 'one', 'person', 'to', 'hold', 'the', 'big', 'picture', 'firmly', 'in', 'their', 'mind', \"'s\", 'eye', ',', 'to', 'track', 'everything', 'important', 'that', 'is', 'going', 'on', 'in', 'our', 'field', ',', 'to', 'make', 'few', 'if', 'any', 'sins', 'of', 'omission', '.']\n",
      "['I', 'wish'] => that\n",
      "['I', 'wish', 'that'] => I\n",
      "['I', 'wish', 'that', 'I'] => could\n",
      "['I', 'wish', 'that', 'I', 'could'] => tell\n",
      "['I', 'wish', 'that', 'I', 'could', 'tell'] => you\n",
      "['wish', 'that'] => I\n",
      "['wish', 'that', 'I'] => could\n",
      "['wish', 'that', 'I', 'could'] => tell\n",
      "['wish', 'that', 'I', 'could', 'tell'] => you\n",
      "['that', 'I'] => could\n",
      "['that', 'I', 'could'] => tell\n",
      "['that', 'I', 'could', 'tell'] => you\n",
      "['I', 'could'] => tell\n",
      "['I', 'could', 'tell'] => you\n",
      "['could', 'tell'] => you\n",
      "['It', 'is', 'not', 'possible', ';', 'that', 'phase', 'passed', 'sometime', 'in', 'the', 'last', 'six', 'years', '.']\n",
      "['It', 'is'] => not\n",
      "['It', 'is', 'not'] => possible\n",
      "['It', 'is', 'not', 'possible'] => ;\n",
      "['It', 'is', 'not', 'possible', ';'] => that\n",
      "['It', 'is', 'not', 'possible', ';', 'that'] => phase\n",
      "['is', 'not'] => possible\n",
      "['is', 'not', 'possible'] => ;\n",
      "['is', 'not', 'possible', ';'] => that\n",
      "['is', 'not', 'possible', ';', 'that'] => phase\n",
      "['not', 'possible'] => ;\n",
      "['not', 'possible', ';'] => that\n",
      "['not', 'possible', ';', 'that'] => phase\n",
      "['possible', ';'] => that\n",
      "['possible', ';', 'that'] => phase\n",
      "[';', 'that'] => phase\n",
      "['I', 'have', 'certainly', 'tried', 'to', 'keep', 'up', 'but', 'I', 'would', 'be', 'less', 'than', 'candid', 'if', 'I', 'were', 'not', 'to', 'say', 'that', 'I', 'know', 'that', 'I', 'am', 'not', 'keeping', 'up', ',', 'not', 'even', 'keeping', 'up', 'with', 'what', 'is', 'going', 'on', 'in', 'my', 'own', 'country', 'much', 'less', 'all', 'countries', '.']\n",
      "['I', 'have'] => certainly\n",
      "['I', 'have', 'certainly'] => tried\n",
      "['I', 'have', 'certainly', 'tried'] => to\n",
      "['I', 'have', 'certainly', 'tried', 'to'] => keep\n",
      "['I', 'have', 'certainly', 'tried', 'to', 'keep'] => up\n",
      "['have', 'certainly'] => tried\n",
      "['have', 'certainly', 'tried'] => to\n",
      "['have', 'certainly', 'tried', 'to'] => keep\n",
      "['have', 'certainly', 'tried', 'to', 'keep'] => up\n",
      "['certainly', 'tried'] => to\n",
      "['certainly', 'tried', 'to'] => keep\n",
      "['certainly', 'tried', 'to', 'keep'] => up\n",
      "['tried', 'to'] => keep\n",
      "['tried', 'to', 'keep'] => up\n",
      "['to', 'keep'] => up\n",
      "['Not', 'only', 'has', 'cybersecurity', 'reached', 'the', 'highest', 'levels', 'of', 'attention', ',', 'it', 'has', 'spread', 'into', 'nearly', 'every', 'corner', '.']\n",
      "['Not', 'only'] => has\n",
      "['Not', 'only', 'has'] => cybersecurity\n",
      "['Not', 'only', 'has', 'cybersecurity'] => reached\n",
      "['Not', 'only', 'has', 'cybersecurity', 'reached'] => the\n",
      "['Not', 'only', 'has', 'cybersecurity', 'reached', 'the'] => highest\n",
      "['only', 'has'] => cybersecurity\n",
      "['only', 'has', 'cybersecurity'] => reached\n",
      "['only', 'has', 'cybersecurity', 'reached'] => the\n",
      "['only', 'has', 'cybersecurity', 'reached', 'the'] => highest\n",
      "['has', 'cybersecurity'] => reached\n",
      "['has', 'cybersecurity', 'reached'] => the\n",
      "['has', 'cybersecurity', 'reached', 'the'] => highest\n",
      "['cybersecurity', 'reached'] => the\n",
      "['cybersecurity', 'reached', 'the'] => highest\n",
      "['reached', 'the'] => highest\n",
      "['If', 'area', 'is', 'the', 'product', 'of', 'height', 'and', 'width', ',', 'then', 'the', 'footprint', 'of', 'cybersecurity', 'has', 'surpassed', 'the', 'grasp', 'of', 'any', 'one', 'of', 'us', '.']\n",
      "['If', 'area'] => is\n",
      "['If', 'area', 'is'] => the\n",
      "['If', 'area', 'is', 'the'] => product\n",
      "['If', 'area', 'is', 'the', 'product'] => of\n",
      "['If', 'area', 'is', 'the', 'product', 'of'] => height\n",
      "['area', 'is'] => the\n",
      "['area', 'is', 'the'] => product\n",
      "['area', 'is', 'the', 'product'] => of\n",
      "['area', 'is', 'the', 'product', 'of'] => height\n",
      "['is', 'the'] => product\n",
      "['is', 'the', 'product'] => of\n",
      "['is', 'the', 'product', 'of'] => height\n",
      "['the', 'product'] => of\n",
      "['the', 'product', 'of'] => height\n",
      "['product', 'of'] => height\n",
      "['The', 'rate', 'of', 'technological', 'change', 'is', 'certainly', 'a', 'part', 'of', 'it', '.']\n",
      "['The', 'rate'] => of\n",
      "['The', 'rate', 'of'] => technological\n",
      "['The', 'rate', 'of', 'technological'] => change\n",
      "['The', 'rate', 'of', 'technological', 'change'] => is\n",
      "['The', 'rate', 'of', 'technological', 'change', 'is'] => certainly\n",
      "['rate', 'of'] => technological\n",
      "['rate', 'of', 'technological'] => change\n",
      "['rate', 'of', 'technological', 'change'] => is\n",
      "['rate', 'of', 'technological', 'change', 'is'] => certainly\n",
      "['of', 'technological'] => change\n",
      "['of', 'technological', 'change'] => is\n",
      "['of', 'technological', 'change', 'is'] => certainly\n",
      "['technological', 'change'] => is\n",
      "['technological', 'change', 'is'] => certainly\n",
      "['change', 'is'] => certainly\n",
      "['When', 'younger', 'people', 'ask', 'my', 'advice', 'on', 'what', 'they', 'should', 'do', 'or', 'study', 'to', 'make', 'a', 'career', 'in', 'cyber', 'security', ',', 'I', 'can', 'only', 'advise', 'specialization', '.']\n",
      "['When', 'younger'] => people\n",
      "['When', 'younger', 'people'] => ask\n",
      "['When', 'younger', 'people', 'ask'] => my\n",
      "['When', 'younger', 'people', 'ask', 'my'] => advice\n",
      "['When', 'younger', 'people', 'ask', 'my', 'advice'] => on\n",
      "['younger', 'people'] => ask\n",
      "['younger', 'people', 'ask'] => my\n",
      "['younger', 'people', 'ask', 'my'] => advice\n",
      "['younger', 'people', 'ask', 'my', 'advice'] => on\n",
      "['people', 'ask'] => my\n",
      "['people', 'ask', 'my'] => advice\n",
      "['people', 'ask', 'my', 'advice'] => on\n",
      "['ask', 'my'] => advice\n",
      "['ask', 'my', 'advice'] => on\n",
      "['my', 'advice'] => on\n",
      "['Those', 'of', 'us', 'who', 'were', 'in', 'the', 'game', 'early', 'enough', 'and', 'who', 'have', 'managed', 'to', 'retain', 'an', 'over-arching', 'generalist', 'knowledge', 'ca', \"n't\", 'be', 'replaced', 'very', 'easily', 'because', 'while', 'absorbing', 'most', 'new', 'information', 'most', 'of', 'the', 'time', 'may', 'have', 'been', 'possible', 'when', 'we', 'began', 'practice', ',', 'no', 'person', 'starting', 'from', 'scratch', 'can', 'do', 'that', 'now', '.']\n",
      "['Those', 'of'] => us\n",
      "['Those', 'of', 'us'] => who\n",
      "['Those', 'of', 'us', 'who'] => were\n",
      "['Those', 'of', 'us', 'who', 'were'] => in\n",
      "['Those', 'of', 'us', 'who', 'were', 'in'] => the\n",
      "['of', 'us'] => who\n",
      "['of', 'us', 'who'] => were\n",
      "['of', 'us', 'who', 'were'] => in\n",
      "['of', 'us', 'who', 'were', 'in'] => the\n",
      "['us', 'who'] => were\n",
      "['us', 'who', 'were'] => in\n",
      "['us', 'who', 'were', 'in'] => the\n",
      "['who', 'were'] => in\n",
      "['who', 'were', 'in'] => the\n",
      "['were', 'in'] => the\n",
      "['Serial', 'specialization', 'is', 'now', 'all', 'that', 'can', 'be', 'done', 'in', 'any', 'practical', 'way', '.']\n",
      "['Serial', 'specialization'] => is\n",
      "['Serial', 'specialization', 'is'] => now\n",
      "['Serial', 'specialization', 'is', 'now'] => all\n",
      "['Serial', 'specialization', 'is', 'now', 'all'] => that\n",
      "['Serial', 'specialization', 'is', 'now', 'all', 'that'] => can\n",
      "['specialization', 'is'] => now\n",
      "['specialization', 'is', 'now'] => all\n",
      "['specialization', 'is', 'now', 'all'] => that\n",
      "['specialization', 'is', 'now', 'all', 'that'] => can\n",
      "['is', 'now'] => all\n",
      "['is', 'now', 'all'] => that\n",
      "['is', 'now', 'all', 'that'] => can\n",
      "['now', 'all'] => that\n",
      "['now', 'all', 'that'] => can\n",
      "['all', 'that'] => can\n",
      "['Just', 'looking', 'at', 'the', 'Black', 'Hat', 'program', 'will', 'confirm', 'that', 'being', 'really', 'good', 'at', 'any', 'one', 'of', 'the', 'many', 'topics', 'presented', 'here', 'all', 'but', 'requires', 'shutting', 'out', 'the', 'demands', 'of', 'being', 'good', 'at', 'any', 'others', '.']\n",
      "['Just', 'looking'] => at\n",
      "['Just', 'looking', 'at'] => the\n",
      "['Just', 'looking', 'at', 'the'] => Black\n",
      "['Just', 'looking', 'at', 'the', 'Black'] => Hat\n",
      "['Just', 'looking', 'at', 'the', 'Black', 'Hat'] => program\n",
      "['looking', 'at'] => the\n",
      "['looking', 'at', 'the'] => Black\n",
      "['looking', 'at', 'the', 'Black'] => Hat\n",
      "['looking', 'at', 'the', 'Black', 'Hat'] => program\n",
      "['at', 'the'] => Black\n",
      "['at', 'the', 'Black'] => Hat\n",
      "['at', 'the', 'Black', 'Hat'] => program\n",
      "['the', 'Black'] => Hat\n",
      "['the', 'Black', 'Hat'] => program\n",
      "['Black', 'Hat'] => program\n",
      "['Why', 'does', 'that', 'matter', '?']\n",
      "['Why', 'does'] => that\n",
      "['Why', 'does', 'that'] => matter\n",
      "['Why', 'does', 'that', 'matter'] => ?\n",
      "['does', 'that'] => matter\n",
      "['does', 'that', 'matter'] => ?\n",
      "['that', 'matter'] => ?\n",
      "['Speaking', 'for', 'myself', ',', 'I', 'am', 'not', 'interested', 'in', 'the', 'advantages', 'or', 'disadvantages', 'of', 'some', 'bit', 'of', 'technology', 'unless', 'I', 'can', 'grasp', 'how', 'it', 'is', 'that', 'that', 'technology', 'works', '.']\n",
      "['Speaking', 'for'] => myself\n",
      "['Speaking', 'for', 'myself'] => ,\n",
      "['Speaking', 'for', 'myself', ','] => I\n",
      "['Speaking', 'for', 'myself', ',', 'I'] => am\n",
      "['Speaking', 'for', 'myself', ',', 'I', 'am'] => not\n",
      "['for', 'myself'] => ,\n",
      "['for', 'myself', ','] => I\n",
      "['for', 'myself', ',', 'I'] => am\n",
      "['for', 'myself', ',', 'I', 'am'] => not\n",
      "['myself', ','] => I\n",
      "['myself', ',', 'I'] => am\n",
      "['myself', ',', 'I', 'am'] => not\n",
      "[',', 'I'] => am\n",
      "[',', 'I', 'am'] => not\n",
      "['I', 'am'] => not\n",
      "['Whenever', 'I', 'see', 'marketing', 'material', 'that', 'tells', 'me', 'all', 'the', 'good', 'things', 'that', 'adopting', 'this', 'or', 'that', 'technology', 'makes', 'possible', ',', 'I', 'remember', 'what', 'George', 'Santayana', 'said', ',', 'that', '``', 'Scepticism', 'is', 'the', 'chastity', 'of', 'the', 'intellect', ';', 'it', 'is', 'shameful', 'to', 'give', 'it', 'up', 'too', 'soon', ',', 'or', 'to', 'the', 'first', 'comer', '.', \"''\"]\n",
      "['Whenever', 'I'] => see\n",
      "['Whenever', 'I', 'see'] => marketing\n",
      "['Whenever', 'I', 'see', 'marketing'] => material\n",
      "['Whenever', 'I', 'see', 'marketing', 'material'] => that\n",
      "['Whenever', 'I', 'see', 'marketing', 'material', 'that'] => tells\n",
      "['I', 'see'] => marketing\n",
      "['I', 'see', 'marketing'] => material\n",
      "['I', 'see', 'marketing', 'material'] => that\n",
      "['I', 'see', 'marketing', 'material', 'that'] => tells\n",
      "['see', 'marketing'] => material\n",
      "['see', 'marketing', 'material'] => that\n",
      "['see', 'marketing', 'material', 'that'] => tells\n",
      "['marketing', 'material'] => that\n",
      "['marketing', 'material', 'that'] => tells\n",
      "['material', 'that'] => tells\n",
      "['I', 'suspect', 'that', 'a', 'majority', 'of', 'you', 'have', 'similar', 'skepticism', '--', '``', 'It', \"'s\", 'magic', '!', \"''\"]\n",
      "['I', 'suspect'] => that\n",
      "['I', 'suspect', 'that'] => a\n",
      "['I', 'suspect', 'that', 'a'] => majority\n",
      "['I', 'suspect', 'that', 'a', 'majority'] => of\n",
      "['I', 'suspect', 'that', 'a', 'majority', 'of'] => you\n",
      "['suspect', 'that'] => a\n",
      "['suspect', 'that', 'a'] => majority\n",
      "['suspect', 'that', 'a', 'majority'] => of\n",
      "['suspect', 'that', 'a', 'majority', 'of'] => you\n",
      "['that', 'a'] => majority\n",
      "['that', 'a', 'majority'] => of\n",
      "['that', 'a', 'majority', 'of'] => you\n",
      "['a', 'majority'] => of\n",
      "['a', 'majority', 'of'] => you\n",
      "['majority', 'of'] => you\n",
      "['is', 'not', 'the', 'answer', 'a', 'security', 'person', 'will', 'ever', 'accept', '.']\n",
      "['is', 'not'] => the\n",
      "['is', 'not', 'the'] => answer\n",
      "['is', 'not', 'the', 'answer'] => a\n",
      "['is', 'not', 'the', 'answer', 'a'] => security\n",
      "['is', 'not', 'the', 'answer', 'a', 'security'] => person\n",
      "['not', 'the'] => answer\n",
      "['not', 'the', 'answer'] => a\n",
      "['not', 'the', 'answer', 'a'] => security\n",
      "['not', 'the', 'answer', 'a', 'security'] => person\n",
      "['the', 'answer'] => a\n",
      "['the', 'answer', 'a'] => security\n",
      "['the', 'answer', 'a', 'security'] => person\n",
      "['answer', 'a'] => security\n",
      "['answer', 'a', 'security'] => person\n",
      "['a', 'security'] => person\n",
      "['By', 'and', 'large', ',', 'I', 'can', 'tell', '*', 'what', '*', 'something', 'is', 'good', 'for', 'once', 'I', 'know', '*', 'how', '*', 'it', 'works', '.']\n",
      "['By', 'and'] => large\n",
      "['By', 'and', 'large'] => ,\n",
      "['By', 'and', 'large', ','] => I\n",
      "['By', 'and', 'large', ',', 'I'] => can\n",
      "['By', 'and', 'large', ',', 'I', 'can'] => tell\n",
      "['and', 'large'] => ,\n",
      "['and', 'large', ','] => I\n",
      "['and', 'large', ',', 'I'] => can\n",
      "['and', 'large', ',', 'I', 'can'] => tell\n",
      "['large', ','] => I\n",
      "['large', ',', 'I'] => can\n",
      "['large', ',', 'I', 'can'] => tell\n",
      "[',', 'I'] => can\n",
      "[',', 'I', 'can'] => tell\n",
      "['I', 'can'] => tell\n",
      "['Tell', 'me', 'how', 'it', 'works', 'and', 'then', ',', 'but', 'only', 'then', ',', 'tell', 'me', 'why', 'you', 'have', 'chosen', 'to', 'use', 'those', 'particular', 'mechanisms', 'for', 'the', 'things', 'you', 'have', 'chosen', 'to', 'use', 'them', 'for', '.']\n",
      "['Tell', 'me'] => how\n",
      "['Tell', 'me', 'how'] => it\n",
      "['Tell', 'me', 'how', 'it'] => works\n",
      "['Tell', 'me', 'how', 'it', 'works'] => and\n",
      "['Tell', 'me', 'how', 'it', 'works', 'and'] => then\n",
      "['me', 'how'] => it\n",
      "['me', 'how', 'it'] => works\n",
      "['me', 'how', 'it', 'works'] => and\n",
      "['me', 'how', 'it', 'works', 'and'] => then\n",
      "['how', 'it'] => works\n",
      "['how', 'it', 'works'] => and\n",
      "['how', 'it', 'works', 'and'] => then\n",
      "['it', 'works'] => and\n",
      "['it', 'works', 'and'] => then\n",
      "['works', 'and'] => then\n",
      "['Part', 'of', 'my', 'feeling', 'stems', 'from', 'a', 'long-held', 'and', 'well-substantiated', 'belief', 'that', 'all', 'cyber', 'security', 'technology', 'is', 'dual', 'use', '.']\n",
      "['Part', 'of'] => my\n",
      "['Part', 'of', 'my'] => feeling\n",
      "['Part', 'of', 'my', 'feeling'] => stems\n",
      "['Part', 'of', 'my', 'feeling', 'stems'] => from\n",
      "['Part', 'of', 'my', 'feeling', 'stems', 'from'] => a\n",
      "['of', 'my'] => feeling\n",
      "['of', 'my', 'feeling'] => stems\n",
      "['of', 'my', 'feeling', 'stems'] => from\n",
      "['of', 'my', 'feeling', 'stems', 'from'] => a\n",
      "['my', 'feeling'] => stems\n",
      "['my', 'feeling', 'stems'] => from\n",
      "['my', 'feeling', 'stems', 'from'] => a\n",
      "['feeling', 'stems'] => from\n",
      "['feeling', 'stems', 'from'] => a\n",
      "['stems', 'from'] => a\n",
      "['Perhaps', 'dual', 'use', 'is', 'a', 'truism', 'for', 'any', 'and', 'all', 'tools', 'from', 'the', 'scalpel', 'to', 'the', 'hammer', 'to', 'the', 'gas', 'can', '--', 'they', 'can', 'be', 'used', 'for', 'good', 'or', 'ill', '--', 'but', 'I', 'know', 'that', 'dual', 'use', 'is', 'inherent', 'in', 'cyber', 'security', 'tools', '.']\n",
      "['Perhaps', 'dual'] => use\n",
      "['Perhaps', 'dual', 'use'] => is\n",
      "['Perhaps', 'dual', 'use', 'is'] => a\n",
      "['Perhaps', 'dual', 'use', 'is', 'a'] => truism\n",
      "['Perhaps', 'dual', 'use', 'is', 'a', 'truism'] => for\n",
      "['dual', 'use'] => is\n",
      "['dual', 'use', 'is'] => a\n",
      "['dual', 'use', 'is', 'a'] => truism\n",
      "['dual', 'use', 'is', 'a', 'truism'] => for\n",
      "['use', 'is'] => a\n",
      "['use', 'is', 'a'] => truism\n",
      "['use', 'is', 'a', 'truism'] => for\n",
      "['is', 'a'] => truism\n",
      "['is', 'a', 'truism'] => for\n",
      "['a', 'truism'] => for\n",
      "['If', 'your', 'definition', 'of', '``', 'tool', \"''\", 'is', 'wide', 'enough', ',', 'I', 'suggest', 'that', 'the', 'cyber', 'security', 'tool-set', 'favors', 'offense', 'these', 'days', '.']\n",
      "['If', 'your'] => definition\n",
      "['If', 'your', 'definition'] => of\n",
      "['If', 'your', 'definition', 'of'] => ``\n",
      "['If', 'your', 'definition', 'of', '``'] => tool\n",
      "['If', 'your', 'definition', 'of', '``', 'tool'] => ''\n",
      "['your', 'definition'] => of\n",
      "['your', 'definition', 'of'] => ``\n",
      "['your', 'definition', 'of', '``'] => tool\n",
      "['your', 'definition', 'of', '``', 'tool'] => ''\n",
      "['definition', 'of'] => ``\n",
      "['definition', 'of', '``'] => tool\n",
      "['definition', 'of', '``', 'tool'] => ''\n",
      "['of', '``'] => tool\n",
      "['of', '``', 'tool'] => ''\n",
      "['``', 'tool'] => ''\n",
      "['Chris', 'Inglis', ',', 'recently', 'retired', 'NSA', 'Deputy', 'Director', ',', 'remarked', 'that', 'if', 'we', 'were', 'to', 'score', 'cyber', 'the', 'way', 'we', 'score', 'soccer', ',', 'the', 'tally', 'would', 'be', '462-456', 'twenty', 'minutes', 'into', 'the', 'game', ',', '[', 'CI', ']', 'i.e.', ',', 'all', 'offense', '.']\n",
      "['Chris', 'Inglis'] => ,\n",
      "['Chris', 'Inglis', ','] => recently\n",
      "['Chris', 'Inglis', ',', 'recently'] => retired\n",
      "['Chris', 'Inglis', ',', 'recently', 'retired'] => NSA\n",
      "['Chris', 'Inglis', ',', 'recently', 'retired', 'NSA'] => Deputy\n",
      "['Inglis', ','] => recently\n",
      "['Inglis', ',', 'recently'] => retired\n",
      "['Inglis', ',', 'recently', 'retired'] => NSA\n",
      "['Inglis', ',', 'recently', 'retired', 'NSA'] => Deputy\n",
      "[',', 'recently'] => retired\n",
      "[',', 'recently', 'retired'] => NSA\n",
      "[',', 'recently', 'retired', 'NSA'] => Deputy\n",
      "['recently', 'retired'] => NSA\n",
      "['recently', 'retired', 'NSA'] => Deputy\n",
      "['retired', 'NSA'] => Deputy\n",
      "['I', 'will', 'take', 'his', 'comment', 'as', 'confirming', 'at', 'the', 'highest', 'level', 'not', 'only', 'the', 'dual', 'use', 'nature', 'of', 'cybersecurity', 'but', 'also', 'confirming', 'that', 'offense', 'is', 'where', 'the', 'innovations', 'that', 'only', 'States', 'can', 'afford', 'is', 'going', 'on', '.']\n",
      "['I', 'will'] => take\n",
      "['I', 'will', 'take'] => his\n",
      "['I', 'will', 'take', 'his'] => comment\n",
      "['I', 'will', 'take', 'his', 'comment'] => as\n",
      "['I', 'will', 'take', 'his', 'comment', 'as'] => confirming\n",
      "['will', 'take'] => his\n",
      "['will', 'take', 'his'] => comment\n",
      "['will', 'take', 'his', 'comment'] => as\n",
      "['will', 'take', 'his', 'comment', 'as'] => confirming\n",
      "['take', 'his'] => comment\n",
      "['take', 'his', 'comment'] => as\n",
      "['take', 'his', 'comment', 'as'] => confirming\n",
      "['his', 'comment'] => as\n",
      "['his', 'comment', 'as'] => confirming\n",
      "['comment', 'as'] => confirming\n",
      "['Nevertheless', ',', 'this', 'essay', 'is', 'an', 'outgrowth', 'from', ',', 'an', 'extension', 'of', ',', 'that', 'increasing', 'importance', 'of', 'cybersecurity', '.']\n",
      "['Nevertheless', ','] => this\n",
      "['Nevertheless', ',', 'this'] => essay\n",
      "['Nevertheless', ',', 'this', 'essay'] => is\n",
      "['Nevertheless', ',', 'this', 'essay', 'is'] => an\n",
      "['Nevertheless', ',', 'this', 'essay', 'is', 'an'] => outgrowth\n",
      "[',', 'this'] => essay\n",
      "[',', 'this', 'essay'] => is\n",
      "[',', 'this', 'essay', 'is'] => an\n",
      "[',', 'this', 'essay', 'is', 'an'] => outgrowth\n",
      "['this', 'essay'] => is\n",
      "['this', 'essay', 'is'] => an\n",
      "['this', 'essay', 'is', 'an'] => outgrowth\n",
      "['essay', 'is'] => an\n",
      "['essay', 'is', 'an'] => outgrowth\n",
      "['is', 'an'] => outgrowth\n",
      "['With', 'the', 'humility', 'of', 'which', 'I', 'spoke', ',', 'I', 'do', 'not', 'claim', 'that', 'I', 'have', 'the', 'last', 'word', '.']\n",
      "['With', 'the'] => humility\n",
      "['With', 'the', 'humility'] => of\n",
      "['With', 'the', 'humility', 'of'] => which\n",
      "['With', 'the', 'humility', 'of', 'which'] => I\n",
      "['With', 'the', 'humility', 'of', 'which', 'I'] => spoke\n",
      "['the', 'humility'] => of\n",
      "['the', 'humility', 'of'] => which\n",
      "['the', 'humility', 'of', 'which'] => I\n",
      "['the', 'humility', 'of', 'which', 'I'] => spoke\n",
      "['humility', 'of'] => which\n",
      "['humility', 'of', 'which'] => I\n",
      "['humility', 'of', 'which', 'I'] => spoke\n",
      "['of', 'which'] => I\n",
      "['of', 'which', 'I'] => spoke\n",
      "['which', 'I'] => spoke\n",
      "['What', 'I', 'do', 'claim', 'is', 'that', 'when', 'we', 'speak', 'about', 'cybersecurity', 'policy', 'we', 'are', 'no', 'longer', 'engaging', 'in', 'some', 'sort', 'of', 'parlor', 'game', '.']\n",
      "['What', 'I'] => do\n",
      "['What', 'I', 'do'] => claim\n",
      "['What', 'I', 'do', 'claim'] => is\n",
      "['What', 'I', 'do', 'claim', 'is'] => that\n",
      "['What', 'I', 'do', 'claim', 'is', 'that'] => when\n",
      "['I', 'do'] => claim\n",
      "['I', 'do', 'claim'] => is\n",
      "['I', 'do', 'claim', 'is'] => that\n",
      "['I', 'do', 'claim', 'is', 'that'] => when\n",
      "['do', 'claim'] => is\n",
      "['do', 'claim', 'is'] => that\n",
      "['do', 'claim', 'is', 'that'] => when\n",
      "['claim', 'is'] => that\n",
      "['claim', 'is', 'that'] => when\n",
      "['is', 'that'] => when\n",
      "['I', 'claim', 'that', 'policy', 'matters', 'are', 'now', 'the', 'most', 'important', 'matters', ',', 'that', 'once', 'a', 'topic', 'area', ',', 'like', 'cybersecurity', ',', 'becomes', 'interlaced', 'with', 'nearly', 'every', 'aspect', 'of', 'life', 'for', 'nearly', 'everybody', ',', 'the', 'outcome', 'differential', 'between', 'good', 'policies', 'and', 'bad', 'policies', 'broadens', ',', 'and', 'the', 'ease', 'of', 'finding', 'answers', 'falls', '.']\n",
      "['I', 'claim'] => that\n",
      "['I', 'claim', 'that'] => policy\n",
      "['I', 'claim', 'that', 'policy'] => matters\n",
      "['I', 'claim', 'that', 'policy', 'matters'] => are\n",
      "['I', 'claim', 'that', 'policy', 'matters', 'are'] => now\n",
      "['claim', 'that'] => policy\n",
      "['claim', 'that', 'policy'] => matters\n",
      "['claim', 'that', 'policy', 'matters'] => are\n",
      "['claim', 'that', 'policy', 'matters', 'are'] => now\n",
      "['that', 'policy'] => matters\n",
      "['that', 'policy', 'matters'] => are\n",
      "['that', 'policy', 'matters', 'are'] => now\n",
      "['policy', 'matters'] => are\n",
      "['policy', 'matters', 'are'] => now\n",
      "['matters', 'are'] => now\n",
      "['As', 'H.L', '.']\n",
      "['As', 'H.L'] => .\n",
      "['Mencken', 'so', 'trenchantly', 'put', 'it', ',', '``', 'For', 'every', 'complex', 'problem', 'there', 'is', 'a', 'solution', 'that', 'is', 'clear', ',', 'simple', ',', 'and', 'wrong', '.', \"''\"]\n",
      "['Mencken', 'so'] => trenchantly\n",
      "['Mencken', 'so', 'trenchantly'] => put\n",
      "['Mencken', 'so', 'trenchantly', 'put'] => it\n",
      "['Mencken', 'so', 'trenchantly', 'put', 'it'] => ,\n",
      "['Mencken', 'so', 'trenchantly', 'put', 'it', ','] => ``\n",
      "['so', 'trenchantly'] => put\n",
      "['so', 'trenchantly', 'put'] => it\n",
      "['so', 'trenchantly', 'put', 'it'] => ,\n",
      "['so', 'trenchantly', 'put', 'it', ','] => ``\n",
      "['trenchantly', 'put'] => it\n",
      "['trenchantly', 'put', 'it'] => ,\n",
      "['trenchantly', 'put', 'it', ','] => ``\n",
      "['put', 'it'] => ,\n",
      "['put', 'it', ','] => ``\n",
      "['it', ','] => ``\n",
      "['The', 'four', 'verities', 'of', 'government', 'are', 'these', ':', '.']\n",
      "['The', 'four'] => verities\n",
      "['The', 'four', 'verities'] => of\n",
      "['The', 'four', 'verities', 'of'] => government\n",
      "['The', 'four', 'verities', 'of', 'government'] => are\n",
      "['The', 'four', 'verities', 'of', 'government', 'are'] => these\n",
      "['four', 'verities'] => of\n",
      "['four', 'verities', 'of'] => government\n",
      "['four', 'verities', 'of', 'government'] => are\n",
      "['four', 'verities', 'of', 'government', 'are'] => these\n",
      "['verities', 'of'] => government\n",
      "['verities', 'of', 'government'] => are\n",
      "['verities', 'of', 'government', 'are'] => these\n",
      "['of', 'government'] => are\n",
      "['of', 'government', 'are'] => these\n",
      "['government', 'are'] => these\n",
      "['Most', 'important', 'ideas', 'are', 'unappealing', '.']\n",
      "['Most', 'important'] => ideas\n",
      "['Most', 'important', 'ideas'] => are\n",
      "['Most', 'important', 'ideas', 'are'] => unappealing\n",
      "['Most', 'important', 'ideas', 'are', 'unappealing'] => .\n",
      "['important', 'ideas'] => are\n",
      "['important', 'ideas', 'are'] => unappealing\n",
      "['important', 'ideas', 'are', 'unappealing'] => .\n",
      "['ideas', 'are'] => unappealing\n",
      "['ideas', 'are', 'unappealing'] => .\n",
      "['are', 'unappealing'] => .\n",
      "['Most', 'appealing', 'ideas', 'are', 'unimportant', '.']\n",
      "['Most', 'appealing'] => ideas\n",
      "['Most', 'appealing', 'ideas'] => are\n",
      "['Most', 'appealing', 'ideas', 'are'] => unimportant\n",
      "['Most', 'appealing', 'ideas', 'are', 'unimportant'] => .\n",
      "['appealing', 'ideas'] => are\n",
      "['appealing', 'ideas', 'are'] => unimportant\n",
      "['appealing', 'ideas', 'are', 'unimportant'] => .\n",
      "['ideas', 'are'] => unimportant\n",
      "['ideas', 'are', 'unimportant'] => .\n",
      "['are', 'unimportant'] => .\n",
      "['Not', 'every', 'problem', 'has', 'a', 'good', 'solution', '.']\n",
      "['Not', 'every'] => problem\n",
      "['Not', 'every', 'problem'] => has\n",
      "['Not', 'every', 'problem', 'has'] => a\n",
      "['Not', 'every', 'problem', 'has', 'a'] => good\n",
      "['Not', 'every', 'problem', 'has', 'a', 'good'] => solution\n",
      "['every', 'problem'] => has\n",
      "['every', 'problem', 'has'] => a\n",
      "['every', 'problem', 'has', 'a'] => good\n",
      "['every', 'problem', 'has', 'a', 'good'] => solution\n",
      "['problem', 'has'] => a\n",
      "['problem', 'has', 'a'] => good\n",
      "['problem', 'has', 'a', 'good'] => solution\n",
      "['has', 'a'] => good\n",
      "['has', 'a', 'good'] => solution\n",
      "['a', 'good'] => solution\n",
      "['Every', 'solution', 'has', 'side', 'effects']\n",
      "['Every', 'solution'] => has\n",
      "['Every', 'solution', 'has'] => side\n",
      "['Every', 'solution', 'has', 'side'] => effects\n",
      "['solution', 'has'] => side\n",
      "['solution', 'has', 'side'] => effects\n",
      "['has', 'side'] => effects\n"
     ]
    }
   ],
   "source": [
    "from nltk import word_tokenize\n",
    "wordTokenizedSentence=[]\n",
    "for sentence in sentences:\n",
    "    wordTokenizedSentence.append(word_tokenize(sentence))\n",
    "\n",
    "x=[]\n",
    "y=[]\n",
    "for sentence in wordTokenizedSentence:\n",
    "    print(sentence)\n",
    "    for i in range(len(sentence)):\n",
    "        j=i+1\n",
    "        while j <= 5:\n",
    "            try:\n",
    "                y.append(sentence[j])\n",
    "                x.append(sentence[i:j])\n",
    "                j+=1\n",
    "                print(sentence[i:j],'=>',sentence[j])\n",
    "            except:\n",
    "                j+=1\n",
    "                continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "55afcd9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([['['],\n",
       "  ['[', 'nominal'],\n",
       "  ['[', 'nominal', 'delivery'],\n",
       "  ['[', 'nominal', 'delivery', 'draft'],\n",
       "  ['[', 'nominal', 'delivery', 'draft', ',']],\n",
       " ['nominal', 'delivery', 'draft', ',', '6'])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:5],y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9e8b5337",
   "metadata": {},
   "outputs": [],
   "source": [
    "emeddingModel=Word2Vec(wordTokenizedSentence, vector_size=15, window=10, min_count=1, workers=4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b8c61530",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.06246194, -0.049209  ,  0.00407102, -0.02026014, -0.04346866,\n",
       "       -0.00748973, -0.0356756 ,  0.06222412, -0.03854244,  0.02709549,\n",
       "        0.00292689,  0.03292041,  0.01779463,  0.06369314,  0.00115686],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emeddingModel.wv['[']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b8383a3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.06246194, -0.049209  ,  0.00407102, -0.02026014, -0.04346866,\n",
       "        -0.00748973, -0.0356756 ,  0.06222412, -0.03854244,  0.02709549,\n",
       "         0.00292689,  0.03292041,  0.01779463,  0.06369314,  0.00115686]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "embeddings_x = []\n",
    "embeddings_y = []\n",
    "\n",
    "for sentence in x:\n",
    "    embeddings = []\n",
    "    for word in sentence:\n",
    "        try:\n",
    "            embeddings.append(emeddingModel.wv[word])  # Get the word2vec embedding\n",
    "        except:\n",
    "            continue\n",
    "    embeddings_x.append(np.array(embeddings))\n",
    "\n",
    "embeddings_x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "81040024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "459 {'that': 1, 'of': 2, 'is': 3, 'the': 4, 'i': 5, 'are': 6, 'it': 7, 'a': 8, 'to': 9, 'not': 10, 'has': 11, 'will': 12, 'and': 13, 'my': 14, 'cyber': 15, 'for': 16, 'in': 17, 'black': 18, 'security': 19, 'me': 20, 'can': 21, 'good': 22, 'as': 23, 'this': 24, 'all': 25, 'be': 26, 'when': 27, 'being': 28, 'tell': 29, 'from': 30, 'an': 31, 'which': 32, 'hat': 33, 'am': 34, 'tool': 35, '6': 36, 'cybersecurity': 37, 'taking': 38, 'discern': 39, 'beat': 40, 'again': 41, 'were': 42, 'laws': 43, 'nothing': 44, 'keep': 45, 'advice': 46, 'truism': 47, 'nsa': 48, 'have': 49, 'those': 50, 'works': 51, 'claim': 52, 'talk': 53, 'let': 54, 'about': 55, 'matters': 56, 'ideas': 57, 'you': 58, 'wish': 59, 'safety': 60, 'order': 61, 'timidity': 62, 'proposals': 63, 'saying': 64, 'now': 65, 'insult': 66, 'seen': 67, 'could': 68, 'possible': 69, 'reached': 70, 'product': 71, 'change': 72, 'material': 73, 'majority': 74, 'stems': 75, 'retired': 76, 'comment': 77, 'government': 78, 'unappealing': 79, 'unimportant': 80, 'effects': 81, 'who': 82, 'policy': 83, 'use': 84, 'do': 85, 'eye': 86, 'say': 87, 'talking': 88, 'every': 89, 'at': 90, 'draft': 91, 'professions': 92, 'humility': 93, 'mean': 94, 'means': 95, 'needed': 96, 'we': 97, 'tried': 98, 'technological': 99, 'ask': 100, 'matter': 101, 'marketing': 102, 'answer': 103, 'feeling': 104, 'recently': 105, 'his': 106, 'essay': 107, 'put': 108, 'side': 109, 'if': 110, 'us': 111, 'how': 112, \"n't\": 113, 'does': 114, 'myself': 115, 'or': 116, 'certainly': 117, 'only': 118, 'problem': 119, 'delivery': 120, 'clarity': 121, 'three': 122, 'two': 123, 'important': 124, 'people': 125, 'see': 126, 'large': 127, 'dual': 128, 'definition': 129, 'take': 130, 'trenchantly': 131, 'verities': 132, 'what': 133, 'but': 134, 'any': 135, 'solution': 136, 'ai': 137, 'with': 138, 'simple': 139, 'they': 140, 'practice': 141, 'area': 142, 'specialization': 143, 'most': 144, 'nominal': 145, 'plaintext': 146, 'some': 147, 'their': 148, 'person': 149, 'expect': 150, 'one': 151, 'know': 152, 'on': 153, 'up': 154, 'rate': 155, 'younger': 156, 'looking': 157, 'technology': 158, 'suspect': 159, 'your': 160, 'inglis': 161, 'h': 162, 'l': 163, 'so': 164, 'four': 165, 'appealing': 166, 'been': 167, 'policies': 168, 'may': 169, 'into': 170, 'well': 171, 'more': 172, 'taken': 173, 'going': 174, 'nearly': 175, 'then': 176, 'game': 177, 'offense': 178, 'speak': 179, 'today': 180, 'while': 181, 'later': 182, 'used': 183, 'get': 184, 'others': 185, 'there': 186, 'follow': 187, 'presented': 188, 'rather': 189, 'held': 190, 'belief': 191, 'wrong': 192, 'mind': 193, 'issue': 194, 'many': 195, 'than': 196, 'field': 197, 'topic': 198, 'seriously': 199, 'like': 200, 'act': 201, 'perhaps': 202, 'even': 203, 'make': 204, 'last': 205, 'would': 206, 'less': 207, 'keeping': 208, 'highest': 209, 'grasp': 210, 'part': 211, 'enough': 212, 'no': 213, 'way': 214, 'why': 215, 'things': 216, 'once': 217, 'chosen': 218, 'tools': 219, 'these': 220, 'score': 221, 'confirming': 222, 'august': 223, '2014': 224, 'realpolitik': 225, 'dan': 226, 'geer': 227, 'morning': 228, 'thank': 229, 'invitation': 230, 'made': 231, 'available': 232, 'organizers': 233, 'questions': 234, 'welcome': 235, 'contact': 236, 'reply': 237, 'repeat': 238, 'abstract': 239, 'power': 240, 'exists': 241, 'least': 242, 'worst': 243, 'thing': 244, 'fill': 245, 'vacuum': 246, 'wishful': 247, 'thinking': 248, 'practitioners': 249, 'state': 250, 'farming': 251, 'weather': 252, 'forecasting': 253, 'such': 254, 'assure': 255, 'recommendations': 256, 'strongly': 257, 'proven': 258, 'humble': 259, 'changes': 260, 'result': 261, 'considerable': 262, 'push': 263, 'back': 264, 'changing': 265, 'though': 266, 'speech': 267, 'riveting': 268, 'concern': 269, 'top': 270, 'venues': 271, 'note': 272, 'speaker': 273, 'writer': 274, 'practitioner': 275, 'wished': 276, 'its': 277, 'gotten': 278, 'same': 279, 'usefully': 280, 'coherently': 281, 'lastingly': 282, 'whether': 283, 'digital': 284, 'millenium': 285, 'copyright': 286, 'computer': 287, 'fraud': 288, 'abuse': 289, 'non': 290, 'lawmaking': 291, 'significant': 292, 'actions': 293, 'executive': 294, 'agencies': 295, 'undertaking': 296, 'never': 297, 'forefront': 298, \"ain't\": 299, 'yet': 300, 'still': 301, 'hold': 302, 'big': 303, 'picture': 304, 'firmly': 305, \"mind's\": 306, 'track': 307, 'everything': 308, 'our': 309, 'few': 310, 'sins': 311, 'omission': 312, 'phase': 313, 'passed': 314, 'sometime': 315, 'six': 316, 'years': 317, 'candid': 318, 'own': 319, 'country': 320, 'much': 321, 'countries': 322, 'levels': 323, 'attention': 324, 'spread': 325, 'corner': 326, 'height': 327, 'width': 328, 'footprint': 329, 'surpassed': 330, 'should': 331, 'study': 332, 'career': 333, 'advise': 334, 'early': 335, 'managed': 336, 'retain': 337, 'over': 338, 'arching': 339, 'generalist': 340, 'knowledge': 341, \"can't\": 342, 'replaced': 343, 'very': 344, 'easily': 345, 'because': 346, 'absorbing': 347, 'new': 348, 'information': 349, 'time': 350, 'began': 351, 'starting': 352, 'scratch': 353, 'serial': 354, 'done': 355, 'practical': 356, 'just': 357, 'program': 358, 'confirm': 359, 'really': 360, 'topics': 361, 'here': 362, 'requires': 363, 'shutting': 364, 'out': 365, 'demands': 366, 'speaking': 367, 'interested': 368, 'advantages': 369, 'disadvantages': 370, 'bit': 371, 'unless': 372, 'whenever': 373, 'tells': 374, 'adopting': 375, 'makes': 376, 'remember': 377, 'george': 378, 'santayana': 379, 'said': 380, 'scepticism': 381, 'chastity': 382, 'intellect': 383, 'shameful': 384, 'give': 385, 'too': 386, 'soon': 387, 'first': 388, 'comer': 389, 'similar': 390, 'skepticism': 391, \"it's\": 392, 'magic': 393, 'ever': 394, 'accept': 395, 'by': 396, 'something': 397, 'particular': 398, 'mechanisms': 399, 'them': 400, 'long': 401, 'substantiated': 402, 'scalpel': 403, 'hammer': 404, 'gas': 405, 'ill': 406, 'inherent': 407, 'wide': 408, 'suggest': 409, 'set': 410, 'favors': 411, 'days': 412, 'chris': 413, 'deputy': 414, 'director': 415, 'remarked': 416, 'soccer': 417, 'tally': 418, '462': 419, '456': 420, 'twenty': 421, 'minutes': 422, 'ci': 423, 'e': 424, 'level': 425, 'nature': 426, 'also': 427, 'where': 428, 'innovations': 429, 'states': 430, 'afford': 431, 'nevertheless': 432, 'outgrowth': 433, 'extension': 434, 'increasing': 435, 'importance': 436, 'spoke': 437, 'word': 438, 'longer': 439, 'engaging': 440, 'sort': 441, 'parlor': 442, 'becomes': 443, 'interlaced': 444, 'aspect': 445, 'life': 446, 'everybody': 447, 'outcome': 448, 'differential': 449, 'between': 450, 'bad': 451, 'broadens': 452, 'ease': 453, 'finding': 454, 'answers': 455, 'falls': 456, 'mencken': 457, 'complex': 458, 'clear': 459}\n"
     ]
    }
   ],
   "source": [
    "tokenizer.fit_on_texts(y)\n",
    "print(len(tokenizer.word_index),tokenizer.word_index)\n",
    "for word in y:\n",
    "    try:\n",
    "        e=tokenizer.texts_to_sequences([word])[0][0]\n",
    "    except:\n",
    "        e=0\n",
    "    embeddings_y.append(e)\n",
    "embeddings_y=np.array(embeddings_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0fe3efb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "743"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ade68493",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.06246194, -0.049209  ,  0.00407102, -0.02026014, -0.04346866,\n",
       "        -0.00748973, -0.0356756 ,  0.06222412, -0.03854244,  0.02709549,\n",
       "         0.00292689,  0.03292041,  0.01779463,  0.06369314,  0.00115686]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "56848993",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.06246194, -0.049209  ,  0.00407102, -0.02026014, -0.04346866,\n",
       "        -0.00748973, -0.0356756 ,  0.06222412, -0.03854244,  0.02709549,\n",
       "         0.00292689,  0.03292041,  0.01779463,  0.06369314,  0.00115686],\n",
       "       [-0.05683396,  0.05229538, -0.05341402,  0.0306057 ,  0.06263665,\n",
       "         0.03840695,  0.04100427,  0.05531496,  0.02296231, -0.0471125 ,\n",
       "         0.03942722, -0.05425759, -0.03720862,  0.03856581, -0.05377772]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_x[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "bc706c44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.06246194, -0.049209  ,  0.00407102, -0.02026014, -0.04346866,\n",
       "        -0.00748973, -0.0356756 ,  0.06222412, -0.03854244,  0.02709549,\n",
       "         0.00292689,  0.03292041,  0.01779463,  0.06369314,  0.00115686],\n",
       "       [-0.05683396,  0.05229538, -0.05341402,  0.0306057 ,  0.06263665,\n",
       "         0.03840695,  0.04100427,  0.05531496,  0.02296231, -0.0471125 ,\n",
       "         0.03942722, -0.05425759, -0.03720862,  0.03856581, -0.05377772],\n",
       "       [-0.03969079, -0.02383095,  0.02410348,  0.03382367,  0.01345079,\n",
       "         0.0347387 , -0.01769079,  0.02956779, -0.04704267, -0.01040189,\n",
       "        -0.05036606,  0.00243362,  0.03236112,  0.03101156, -0.03196787]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_x[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "96b2832e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.06246194, -0.049209  ,  0.00407102, -0.02026014, -0.04346866,\n",
       "         -0.00748973, -0.0356756 ,  0.06222412, -0.03854244,  0.02709549,\n",
       "          0.00292689,  0.03292041,  0.01779463,  0.06369314,  0.00115686],\n",
       "        [-0.05683396,  0.05229538, -0.05341402,  0.0306057 ,  0.06263665,\n",
       "          0.03840695,  0.04100427,  0.05531496,  0.02296231, -0.0471125 ,\n",
       "          0.03942722, -0.05425759, -0.03720862,  0.03856581, -0.05377772],\n",
       "        [-0.03969079, -0.02383095,  0.02410348,  0.03382367,  0.01345079,\n",
       "          0.0347387 , -0.01769079,  0.02956779, -0.04704267, -0.01040189,\n",
       "         -0.05036606,  0.00243362,  0.03236112,  0.03101156, -0.03196787],\n",
       "        [ 0.01106247,  0.05192446, -0.03524574, -0.02650766, -0.00426547,\n",
       "         -0.03063049,  0.05779214,  0.05081302,  0.06144317,  0.06326098,\n",
       "         -0.05483432, -0.0015293 , -0.04956562, -0.03316838, -0.06006755]],\n",
       "       dtype=float32),\n",
       " 0)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_x[3],embeddings_y[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "91748618",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxsize=[]\n",
    "for i in embeddings_x:\n",
    "    maxsize.append(i.shape[0])\n",
    "max(maxsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ca74a644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 15)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_x[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5f8fd900",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.06246194, -0.049209  ,  0.00407102, ...,  0.01779463,\n",
       "          0.06369314,  0.00115686]],\n",
       "\n",
       "       [[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.06246194, -0.049209  ,  0.00407102, ...,  0.01779463,\n",
       "          0.06369314,  0.00115686],\n",
       "        [-0.05683396,  0.05229538, -0.05341402, ..., -0.03720862,\n",
       "          0.03856581, -0.05377772]],\n",
       "\n",
       "       [[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.06246194, -0.049209  ,  0.00407102, ...,  0.01779463,\n",
       "          0.06369314,  0.00115686],\n",
       "        [-0.05683396,  0.05229538, -0.05341402, ..., -0.03720862,\n",
       "          0.03856581, -0.05377772],\n",
       "        [-0.03969079, -0.02383095,  0.02410348, ...,  0.03236112,\n",
       "          0.03101156, -0.03196787]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [-0.00091926, -0.02648852, -0.03698023, ...,  0.05022385,\n",
       "         -0.0236564 ,  0.04158781]],\n",
       "\n",
       "       [[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [-0.00091926, -0.02648852, -0.03698023, ...,  0.05022385,\n",
       "         -0.0236564 ,  0.04158781],\n",
       "        [ 0.01310604,  0.01614948,  0.03378637, ..., -0.04875587,\n",
       "          0.03600669, -0.02195277]],\n",
       "\n",
       "       [[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.01310604,  0.01614948,  0.03378637, ..., -0.04875587,\n",
       "          0.03600669, -0.02195277]]], dtype=float32)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_sequences_padded_x = pad_sequences(\n",
    "    embeddings_x,\n",
    "    maxlen=5,\n",
    "    dtype='float32',\n",
    "    padding='pre'\n",
    ")\n",
    "embedding_sequences_padded_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b308538b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(embedding_sequences_padded_x)):\n",
    "    print(embeddings_x[i].shape, embedding_sequences_padded_x[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a6f25dd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1229, (743, 5, 15))"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emeddingModel.corpus_total_words,embedding_sequences_padded_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6d3d8c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\DeepLearning\\Code\\env\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_8\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_8\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">20,480</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,416</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">744</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">24,552</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │        \u001b[38;5;34m20,480\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │        \u001b[38;5;34m12,416\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m744\u001b[0m)            │        \u001b[38;5;34m24,552\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">57,448</span> (224.41 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m57,448\u001b[0m (224.41 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">57,448</span> (224.41 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m57,448\u001b[0m (224.41 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    LSTM(64,activation='relu', input_shape=(5, 15),return_sequences=True),\n",
    "    Dropout(0.05),\n",
    "    LSTM(32,activation='relu'),\n",
    "    Dense(744,activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "443eb95e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((743, 5, 15), (743,))"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_sequences_padded_x.shape,embeddings_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "acf738b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8001 - loss: 0.5974\n",
      "Epoch 2/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7887 - loss: 0.6278\n",
      "Epoch 3/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7627 - loss: 0.6285\n",
      "Epoch 4/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7955 - loss: 0.5968\n",
      "Epoch 5/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7757 - loss: 0.6260\n",
      "Epoch 6/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7982 - loss: 0.6346\n",
      "Epoch 7/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7883 - loss: 0.6250\n",
      "Epoch 8/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7957 - loss: 0.6392\n",
      "Epoch 9/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7623 - loss: 0.7015\n",
      "Epoch 10/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7720 - loss: 0.6452\n",
      "Epoch 11/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7963 - loss: 0.6246\n",
      "Epoch 12/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8087 - loss: 0.5617\n",
      "Epoch 13/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7764 - loss: 0.6125\n",
      "Epoch 14/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7964 - loss: 0.5668\n",
      "Epoch 15/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8256 - loss: 0.5386\n",
      "Epoch 16/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7982 - loss: 0.5543\n",
      "Epoch 17/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7941 - loss: 0.5457\n",
      "Epoch 18/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7840 - loss: 0.5915\n",
      "Epoch 19/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8045 - loss: 0.5634\n",
      "Epoch 20/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7900 - loss: 0.6127\n",
      "Epoch 21/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8272 - loss: 0.5438\n",
      "Epoch 22/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8123 - loss: 0.5145\n",
      "Epoch 23/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7960 - loss: 0.6388\n",
      "Epoch 24/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7935 - loss: 0.5975\n",
      "Epoch 25/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8061 - loss: 0.5717\n",
      "Epoch 26/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8028 - loss: 0.5836\n",
      "Epoch 27/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7899 - loss: 0.5782\n",
      "Epoch 28/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8389 - loss: 0.4860\n",
      "Epoch 29/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8222 - loss: 0.5082\n",
      "Epoch 30/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8405 - loss: 0.4868\n",
      "Epoch 31/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8008 - loss: 0.5620\n",
      "Epoch 32/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7942 - loss: 0.5873\n",
      "Epoch 33/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8405 - loss: 0.4522\n",
      "Epoch 34/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7826 - loss: 0.5600\n",
      "Epoch 35/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7777 - loss: 0.5574\n",
      "Epoch 36/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8259 - loss: 0.5547\n",
      "Epoch 37/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8252 - loss: 0.4982\n",
      "Epoch 38/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8042 - loss: 0.5891\n",
      "Epoch 39/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8181 - loss: 0.5524\n",
      "Epoch 40/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8032 - loss: 0.5720\n",
      "Epoch 41/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8152 - loss: 0.5341\n",
      "Epoch 42/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8152 - loss: 0.5189\n",
      "Epoch 43/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8020 - loss: 0.5451\n",
      "Epoch 44/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8231 - loss: 0.5217\n",
      "Epoch 45/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8116 - loss: 0.5803\n",
      "Epoch 46/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8147 - loss: 0.5313\n",
      "Epoch 47/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8231 - loss: 0.5470\n",
      "Epoch 48/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8086 - loss: 0.5142\n",
      "Epoch 49/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8290 - loss: 0.5205\n",
      "Epoch 50/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7878 - loss: 0.5282\n",
      "Epoch 51/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8261 - loss: 0.5115\n",
      "Epoch 52/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8155 - loss: 0.5222\n",
      "Epoch 53/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8112 - loss: 0.5349\n",
      "Epoch 54/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7961 - loss: 0.5437\n",
      "Epoch 55/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8317 - loss: 0.4641\n",
      "Epoch 56/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8028 - loss: 0.5567\n",
      "Epoch 57/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8018 - loss: 0.5732\n",
      "Epoch 58/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8362 - loss: 0.4497\n",
      "Epoch 59/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8246 - loss: 0.4964\n",
      "Epoch 60/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8030 - loss: 0.5893\n",
      "Epoch 61/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7958 - loss: 0.6230\n",
      "Epoch 62/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8095 - loss: 0.5894\n",
      "Epoch 63/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8287 - loss: 0.5047\n",
      "Epoch 64/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8062 - loss: 0.5480\n",
      "Epoch 65/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8181 - loss: 0.5167\n",
      "Epoch 66/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8099 - loss: 0.5091\n",
      "Epoch 67/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8119 - loss: 0.5320\n",
      "Epoch 68/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8356 - loss: 0.4798\n",
      "Epoch 69/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7966 - loss: 0.5303\n",
      "Epoch 70/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8021 - loss: 0.5616\n",
      "Epoch 71/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8197 - loss: 0.5161\n",
      "Epoch 72/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8163 - loss: 0.4989\n",
      "Epoch 73/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8240 - loss: 0.5234\n",
      "Epoch 74/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8073 - loss: 0.5667\n",
      "Epoch 75/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8266 - loss: 0.4774\n",
      "Epoch 76/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7946 - loss: 0.5402\n",
      "Epoch 77/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8354 - loss: 0.5017\n",
      "Epoch 78/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8307 - loss: 0.4887\n",
      "Epoch 79/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7991 - loss: 0.5684\n",
      "Epoch 80/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7696 - loss: 0.5990\n",
      "Epoch 81/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8082 - loss: 0.5075\n",
      "Epoch 82/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8024 - loss: 0.4920\n",
      "Epoch 83/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8311 - loss: 0.4855\n",
      "Epoch 84/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8271 - loss: 0.4595\n",
      "Epoch 85/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8272 - loss: 0.5282\n",
      "Epoch 86/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8314 - loss: 0.4681\n",
      "Epoch 87/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8170 - loss: 0.5774\n",
      "Epoch 88/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8267 - loss: 0.4918\n",
      "Epoch 89/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8199 - loss: 0.5135\n",
      "Epoch 90/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8294 - loss: 0.4706\n",
      "Epoch 91/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8144 - loss: 0.5053\n",
      "Epoch 92/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8331 - loss: 0.4761\n",
      "Epoch 93/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8193 - loss: 0.5142\n",
      "Epoch 94/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8179 - loss: 0.5318\n",
      "Epoch 95/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8378 - loss: 0.4540\n",
      "Epoch 96/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8511 - loss: 0.4535\n",
      "Epoch 97/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8171 - loss: 0.4978\n",
      "Epoch 98/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8408 - loss: 0.4581\n",
      "Epoch 99/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8076 - loss: 0.5156\n",
      "Epoch 100/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8044 - loss: 0.5419\n",
      "Epoch 101/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8268 - loss: 0.4772\n",
      "Epoch 102/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8095 - loss: 0.5820\n",
      "Epoch 103/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8021 - loss: 0.5272\n",
      "Epoch 104/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8123 - loss: 0.4903\n",
      "Epoch 105/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7995 - loss: 0.5596\n",
      "Epoch 106/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8240 - loss: 0.4800\n",
      "Epoch 107/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8508 - loss: 0.4152\n",
      "Epoch 108/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8277 - loss: 0.4068\n",
      "Epoch 109/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7988 - loss: 0.5237\n",
      "Epoch 110/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8145 - loss: 0.4803\n",
      "Epoch 111/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8293 - loss: 0.4379\n",
      "Epoch 112/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8328 - loss: 0.4706\n",
      "Epoch 113/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8122 - loss: 0.5053\n",
      "Epoch 114/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8277 - loss: 0.5007\n",
      "Epoch 115/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8467 - loss: 0.4121\n",
      "Epoch 116/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7920 - loss: 0.5766\n",
      "Epoch 117/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8090 - loss: 0.5607\n",
      "Epoch 118/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8453 - loss: 0.4429\n",
      "Epoch 119/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8353 - loss: 0.4393\n",
      "Epoch 120/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8291 - loss: 0.4706\n",
      "Epoch 121/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8368 - loss: 0.4554\n",
      "Epoch 122/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8247 - loss: 0.4676\n",
      "Epoch 123/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8293 - loss: 0.4623\n",
      "Epoch 124/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8578 - loss: 0.4312\n",
      "Epoch 125/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8153 - loss: 0.5174\n",
      "Epoch 126/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8026 - loss: 0.5077\n",
      "Epoch 127/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8163 - loss: 0.4934\n",
      "Epoch 128/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7908 - loss: 0.5564\n",
      "Epoch 129/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8434 - loss: 0.4730\n",
      "Epoch 130/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8308 - loss: 0.4411\n",
      "Epoch 131/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8360 - loss: 0.4182\n",
      "Epoch 132/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8334 - loss: 0.4319\n",
      "Epoch 133/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7920 - loss: 0.5176\n",
      "Epoch 134/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8187 - loss: 0.5046\n",
      "Epoch 135/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8323 - loss: 0.4898\n",
      "Epoch 136/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8278 - loss: 0.4762\n",
      "Epoch 137/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8188 - loss: 0.4747\n",
      "Epoch 138/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8262 - loss: 0.4660\n",
      "Epoch 139/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7873 - loss: 0.5893\n",
      "Epoch 140/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8386 - loss: 0.4732\n",
      "Epoch 141/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8524 - loss: 0.4199\n",
      "Epoch 142/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8524 - loss: 0.4306\n",
      "Epoch 143/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8387 - loss: 0.4477\n",
      "Epoch 144/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8320 - loss: 0.4759\n",
      "Epoch 145/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8165 - loss: 0.5169\n",
      "Epoch 146/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8061 - loss: 0.4772\n",
      "Epoch 147/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8327 - loss: 0.4525\n",
      "Epoch 148/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8206 - loss: 0.4345\n",
      "Epoch 149/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8243 - loss: 0.4400\n",
      "Epoch 150/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8557 - loss: 0.4479\n",
      "Epoch 151/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8428 - loss: 0.4028\n",
      "Epoch 152/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8222 - loss: 0.4401\n",
      "Epoch 153/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8104 - loss: 0.4663\n",
      "Epoch 154/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8101 - loss: 0.5133\n",
      "Epoch 155/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8214 - loss: 0.4757\n",
      "Epoch 156/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8446 - loss: 0.4628\n",
      "Epoch 157/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8467 - loss: 0.4223\n",
      "Epoch 158/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8516 - loss: 0.4149\n",
      "Epoch 159/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8113 - loss: 0.4617\n",
      "Epoch 160/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8536 - loss: 0.4010\n",
      "Epoch 161/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8533 - loss: 0.4222\n",
      "Epoch 162/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8187 - loss: 0.5184\n",
      "Epoch 163/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8280 - loss: 0.4589\n",
      "Epoch 164/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8116 - loss: 0.4885\n",
      "Epoch 165/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8205 - loss: 0.5068\n",
      "Epoch 166/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8354 - loss: 0.4589\n",
      "Epoch 167/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8410 - loss: 0.4756\n",
      "Epoch 168/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8333 - loss: 0.4497\n",
      "Epoch 169/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8167 - loss: 0.4651\n",
      "Epoch 170/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8278 - loss: 0.4461\n",
      "Epoch 171/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8287 - loss: 0.4383\n",
      "Epoch 172/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8398 - loss: 0.4289\n",
      "Epoch 173/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8080 - loss: 0.4636\n",
      "Epoch 174/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8385 - loss: 0.4539\n",
      "Epoch 175/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8603 - loss: 0.3817\n",
      "Epoch 176/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8403 - loss: 0.3991\n",
      "Epoch 177/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8205 - loss: 0.4606\n",
      "Epoch 178/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8264 - loss: 0.4427\n",
      "Epoch 179/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8366 - loss: 0.4183\n",
      "Epoch 180/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8297 - loss: 0.4641\n",
      "Epoch 181/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8630 - loss: 0.4034\n",
      "Epoch 182/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8016 - loss: 0.4868\n",
      "Epoch 183/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8503 - loss: 0.3930\n",
      "Epoch 184/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8270 - loss: 0.4388\n",
      "Epoch 185/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8305 - loss: 0.4621\n",
      "Epoch 186/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8055 - loss: 0.5004\n",
      "Epoch 187/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8352 - loss: 0.4720\n",
      "Epoch 188/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8308 - loss: 0.4577\n",
      "Epoch 189/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8083 - loss: 0.4641\n",
      "Epoch 190/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7904 - loss: 0.4894\n",
      "Epoch 191/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8169 - loss: 0.4363\n",
      "Epoch 192/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8538 - loss: 0.3964\n",
      "Epoch 193/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8379 - loss: 0.4137\n",
      "Epoch 194/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8498 - loss: 0.4293\n",
      "Epoch 195/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8284 - loss: 0.4826\n",
      "Epoch 196/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8472 - loss: 0.4041\n",
      "Epoch 197/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8560 - loss: 0.4040\n",
      "Epoch 198/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8353 - loss: 0.4426\n",
      "Epoch 199/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8517 - loss: 0.4162\n",
      "Epoch 200/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8331 - loss: 0.4351\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x168bbb1b7d0>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "earlystopping=EarlyStopping(monitor='val_loss',patience=20,restore_best_weights=True)\n",
    "model.fit(embedding_sequences_padded_x, embeddings_y , batch_size=32, epochs=200, callbacks=[earlystopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1861ca",
   "metadata": {},
   "source": [
    "- Those of us who are backing out our remaining dependencies on digital goods and services are being entirely rational and are likely to survive.\n",
    "- I say that because the root cause of risk is dependence, and most especially dependence on expectations of system state.\n",
    "- If I don't use my trademark, then my rights go over to those who use what was and could have remained mine.\n",
    "- For better or poorer, the only two products not covered by product liability today are religion and software, and software should not escape for much longer.\n",
    "\n",
    "<bR><br>\n",
    "\n",
    "- There are three professions that beat their practitioners into a state of humility: farming, weather forecasting, and cyber security. I practice two of those, and, as such, let me assure you that the recommendations which follow are presented in all humility.  Humility does not mean timidity.  Rather, it means that when a strongly held belief is proven wrong, that the humble person changes their mind. I expect that my proposals will result in considerable push-back, and changing my mind may well follow.  Though I will say it again later, this speech is me talking for myself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "5a50bc97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Whether we are talking about laws\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "Top predictions:\n",
      "a: 0.5678\n",
      "it: 0.3311\n",
      "those: 0.1011\n",
      "laws: 0.0000\n",
      "<UNK>: 0.0000\n",
      "\n",
      " Whether we are talking about\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "Top predictions:\n",
      "laws: 1.0000\n",
      "not: 0.0000\n",
      "those: 0.0000\n",
      "a: 0.0000\n",
      "two: 0.0000\n",
      "\n",
      " Whether we are talking\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "Top predictions:\n",
      "about: 0.9997\n",
      "<UNK>: 0.0003\n",
      "are: 0.0000\n",
      "laws: 0.0000\n",
      "ideas: 0.0000\n",
      "\n",
      " Whether we are\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "Top predictions:\n",
      "talking: 0.9959\n",
      "unappealing: 0.0028\n",
      "three: 0.0008\n",
      "majority: 0.0004\n",
      "unimportant: 0.0002\n",
      "\n",
      " Whether we\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n",
      "Top predictions:\n",
      "are: 0.9526\n",
      "a: 0.0123\n",
      "of: 0.0098\n",
      "is: 0.0067\n",
      "this: 0.0057\n",
      "\n",
      " Whether\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "Top predictions:\n",
      "we: 0.9959\n",
      "of: 0.0013\n",
      "are: 0.0009\n",
      "i: 0.0006\n",
      "put: 0.0004\n",
      "\n",
      " like the Digital Millenium\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "Top predictions:\n",
      "do: 0.7995\n",
      "that: 0.1442\n",
      "will: 0.0483\n",
      "<UNK>: 0.0079\n",
      "are: 0.0001\n",
      "\n",
      " like the Digital\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "Top predictions:\n",
      "of: 0.4184\n",
      "my: 0.3697\n",
      "at: 0.1112\n",
      "government: 0.0863\n",
      "i: 0.0090\n"
     ]
    }
   ],
   "source": [
    "input=[\"Whether we are talking about laws\",\"Whether we are talking about\",\"Whether we are talking\",\"Whether we are\",\"Whether we\",\"Whether\",\"like the Digital Millenium\",\"like the Digital\"]\n",
    "for line in input:\n",
    "    print('\\n',line)\n",
    "    input=line.split(' ')\n",
    "    embeddings=[]\n",
    "    if len(input) >=5:\n",
    "        for word in input[len(input)-5:]:\n",
    "            e=emeddingModel.wv[word]\n",
    "            embeddings.append(e)\n",
    "    else:\n",
    "        for word in input:\n",
    "            e=emeddingModel.wv[word]\n",
    "            embeddings.append(e)\n",
    "\n",
    "    embeddings=np.array(embeddings)\n",
    "    \n",
    "    if embeddings.shape[0] < 5:  # If embeddings has shape as (3,15)\n",
    "        diff=5-embeddings.shape[0]\n",
    "        arr=np.zeros((diff,15))\n",
    "        embeddings=np.vstack((arr,embeddings))\n",
    "\n",
    "\n",
    "    embeddings=embeddings.reshape(1, 5, 15)  # Had to reshape since the training shape was (743, 5, 15) for embedding_sequences_padded_x\n",
    "\n",
    "    prediction = model.predict(embeddings)\n",
    "    top_n = 5\n",
    "    top_indices = prediction[0].argsort()[-top_n:][::-1]\n",
    "    top_words = [(tokenizer.index_word.get(i, \"<UNK>\"), prediction[0][i]) for i in top_indices]\n",
    "\n",
    "    print(\"Top predictions:\")\n",
    "    for word, score in top_words:\n",
    "        print(f\"{word}: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "5a410f93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 5, 15)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa9d400",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "842c9d6c",
   "metadata": {},
   "source": [
    "<br><br><br><br>\n",
    "\n",
    "# GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "7cf8c740",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' [ nominal delivery draft, 6 August 2014 ]  Cybersecurity as Realpolitik Dan Geer   Good morning and thank you for the invitation to speak with you today.',\n",
       " 'The plaintext of this talk has been made available to the organizers.',\n",
       " 'While I will not be taking questions today, you are welcome to contact me later and I will do what I can to reply.',\n",
       " 'For simple clarity, let me repeat the abstract for this talk:     Power exists to be used.',\n",
       " 'Some wish for cyber safety, which they    will not get.',\n",
       " 'Others wish for cyber order, which they will not    get.',\n",
       " 'Some have the eye to discern cyber policies that are \"the    least worst thing;\" may they fill the vacuum of wishful thinking.',\n",
       " 'There are three professions that beat their practitioners into a state of humility: farming, weather forecasting, and cyber security.',\n",
       " 'I practice two of those, and, as such, let me assure you that the recommendations which follow are presented in all humility.',\n",
       " 'Humility does not mean timidity.',\n",
       " 'Rather, it means that when a strongly held belief is proven wrong, that the humble person changes their mind.',\n",
       " 'I expect that my proposals will result in considerable push-back, and changing my mind may well follow.',\n",
       " 'Though I will say it again later, this speech is me talking for myself.',\n",
       " 'As if it needed saying, cyber security is now a riveting concern, a top issue in many venues more important than this one.',\n",
       " 'This is not to insult Black Hat; rather it is to note that every speaker, every writer, every practitioner in the field of cyber security who has wished that its topic, and us with it, were taken seriously has gotten their wish.',\n",
       " 'Cyber security *is* being taken seriously, which, as you well know is not the same as being taken usefully, coherently, or lastingly.',\n",
       " 'Whether we are talking about laws like the Digital Millenium Copyright Act or the Computer Fraud and Abuse Act, or the non-lawmaking but perhaps even more significant actions that the Executive agencies are undertaking, \"we\" and the cyber security issue have never been more at the forefront of policy.',\n",
       " \"And you ain't seen nothing yet.\",\n",
       " \"I wish that I could tell you that it is still possible for one person to hold the big picture firmly in their mind's eye, to track everything important that is going on in our field, to make few if any sins of omission.\",\n",
       " 'It is not possible; that phase passed sometime in the last six years.',\n",
       " 'I have certainly tried to keep up but I would be less than candid if I were not to say that I know that I am not keeping up, not even keeping up with what is going on in my own country much less all countries.',\n",
       " 'Not only has cybersecurity reached the highest levels of attention, it has spread into nearly every corner.',\n",
       " 'If area is the product of height and width, then the footprint of cybersecurity has surpassed the grasp of any one of us.',\n",
       " 'The rate of technological change is certainly a part of it.',\n",
       " 'When younger people ask my advice on what they should do or study to make a career in cyber security, I can only advise specialization.',\n",
       " \"Those of us who were in the game early enough and who have managed to retain an over-arching generalist knowledge can't be replaced very easily because while absorbing most new information most of the time may have been possible when we began practice, no person starting from scratch can do that now.\",\n",
       " 'Serial specialization is now all that can be done in any practical way.',\n",
       " 'Just looking at the Black Hat program will confirm that being really good at any one of the many topics presented here all but requires shutting out the demands of being good at any others.',\n",
       " 'Why does that matter?',\n",
       " 'Speaking for myself, I am not interested in the advantages or disadvantages of some bit of technology unless I can grasp how it is that that technology works.',\n",
       " 'Whenever I see marketing material that tells me all the good things that adopting this or that technology makes possible, I remember what George Santayana said, that \"Scepticism is the chastity of the intellect; it is shameful to give it up too soon, or to the first comer.\"',\n",
       " 'I suspect that a majority of you have similar skepticism -- \"It\\'s magic!\"',\n",
       " 'is not the answer a security person will ever accept.',\n",
       " 'By and large, I can tell *what* something is good for once I know *how* it works.',\n",
       " 'Tell me how it works and then, but only then, tell me why you have chosen to use those particular mechanisms for the things you have chosen to use them for.',\n",
       " 'Part of my feeling stems from a long-held and well-substantiated belief that all cyber security technology is dual use.',\n",
       " 'Perhaps dual use is a truism for any and all tools from the scalpel to the hammer to the gas can -- they can be used for good or ill -- but I know that dual use is inherent in cyber security tools.',\n",
       " 'If your definition of \"tool\" is wide enough, I suggest that the cyber security tool-set favors offense these days.',\n",
       " 'Chris Inglis, recently retired NSA Deputy Director, remarked that if we were to score cyber the way we score soccer, the tally would be 462-456 twenty minutes into the game,[CI] i.e., all offense.',\n",
       " 'I will take his comment as confirming at the highest level not only the dual use nature of cybersecurity but also confirming that offense is where the innovations that only States can afford is going on.',\n",
       " 'Nevertheless, this essay is an outgrowth from, an extension of, that increasing importance of cybersecurity.',\n",
       " 'With the humility of which I spoke, I do not claim that I have the last word.',\n",
       " 'What I do claim is that when we speak about cybersecurity policy we are no longer engaging in some sort of parlor game.',\n",
       " 'I claim that policy matters are now the most important matters, that once a topic area, like cybersecurity, becomes interlaced with nearly every aspect of life for nearly everybody, the outcome differential between good policies and bad policies broadens, and the ease of finding answers falls.',\n",
       " 'As H.L.',\n",
       " 'Mencken so trenchantly put it, \"For every complex problem there is a solution that is clear, simple, and wrong.\"',\n",
       " 'The four verities of government are these: .',\n",
       " 'Most important ideas are unappealing .',\n",
       " 'Most appealing ideas are unimportant .',\n",
       " 'Not every problem has a good solution .',\n",
       " 'Every solution has side effects']"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "sentences=sent_tokenize(corpus)\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "99043299",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' [ nominal delivery draft, 6 August 2014 ]  Cybersecurity as Realpolitik Dan Geer   Good morning and thank you for the invitation to speak with you today.'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "08da6299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[', 'nominal', 'delivery', 'draft', ',', '6', 'August', '2014', ']', 'Cybersecurity', 'as', 'Realpolitik', 'Dan', 'Geer', 'Good', 'morning', 'and', 'thank', 'you', 'for', 'the', 'invitation', 'to', 'speak', 'with', 'you', 'today', '.']\n",
      "['[', 'nominal'] => delivery\n",
      "['[', 'nominal', 'delivery'] => draft\n",
      "['[', 'nominal', 'delivery', 'draft'] => ,\n",
      "['[', 'nominal', 'delivery', 'draft', ','] => 6\n",
      "['[', 'nominal', 'delivery', 'draft', ',', '6'] => August\n",
      "['nominal', 'delivery'] => draft\n",
      "['nominal', 'delivery', 'draft'] => ,\n",
      "['nominal', 'delivery', 'draft', ','] => 6\n",
      "['nominal', 'delivery', 'draft', ',', '6'] => August\n",
      "['delivery', 'draft'] => ,\n",
      "['delivery', 'draft', ','] => 6\n",
      "['delivery', 'draft', ',', '6'] => August\n",
      "['draft', ','] => 6\n",
      "['draft', ',', '6'] => August\n",
      "[',', '6'] => August\n",
      "['The', 'plaintext', 'of', 'this', 'talk', 'has', 'been', 'made', 'available', 'to', 'the', 'organizers', '.']\n",
      "['The', 'plaintext'] => of\n",
      "['The', 'plaintext', 'of'] => this\n",
      "['The', 'plaintext', 'of', 'this'] => talk\n",
      "['The', 'plaintext', 'of', 'this', 'talk'] => has\n",
      "['The', 'plaintext', 'of', 'this', 'talk', 'has'] => been\n",
      "['plaintext', 'of'] => this\n",
      "['plaintext', 'of', 'this'] => talk\n",
      "['plaintext', 'of', 'this', 'talk'] => has\n",
      "['plaintext', 'of', 'this', 'talk', 'has'] => been\n",
      "['of', 'this'] => talk\n",
      "['of', 'this', 'talk'] => has\n",
      "['of', 'this', 'talk', 'has'] => been\n",
      "['this', 'talk'] => has\n",
      "['this', 'talk', 'has'] => been\n",
      "['talk', 'has'] => been\n",
      "['While', 'I', 'will', 'not', 'be', 'taking', 'questions', 'today', ',', 'you', 'are', 'welcome', 'to', 'contact', 'me', 'later', 'and', 'I', 'will', 'do', 'what', 'I', 'can', 'to', 'reply', '.']\n",
      "['While', 'I'] => will\n",
      "['While', 'I', 'will'] => not\n",
      "['While', 'I', 'will', 'not'] => be\n",
      "['While', 'I', 'will', 'not', 'be'] => taking\n",
      "['While', 'I', 'will', 'not', 'be', 'taking'] => questions\n",
      "['I', 'will'] => not\n",
      "['I', 'will', 'not'] => be\n",
      "['I', 'will', 'not', 'be'] => taking\n",
      "['I', 'will', 'not', 'be', 'taking'] => questions\n",
      "['will', 'not'] => be\n",
      "['will', 'not', 'be'] => taking\n",
      "['will', 'not', 'be', 'taking'] => questions\n",
      "['not', 'be'] => taking\n",
      "['not', 'be', 'taking'] => questions\n",
      "['be', 'taking'] => questions\n",
      "['For', 'simple', 'clarity', ',', 'let', 'me', 'repeat', 'the', 'abstract', 'for', 'this', 'talk', ':', 'Power', 'exists', 'to', 'be', 'used', '.']\n",
      "['For', 'simple'] => clarity\n",
      "['For', 'simple', 'clarity'] => ,\n",
      "['For', 'simple', 'clarity', ','] => let\n",
      "['For', 'simple', 'clarity', ',', 'let'] => me\n",
      "['For', 'simple', 'clarity', ',', 'let', 'me'] => repeat\n",
      "['simple', 'clarity'] => ,\n",
      "['simple', 'clarity', ','] => let\n",
      "['simple', 'clarity', ',', 'let'] => me\n",
      "['simple', 'clarity', ',', 'let', 'me'] => repeat\n",
      "['clarity', ','] => let\n",
      "['clarity', ',', 'let'] => me\n",
      "['clarity', ',', 'let', 'me'] => repeat\n",
      "[',', 'let'] => me\n",
      "[',', 'let', 'me'] => repeat\n",
      "['let', 'me'] => repeat\n",
      "['Some', 'wish', 'for', 'cyber', 'safety', ',', 'which', 'they', 'will', 'not', 'get', '.']\n",
      "['Some', 'wish'] => for\n",
      "['Some', 'wish', 'for'] => cyber\n",
      "['Some', 'wish', 'for', 'cyber'] => safety\n",
      "['Some', 'wish', 'for', 'cyber', 'safety'] => ,\n",
      "['Some', 'wish', 'for', 'cyber', 'safety', ','] => which\n",
      "['wish', 'for'] => cyber\n",
      "['wish', 'for', 'cyber'] => safety\n",
      "['wish', 'for', 'cyber', 'safety'] => ,\n",
      "['wish', 'for', 'cyber', 'safety', ','] => which\n",
      "['for', 'cyber'] => safety\n",
      "['for', 'cyber', 'safety'] => ,\n",
      "['for', 'cyber', 'safety', ','] => which\n",
      "['cyber', 'safety'] => ,\n",
      "['cyber', 'safety', ','] => which\n",
      "['safety', ','] => which\n",
      "['Others', 'wish', 'for', 'cyber', 'order', ',', 'which', 'they', 'will', 'not', 'get', '.']\n",
      "['Others', 'wish'] => for\n",
      "['Others', 'wish', 'for'] => cyber\n",
      "['Others', 'wish', 'for', 'cyber'] => order\n",
      "['Others', 'wish', 'for', 'cyber', 'order'] => ,\n",
      "['Others', 'wish', 'for', 'cyber', 'order', ','] => which\n",
      "['wish', 'for'] => cyber\n",
      "['wish', 'for', 'cyber'] => order\n",
      "['wish', 'for', 'cyber', 'order'] => ,\n",
      "['wish', 'for', 'cyber', 'order', ','] => which\n",
      "['for', 'cyber'] => order\n",
      "['for', 'cyber', 'order'] => ,\n",
      "['for', 'cyber', 'order', ','] => which\n",
      "['cyber', 'order'] => ,\n",
      "['cyber', 'order', ','] => which\n",
      "['order', ','] => which\n",
      "['Some', 'have', 'the', 'eye', 'to', 'discern', 'cyber', 'policies', 'that', 'are', '``', 'the', 'least', 'worst', 'thing', ';', \"''\", 'may', 'they', 'fill', 'the', 'vacuum', 'of', 'wishful', 'thinking', '.']\n",
      "['Some', 'have'] => the\n",
      "['Some', 'have', 'the'] => eye\n",
      "['Some', 'have', 'the', 'eye'] => to\n",
      "['Some', 'have', 'the', 'eye', 'to'] => discern\n",
      "['Some', 'have', 'the', 'eye', 'to', 'discern'] => cyber\n",
      "['have', 'the'] => eye\n",
      "['have', 'the', 'eye'] => to\n",
      "['have', 'the', 'eye', 'to'] => discern\n",
      "['have', 'the', 'eye', 'to', 'discern'] => cyber\n",
      "['the', 'eye'] => to\n",
      "['the', 'eye', 'to'] => discern\n",
      "['the', 'eye', 'to', 'discern'] => cyber\n",
      "['eye', 'to'] => discern\n",
      "['eye', 'to', 'discern'] => cyber\n",
      "['to', 'discern'] => cyber\n",
      "['There', 'are', 'three', 'professions', 'that', 'beat', 'their', 'practitioners', 'into', 'a', 'state', 'of', 'humility', ':', 'farming', ',', 'weather', 'forecasting', ',', 'and', 'cyber', 'security', '.']\n",
      "['There', 'are'] => three\n",
      "['There', 'are', 'three'] => professions\n",
      "['There', 'are', 'three', 'professions'] => that\n",
      "['There', 'are', 'three', 'professions', 'that'] => beat\n",
      "['There', 'are', 'three', 'professions', 'that', 'beat'] => their\n",
      "['are', 'three'] => professions\n",
      "['are', 'three', 'professions'] => that\n",
      "['are', 'three', 'professions', 'that'] => beat\n",
      "['are', 'three', 'professions', 'that', 'beat'] => their\n",
      "['three', 'professions'] => that\n",
      "['three', 'professions', 'that'] => beat\n",
      "['three', 'professions', 'that', 'beat'] => their\n",
      "['professions', 'that'] => beat\n",
      "['professions', 'that', 'beat'] => their\n",
      "['that', 'beat'] => their\n",
      "['I', 'practice', 'two', 'of', 'those', ',', 'and', ',', 'as', 'such', ',', 'let', 'me', 'assure', 'you', 'that', 'the', 'recommendations', 'which', 'follow', 'are', 'presented', 'in', 'all', 'humility', '.']\n",
      "['I', 'practice'] => two\n",
      "['I', 'practice', 'two'] => of\n",
      "['I', 'practice', 'two', 'of'] => those\n",
      "['I', 'practice', 'two', 'of', 'those'] => ,\n",
      "['I', 'practice', 'two', 'of', 'those', ','] => and\n",
      "['practice', 'two'] => of\n",
      "['practice', 'two', 'of'] => those\n",
      "['practice', 'two', 'of', 'those'] => ,\n",
      "['practice', 'two', 'of', 'those', ','] => and\n",
      "['two', 'of'] => those\n",
      "['two', 'of', 'those'] => ,\n",
      "['two', 'of', 'those', ','] => and\n",
      "['of', 'those'] => ,\n",
      "['of', 'those', ','] => and\n",
      "['those', ','] => and\n",
      "['Humility', 'does', 'not', 'mean', 'timidity', '.']\n",
      "['Humility', 'does'] => not\n",
      "['Humility', 'does', 'not'] => mean\n",
      "['Humility', 'does', 'not', 'mean'] => timidity\n",
      "['Humility', 'does', 'not', 'mean', 'timidity'] => .\n",
      "['does', 'not'] => mean\n",
      "['does', 'not', 'mean'] => timidity\n",
      "['does', 'not', 'mean', 'timidity'] => .\n",
      "['not', 'mean'] => timidity\n",
      "['not', 'mean', 'timidity'] => .\n",
      "['mean', 'timidity'] => .\n",
      "['Rather', ',', 'it', 'means', 'that', 'when', 'a', 'strongly', 'held', 'belief', 'is', 'proven', 'wrong', ',', 'that', 'the', 'humble', 'person', 'changes', 'their', 'mind', '.']\n",
      "['Rather', ','] => it\n",
      "['Rather', ',', 'it'] => means\n",
      "['Rather', ',', 'it', 'means'] => that\n",
      "['Rather', ',', 'it', 'means', 'that'] => when\n",
      "['Rather', ',', 'it', 'means', 'that', 'when'] => a\n",
      "[',', 'it'] => means\n",
      "[',', 'it', 'means'] => that\n",
      "[',', 'it', 'means', 'that'] => when\n",
      "[',', 'it', 'means', 'that', 'when'] => a\n",
      "['it', 'means'] => that\n",
      "['it', 'means', 'that'] => when\n",
      "['it', 'means', 'that', 'when'] => a\n",
      "['means', 'that'] => when\n",
      "['means', 'that', 'when'] => a\n",
      "['that', 'when'] => a\n",
      "['I', 'expect', 'that', 'my', 'proposals', 'will', 'result', 'in', 'considerable', 'push-back', ',', 'and', 'changing', 'my', 'mind', 'may', 'well', 'follow', '.']\n",
      "['I', 'expect'] => that\n",
      "['I', 'expect', 'that'] => my\n",
      "['I', 'expect', 'that', 'my'] => proposals\n",
      "['I', 'expect', 'that', 'my', 'proposals'] => will\n",
      "['I', 'expect', 'that', 'my', 'proposals', 'will'] => result\n",
      "['expect', 'that'] => my\n",
      "['expect', 'that', 'my'] => proposals\n",
      "['expect', 'that', 'my', 'proposals'] => will\n",
      "['expect', 'that', 'my', 'proposals', 'will'] => result\n",
      "['that', 'my'] => proposals\n",
      "['that', 'my', 'proposals'] => will\n",
      "['that', 'my', 'proposals', 'will'] => result\n",
      "['my', 'proposals'] => will\n",
      "['my', 'proposals', 'will'] => result\n",
      "['proposals', 'will'] => result\n",
      "['Though', 'I', 'will', 'say', 'it', 'again', 'later', ',', 'this', 'speech', 'is', 'me', 'talking', 'for', 'myself', '.']\n",
      "['Though', 'I'] => will\n",
      "['Though', 'I', 'will'] => say\n",
      "['Though', 'I', 'will', 'say'] => it\n",
      "['Though', 'I', 'will', 'say', 'it'] => again\n",
      "['Though', 'I', 'will', 'say', 'it', 'again'] => later\n",
      "['I', 'will'] => say\n",
      "['I', 'will', 'say'] => it\n",
      "['I', 'will', 'say', 'it'] => again\n",
      "['I', 'will', 'say', 'it', 'again'] => later\n",
      "['will', 'say'] => it\n",
      "['will', 'say', 'it'] => again\n",
      "['will', 'say', 'it', 'again'] => later\n",
      "['say', 'it'] => again\n",
      "['say', 'it', 'again'] => later\n",
      "['it', 'again'] => later\n",
      "['As', 'if', 'it', 'needed', 'saying', ',', 'cyber', 'security', 'is', 'now', 'a', 'riveting', 'concern', ',', 'a', 'top', 'issue', 'in', 'many', 'venues', 'more', 'important', 'than', 'this', 'one', '.']\n",
      "['As', 'if'] => it\n",
      "['As', 'if', 'it'] => needed\n",
      "['As', 'if', 'it', 'needed'] => saying\n",
      "['As', 'if', 'it', 'needed', 'saying'] => ,\n",
      "['As', 'if', 'it', 'needed', 'saying', ','] => cyber\n",
      "['if', 'it'] => needed\n",
      "['if', 'it', 'needed'] => saying\n",
      "['if', 'it', 'needed', 'saying'] => ,\n",
      "['if', 'it', 'needed', 'saying', ','] => cyber\n",
      "['it', 'needed'] => saying\n",
      "['it', 'needed', 'saying'] => ,\n",
      "['it', 'needed', 'saying', ','] => cyber\n",
      "['needed', 'saying'] => ,\n",
      "['needed', 'saying', ','] => cyber\n",
      "['saying', ','] => cyber\n",
      "['This', 'is', 'not', 'to', 'insult', 'Black', 'Hat', ';', 'rather', 'it', 'is', 'to', 'note', 'that', 'every', 'speaker', ',', 'every', 'writer', ',', 'every', 'practitioner', 'in', 'the', 'field', 'of', 'cyber', 'security', 'who', 'has', 'wished', 'that', 'its', 'topic', ',', 'and', 'us', 'with', 'it', ',', 'were', 'taken', 'seriously', 'has', 'gotten', 'their', 'wish', '.']\n",
      "['This', 'is'] => not\n",
      "['This', 'is', 'not'] => to\n",
      "['This', 'is', 'not', 'to'] => insult\n",
      "['This', 'is', 'not', 'to', 'insult'] => Black\n",
      "['This', 'is', 'not', 'to', 'insult', 'Black'] => Hat\n",
      "['is', 'not'] => to\n",
      "['is', 'not', 'to'] => insult\n",
      "['is', 'not', 'to', 'insult'] => Black\n",
      "['is', 'not', 'to', 'insult', 'Black'] => Hat\n",
      "['not', 'to'] => insult\n",
      "['not', 'to', 'insult'] => Black\n",
      "['not', 'to', 'insult', 'Black'] => Hat\n",
      "['to', 'insult'] => Black\n",
      "['to', 'insult', 'Black'] => Hat\n",
      "['insult', 'Black'] => Hat\n",
      "['Cyber', 'security', '*', 'is', '*', 'being', 'taken', 'seriously', ',', 'which', ',', 'as', 'you', 'well', 'know', 'is', 'not', 'the', 'same', 'as', 'being', 'taken', 'usefully', ',', 'coherently', ',', 'or', 'lastingly', '.']\n",
      "['Cyber', 'security'] => *\n",
      "['Cyber', 'security', '*'] => is\n",
      "['Cyber', 'security', '*', 'is'] => *\n",
      "['Cyber', 'security', '*', 'is', '*'] => being\n",
      "['Cyber', 'security', '*', 'is', '*', 'being'] => taken\n",
      "['security', '*'] => is\n",
      "['security', '*', 'is'] => *\n",
      "['security', '*', 'is', '*'] => being\n",
      "['security', '*', 'is', '*', 'being'] => taken\n",
      "['*', 'is'] => *\n",
      "['*', 'is', '*'] => being\n",
      "['*', 'is', '*', 'being'] => taken\n",
      "['is', '*'] => being\n",
      "['is', '*', 'being'] => taken\n",
      "['*', 'being'] => taken\n",
      "['Whether', 'we', 'are', 'talking', 'about', 'laws', 'like', 'the', 'Digital', 'Millenium', 'Copyright', 'Act', 'or', 'the', 'Computer', 'Fraud', 'and', 'Abuse', 'Act', ',', 'or', 'the', 'non-lawmaking', 'but', 'perhaps', 'even', 'more', 'significant', 'actions', 'that', 'the', 'Executive', 'agencies', 'are', 'undertaking', ',', '``', 'we', \"''\", 'and', 'the', 'cyber', 'security', 'issue', 'have', 'never', 'been', 'more', 'at', 'the', 'forefront', 'of', 'policy', '.']\n",
      "['Whether', 'we'] => are\n",
      "['Whether', 'we', 'are'] => talking\n",
      "['Whether', 'we', 'are', 'talking'] => about\n",
      "['Whether', 'we', 'are', 'talking', 'about'] => laws\n",
      "['Whether', 'we', 'are', 'talking', 'about', 'laws'] => like\n",
      "['we', 'are'] => talking\n",
      "['we', 'are', 'talking'] => about\n",
      "['we', 'are', 'talking', 'about'] => laws\n",
      "['we', 'are', 'talking', 'about', 'laws'] => like\n",
      "['are', 'talking'] => about\n",
      "['are', 'talking', 'about'] => laws\n",
      "['are', 'talking', 'about', 'laws'] => like\n",
      "['talking', 'about'] => laws\n",
      "['talking', 'about', 'laws'] => like\n",
      "['about', 'laws'] => like\n",
      "['And', 'you', 'ai', \"n't\", 'seen', 'nothing', 'yet', '.']\n",
      "['And', 'you'] => ai\n",
      "['And', 'you', 'ai'] => n't\n",
      "['And', 'you', 'ai', \"n't\"] => seen\n",
      "['And', 'you', 'ai', \"n't\", 'seen'] => nothing\n",
      "['And', 'you', 'ai', \"n't\", 'seen', 'nothing'] => yet\n",
      "['you', 'ai'] => n't\n",
      "['you', 'ai', \"n't\"] => seen\n",
      "['you', 'ai', \"n't\", 'seen'] => nothing\n",
      "['you', 'ai', \"n't\", 'seen', 'nothing'] => yet\n",
      "['ai', \"n't\"] => seen\n",
      "['ai', \"n't\", 'seen'] => nothing\n",
      "['ai', \"n't\", 'seen', 'nothing'] => yet\n",
      "[\"n't\", 'seen'] => nothing\n",
      "[\"n't\", 'seen', 'nothing'] => yet\n",
      "['seen', 'nothing'] => yet\n",
      "['I', 'wish', 'that', 'I', 'could', 'tell', 'you', 'that', 'it', 'is', 'still', 'possible', 'for', 'one', 'person', 'to', 'hold', 'the', 'big', 'picture', 'firmly', 'in', 'their', 'mind', \"'s\", 'eye', ',', 'to', 'track', 'everything', 'important', 'that', 'is', 'going', 'on', 'in', 'our', 'field', ',', 'to', 'make', 'few', 'if', 'any', 'sins', 'of', 'omission', '.']\n",
      "['I', 'wish'] => that\n",
      "['I', 'wish', 'that'] => I\n",
      "['I', 'wish', 'that', 'I'] => could\n",
      "['I', 'wish', 'that', 'I', 'could'] => tell\n",
      "['I', 'wish', 'that', 'I', 'could', 'tell'] => you\n",
      "['wish', 'that'] => I\n",
      "['wish', 'that', 'I'] => could\n",
      "['wish', 'that', 'I', 'could'] => tell\n",
      "['wish', 'that', 'I', 'could', 'tell'] => you\n",
      "['that', 'I'] => could\n",
      "['that', 'I', 'could'] => tell\n",
      "['that', 'I', 'could', 'tell'] => you\n",
      "['I', 'could'] => tell\n",
      "['I', 'could', 'tell'] => you\n",
      "['could', 'tell'] => you\n",
      "['It', 'is', 'not', 'possible', ';', 'that', 'phase', 'passed', 'sometime', 'in', 'the', 'last', 'six', 'years', '.']\n",
      "['It', 'is'] => not\n",
      "['It', 'is', 'not'] => possible\n",
      "['It', 'is', 'not', 'possible'] => ;\n",
      "['It', 'is', 'not', 'possible', ';'] => that\n",
      "['It', 'is', 'not', 'possible', ';', 'that'] => phase\n",
      "['is', 'not'] => possible\n",
      "['is', 'not', 'possible'] => ;\n",
      "['is', 'not', 'possible', ';'] => that\n",
      "['is', 'not', 'possible', ';', 'that'] => phase\n",
      "['not', 'possible'] => ;\n",
      "['not', 'possible', ';'] => that\n",
      "['not', 'possible', ';', 'that'] => phase\n",
      "['possible', ';'] => that\n",
      "['possible', ';', 'that'] => phase\n",
      "[';', 'that'] => phase\n",
      "['I', 'have', 'certainly', 'tried', 'to', 'keep', 'up', 'but', 'I', 'would', 'be', 'less', 'than', 'candid', 'if', 'I', 'were', 'not', 'to', 'say', 'that', 'I', 'know', 'that', 'I', 'am', 'not', 'keeping', 'up', ',', 'not', 'even', 'keeping', 'up', 'with', 'what', 'is', 'going', 'on', 'in', 'my', 'own', 'country', 'much', 'less', 'all', 'countries', '.']\n",
      "['I', 'have'] => certainly\n",
      "['I', 'have', 'certainly'] => tried\n",
      "['I', 'have', 'certainly', 'tried'] => to\n",
      "['I', 'have', 'certainly', 'tried', 'to'] => keep\n",
      "['I', 'have', 'certainly', 'tried', 'to', 'keep'] => up\n",
      "['have', 'certainly'] => tried\n",
      "['have', 'certainly', 'tried'] => to\n",
      "['have', 'certainly', 'tried', 'to'] => keep\n",
      "['have', 'certainly', 'tried', 'to', 'keep'] => up\n",
      "['certainly', 'tried'] => to\n",
      "['certainly', 'tried', 'to'] => keep\n",
      "['certainly', 'tried', 'to', 'keep'] => up\n",
      "['tried', 'to'] => keep\n",
      "['tried', 'to', 'keep'] => up\n",
      "['to', 'keep'] => up\n",
      "['Not', 'only', 'has', 'cybersecurity', 'reached', 'the', 'highest', 'levels', 'of', 'attention', ',', 'it', 'has', 'spread', 'into', 'nearly', 'every', 'corner', '.']\n",
      "['Not', 'only'] => has\n",
      "['Not', 'only', 'has'] => cybersecurity\n",
      "['Not', 'only', 'has', 'cybersecurity'] => reached\n",
      "['Not', 'only', 'has', 'cybersecurity', 'reached'] => the\n",
      "['Not', 'only', 'has', 'cybersecurity', 'reached', 'the'] => highest\n",
      "['only', 'has'] => cybersecurity\n",
      "['only', 'has', 'cybersecurity'] => reached\n",
      "['only', 'has', 'cybersecurity', 'reached'] => the\n",
      "['only', 'has', 'cybersecurity', 'reached', 'the'] => highest\n",
      "['has', 'cybersecurity'] => reached\n",
      "['has', 'cybersecurity', 'reached'] => the\n",
      "['has', 'cybersecurity', 'reached', 'the'] => highest\n",
      "['cybersecurity', 'reached'] => the\n",
      "['cybersecurity', 'reached', 'the'] => highest\n",
      "['reached', 'the'] => highest\n",
      "['If', 'area', 'is', 'the', 'product', 'of', 'height', 'and', 'width', ',', 'then', 'the', 'footprint', 'of', 'cybersecurity', 'has', 'surpassed', 'the', 'grasp', 'of', 'any', 'one', 'of', 'us', '.']\n",
      "['If', 'area'] => is\n",
      "['If', 'area', 'is'] => the\n",
      "['If', 'area', 'is', 'the'] => product\n",
      "['If', 'area', 'is', 'the', 'product'] => of\n",
      "['If', 'area', 'is', 'the', 'product', 'of'] => height\n",
      "['area', 'is'] => the\n",
      "['area', 'is', 'the'] => product\n",
      "['area', 'is', 'the', 'product'] => of\n",
      "['area', 'is', 'the', 'product', 'of'] => height\n",
      "['is', 'the'] => product\n",
      "['is', 'the', 'product'] => of\n",
      "['is', 'the', 'product', 'of'] => height\n",
      "['the', 'product'] => of\n",
      "['the', 'product', 'of'] => height\n",
      "['product', 'of'] => height\n",
      "['The', 'rate', 'of', 'technological', 'change', 'is', 'certainly', 'a', 'part', 'of', 'it', '.']\n",
      "['The', 'rate'] => of\n",
      "['The', 'rate', 'of'] => technological\n",
      "['The', 'rate', 'of', 'technological'] => change\n",
      "['The', 'rate', 'of', 'technological', 'change'] => is\n",
      "['The', 'rate', 'of', 'technological', 'change', 'is'] => certainly\n",
      "['rate', 'of'] => technological\n",
      "['rate', 'of', 'technological'] => change\n",
      "['rate', 'of', 'technological', 'change'] => is\n",
      "['rate', 'of', 'technological', 'change', 'is'] => certainly\n",
      "['of', 'technological'] => change\n",
      "['of', 'technological', 'change'] => is\n",
      "['of', 'technological', 'change', 'is'] => certainly\n",
      "['technological', 'change'] => is\n",
      "['technological', 'change', 'is'] => certainly\n",
      "['change', 'is'] => certainly\n",
      "['When', 'younger', 'people', 'ask', 'my', 'advice', 'on', 'what', 'they', 'should', 'do', 'or', 'study', 'to', 'make', 'a', 'career', 'in', 'cyber', 'security', ',', 'I', 'can', 'only', 'advise', 'specialization', '.']\n",
      "['When', 'younger'] => people\n",
      "['When', 'younger', 'people'] => ask\n",
      "['When', 'younger', 'people', 'ask'] => my\n",
      "['When', 'younger', 'people', 'ask', 'my'] => advice\n",
      "['When', 'younger', 'people', 'ask', 'my', 'advice'] => on\n",
      "['younger', 'people'] => ask\n",
      "['younger', 'people', 'ask'] => my\n",
      "['younger', 'people', 'ask', 'my'] => advice\n",
      "['younger', 'people', 'ask', 'my', 'advice'] => on\n",
      "['people', 'ask'] => my\n",
      "['people', 'ask', 'my'] => advice\n",
      "['people', 'ask', 'my', 'advice'] => on\n",
      "['ask', 'my'] => advice\n",
      "['ask', 'my', 'advice'] => on\n",
      "['my', 'advice'] => on\n",
      "['Those', 'of', 'us', 'who', 'were', 'in', 'the', 'game', 'early', 'enough', 'and', 'who', 'have', 'managed', 'to', 'retain', 'an', 'over-arching', 'generalist', 'knowledge', 'ca', \"n't\", 'be', 'replaced', 'very', 'easily', 'because', 'while', 'absorbing', 'most', 'new', 'information', 'most', 'of', 'the', 'time', 'may', 'have', 'been', 'possible', 'when', 'we', 'began', 'practice', ',', 'no', 'person', 'starting', 'from', 'scratch', 'can', 'do', 'that', 'now', '.']\n",
      "['Those', 'of'] => us\n",
      "['Those', 'of', 'us'] => who\n",
      "['Those', 'of', 'us', 'who'] => were\n",
      "['Those', 'of', 'us', 'who', 'were'] => in\n",
      "['Those', 'of', 'us', 'who', 'were', 'in'] => the\n",
      "['of', 'us'] => who\n",
      "['of', 'us', 'who'] => were\n",
      "['of', 'us', 'who', 'were'] => in\n",
      "['of', 'us', 'who', 'were', 'in'] => the\n",
      "['us', 'who'] => were\n",
      "['us', 'who', 'were'] => in\n",
      "['us', 'who', 'were', 'in'] => the\n",
      "['who', 'were'] => in\n",
      "['who', 'were', 'in'] => the\n",
      "['were', 'in'] => the\n",
      "['Serial', 'specialization', 'is', 'now', 'all', 'that', 'can', 'be', 'done', 'in', 'any', 'practical', 'way', '.']\n",
      "['Serial', 'specialization'] => is\n",
      "['Serial', 'specialization', 'is'] => now\n",
      "['Serial', 'specialization', 'is', 'now'] => all\n",
      "['Serial', 'specialization', 'is', 'now', 'all'] => that\n",
      "['Serial', 'specialization', 'is', 'now', 'all', 'that'] => can\n",
      "['specialization', 'is'] => now\n",
      "['specialization', 'is', 'now'] => all\n",
      "['specialization', 'is', 'now', 'all'] => that\n",
      "['specialization', 'is', 'now', 'all', 'that'] => can\n",
      "['is', 'now'] => all\n",
      "['is', 'now', 'all'] => that\n",
      "['is', 'now', 'all', 'that'] => can\n",
      "['now', 'all'] => that\n",
      "['now', 'all', 'that'] => can\n",
      "['all', 'that'] => can\n",
      "['Just', 'looking', 'at', 'the', 'Black', 'Hat', 'program', 'will', 'confirm', 'that', 'being', 'really', 'good', 'at', 'any', 'one', 'of', 'the', 'many', 'topics', 'presented', 'here', 'all', 'but', 'requires', 'shutting', 'out', 'the', 'demands', 'of', 'being', 'good', 'at', 'any', 'others', '.']\n",
      "['Just', 'looking'] => at\n",
      "['Just', 'looking', 'at'] => the\n",
      "['Just', 'looking', 'at', 'the'] => Black\n",
      "['Just', 'looking', 'at', 'the', 'Black'] => Hat\n",
      "['Just', 'looking', 'at', 'the', 'Black', 'Hat'] => program\n",
      "['looking', 'at'] => the\n",
      "['looking', 'at', 'the'] => Black\n",
      "['looking', 'at', 'the', 'Black'] => Hat\n",
      "['looking', 'at', 'the', 'Black', 'Hat'] => program\n",
      "['at', 'the'] => Black\n",
      "['at', 'the', 'Black'] => Hat\n",
      "['at', 'the', 'Black', 'Hat'] => program\n",
      "['the', 'Black'] => Hat\n",
      "['the', 'Black', 'Hat'] => program\n",
      "['Black', 'Hat'] => program\n",
      "['Why', 'does', 'that', 'matter', '?']\n",
      "['Why', 'does'] => that\n",
      "['Why', 'does', 'that'] => matter\n",
      "['Why', 'does', 'that', 'matter'] => ?\n",
      "['does', 'that'] => matter\n",
      "['does', 'that', 'matter'] => ?\n",
      "['that', 'matter'] => ?\n",
      "['Speaking', 'for', 'myself', ',', 'I', 'am', 'not', 'interested', 'in', 'the', 'advantages', 'or', 'disadvantages', 'of', 'some', 'bit', 'of', 'technology', 'unless', 'I', 'can', 'grasp', 'how', 'it', 'is', 'that', 'that', 'technology', 'works', '.']\n",
      "['Speaking', 'for'] => myself\n",
      "['Speaking', 'for', 'myself'] => ,\n",
      "['Speaking', 'for', 'myself', ','] => I\n",
      "['Speaking', 'for', 'myself', ',', 'I'] => am\n",
      "['Speaking', 'for', 'myself', ',', 'I', 'am'] => not\n",
      "['for', 'myself'] => ,\n",
      "['for', 'myself', ','] => I\n",
      "['for', 'myself', ',', 'I'] => am\n",
      "['for', 'myself', ',', 'I', 'am'] => not\n",
      "['myself', ','] => I\n",
      "['myself', ',', 'I'] => am\n",
      "['myself', ',', 'I', 'am'] => not\n",
      "[',', 'I'] => am\n",
      "[',', 'I', 'am'] => not\n",
      "['I', 'am'] => not\n",
      "['Whenever', 'I', 'see', 'marketing', 'material', 'that', 'tells', 'me', 'all', 'the', 'good', 'things', 'that', 'adopting', 'this', 'or', 'that', 'technology', 'makes', 'possible', ',', 'I', 'remember', 'what', 'George', 'Santayana', 'said', ',', 'that', '``', 'Scepticism', 'is', 'the', 'chastity', 'of', 'the', 'intellect', ';', 'it', 'is', 'shameful', 'to', 'give', 'it', 'up', 'too', 'soon', ',', 'or', 'to', 'the', 'first', 'comer', '.', \"''\"]\n",
      "['Whenever', 'I'] => see\n",
      "['Whenever', 'I', 'see'] => marketing\n",
      "['Whenever', 'I', 'see', 'marketing'] => material\n",
      "['Whenever', 'I', 'see', 'marketing', 'material'] => that\n",
      "['Whenever', 'I', 'see', 'marketing', 'material', 'that'] => tells\n",
      "['I', 'see'] => marketing\n",
      "['I', 'see', 'marketing'] => material\n",
      "['I', 'see', 'marketing', 'material'] => that\n",
      "['I', 'see', 'marketing', 'material', 'that'] => tells\n",
      "['see', 'marketing'] => material\n",
      "['see', 'marketing', 'material'] => that\n",
      "['see', 'marketing', 'material', 'that'] => tells\n",
      "['marketing', 'material'] => that\n",
      "['marketing', 'material', 'that'] => tells\n",
      "['material', 'that'] => tells\n",
      "['I', 'suspect', 'that', 'a', 'majority', 'of', 'you', 'have', 'similar', 'skepticism', '--', '``', 'It', \"'s\", 'magic', '!', \"''\"]\n",
      "['I', 'suspect'] => that\n",
      "['I', 'suspect', 'that'] => a\n",
      "['I', 'suspect', 'that', 'a'] => majority\n",
      "['I', 'suspect', 'that', 'a', 'majority'] => of\n",
      "['I', 'suspect', 'that', 'a', 'majority', 'of'] => you\n",
      "['suspect', 'that'] => a\n",
      "['suspect', 'that', 'a'] => majority\n",
      "['suspect', 'that', 'a', 'majority'] => of\n",
      "['suspect', 'that', 'a', 'majority', 'of'] => you\n",
      "['that', 'a'] => majority\n",
      "['that', 'a', 'majority'] => of\n",
      "['that', 'a', 'majority', 'of'] => you\n",
      "['a', 'majority'] => of\n",
      "['a', 'majority', 'of'] => you\n",
      "['majority', 'of'] => you\n",
      "['is', 'not', 'the', 'answer', 'a', 'security', 'person', 'will', 'ever', 'accept', '.']\n",
      "['is', 'not'] => the\n",
      "['is', 'not', 'the'] => answer\n",
      "['is', 'not', 'the', 'answer'] => a\n",
      "['is', 'not', 'the', 'answer', 'a'] => security\n",
      "['is', 'not', 'the', 'answer', 'a', 'security'] => person\n",
      "['not', 'the'] => answer\n",
      "['not', 'the', 'answer'] => a\n",
      "['not', 'the', 'answer', 'a'] => security\n",
      "['not', 'the', 'answer', 'a', 'security'] => person\n",
      "['the', 'answer'] => a\n",
      "['the', 'answer', 'a'] => security\n",
      "['the', 'answer', 'a', 'security'] => person\n",
      "['answer', 'a'] => security\n",
      "['answer', 'a', 'security'] => person\n",
      "['a', 'security'] => person\n",
      "['By', 'and', 'large', ',', 'I', 'can', 'tell', '*', 'what', '*', 'something', 'is', 'good', 'for', 'once', 'I', 'know', '*', 'how', '*', 'it', 'works', '.']\n",
      "['By', 'and'] => large\n",
      "['By', 'and', 'large'] => ,\n",
      "['By', 'and', 'large', ','] => I\n",
      "['By', 'and', 'large', ',', 'I'] => can\n",
      "['By', 'and', 'large', ',', 'I', 'can'] => tell\n",
      "['and', 'large'] => ,\n",
      "['and', 'large', ','] => I\n",
      "['and', 'large', ',', 'I'] => can\n",
      "['and', 'large', ',', 'I', 'can'] => tell\n",
      "['large', ','] => I\n",
      "['large', ',', 'I'] => can\n",
      "['large', ',', 'I', 'can'] => tell\n",
      "[',', 'I'] => can\n",
      "[',', 'I', 'can'] => tell\n",
      "['I', 'can'] => tell\n",
      "['Tell', 'me', 'how', 'it', 'works', 'and', 'then', ',', 'but', 'only', 'then', ',', 'tell', 'me', 'why', 'you', 'have', 'chosen', 'to', 'use', 'those', 'particular', 'mechanisms', 'for', 'the', 'things', 'you', 'have', 'chosen', 'to', 'use', 'them', 'for', '.']\n",
      "['Tell', 'me'] => how\n",
      "['Tell', 'me', 'how'] => it\n",
      "['Tell', 'me', 'how', 'it'] => works\n",
      "['Tell', 'me', 'how', 'it', 'works'] => and\n",
      "['Tell', 'me', 'how', 'it', 'works', 'and'] => then\n",
      "['me', 'how'] => it\n",
      "['me', 'how', 'it'] => works\n",
      "['me', 'how', 'it', 'works'] => and\n",
      "['me', 'how', 'it', 'works', 'and'] => then\n",
      "['how', 'it'] => works\n",
      "['how', 'it', 'works'] => and\n",
      "['how', 'it', 'works', 'and'] => then\n",
      "['it', 'works'] => and\n",
      "['it', 'works', 'and'] => then\n",
      "['works', 'and'] => then\n",
      "['Part', 'of', 'my', 'feeling', 'stems', 'from', 'a', 'long-held', 'and', 'well-substantiated', 'belief', 'that', 'all', 'cyber', 'security', 'technology', 'is', 'dual', 'use', '.']\n",
      "['Part', 'of'] => my\n",
      "['Part', 'of', 'my'] => feeling\n",
      "['Part', 'of', 'my', 'feeling'] => stems\n",
      "['Part', 'of', 'my', 'feeling', 'stems'] => from\n",
      "['Part', 'of', 'my', 'feeling', 'stems', 'from'] => a\n",
      "['of', 'my'] => feeling\n",
      "['of', 'my', 'feeling'] => stems\n",
      "['of', 'my', 'feeling', 'stems'] => from\n",
      "['of', 'my', 'feeling', 'stems', 'from'] => a\n",
      "['my', 'feeling'] => stems\n",
      "['my', 'feeling', 'stems'] => from\n",
      "['my', 'feeling', 'stems', 'from'] => a\n",
      "['feeling', 'stems'] => from\n",
      "['feeling', 'stems', 'from'] => a\n",
      "['stems', 'from'] => a\n",
      "['Perhaps', 'dual', 'use', 'is', 'a', 'truism', 'for', 'any', 'and', 'all', 'tools', 'from', 'the', 'scalpel', 'to', 'the', 'hammer', 'to', 'the', 'gas', 'can', '--', 'they', 'can', 'be', 'used', 'for', 'good', 'or', 'ill', '--', 'but', 'I', 'know', 'that', 'dual', 'use', 'is', 'inherent', 'in', 'cyber', 'security', 'tools', '.']\n",
      "['Perhaps', 'dual'] => use\n",
      "['Perhaps', 'dual', 'use'] => is\n",
      "['Perhaps', 'dual', 'use', 'is'] => a\n",
      "['Perhaps', 'dual', 'use', 'is', 'a'] => truism\n",
      "['Perhaps', 'dual', 'use', 'is', 'a', 'truism'] => for\n",
      "['dual', 'use'] => is\n",
      "['dual', 'use', 'is'] => a\n",
      "['dual', 'use', 'is', 'a'] => truism\n",
      "['dual', 'use', 'is', 'a', 'truism'] => for\n",
      "['use', 'is'] => a\n",
      "['use', 'is', 'a'] => truism\n",
      "['use', 'is', 'a', 'truism'] => for\n",
      "['is', 'a'] => truism\n",
      "['is', 'a', 'truism'] => for\n",
      "['a', 'truism'] => for\n",
      "['If', 'your', 'definition', 'of', '``', 'tool', \"''\", 'is', 'wide', 'enough', ',', 'I', 'suggest', 'that', 'the', 'cyber', 'security', 'tool-set', 'favors', 'offense', 'these', 'days', '.']\n",
      "['If', 'your'] => definition\n",
      "['If', 'your', 'definition'] => of\n",
      "['If', 'your', 'definition', 'of'] => ``\n",
      "['If', 'your', 'definition', 'of', '``'] => tool\n",
      "['If', 'your', 'definition', 'of', '``', 'tool'] => ''\n",
      "['your', 'definition'] => of\n",
      "['your', 'definition', 'of'] => ``\n",
      "['your', 'definition', 'of', '``'] => tool\n",
      "['your', 'definition', 'of', '``', 'tool'] => ''\n",
      "['definition', 'of'] => ``\n",
      "['definition', 'of', '``'] => tool\n",
      "['definition', 'of', '``', 'tool'] => ''\n",
      "['of', '``'] => tool\n",
      "['of', '``', 'tool'] => ''\n",
      "['``', 'tool'] => ''\n",
      "['Chris', 'Inglis', ',', 'recently', 'retired', 'NSA', 'Deputy', 'Director', ',', 'remarked', 'that', 'if', 'we', 'were', 'to', 'score', 'cyber', 'the', 'way', 'we', 'score', 'soccer', ',', 'the', 'tally', 'would', 'be', '462-456', 'twenty', 'minutes', 'into', 'the', 'game', ',', '[', 'CI', ']', 'i.e.', ',', 'all', 'offense', '.']\n",
      "['Chris', 'Inglis'] => ,\n",
      "['Chris', 'Inglis', ','] => recently\n",
      "['Chris', 'Inglis', ',', 'recently'] => retired\n",
      "['Chris', 'Inglis', ',', 'recently', 'retired'] => NSA\n",
      "['Chris', 'Inglis', ',', 'recently', 'retired', 'NSA'] => Deputy\n",
      "['Inglis', ','] => recently\n",
      "['Inglis', ',', 'recently'] => retired\n",
      "['Inglis', ',', 'recently', 'retired'] => NSA\n",
      "['Inglis', ',', 'recently', 'retired', 'NSA'] => Deputy\n",
      "[',', 'recently'] => retired\n",
      "[',', 'recently', 'retired'] => NSA\n",
      "[',', 'recently', 'retired', 'NSA'] => Deputy\n",
      "['recently', 'retired'] => NSA\n",
      "['recently', 'retired', 'NSA'] => Deputy\n",
      "['retired', 'NSA'] => Deputy\n",
      "['I', 'will', 'take', 'his', 'comment', 'as', 'confirming', 'at', 'the', 'highest', 'level', 'not', 'only', 'the', 'dual', 'use', 'nature', 'of', 'cybersecurity', 'but', 'also', 'confirming', 'that', 'offense', 'is', 'where', 'the', 'innovations', 'that', 'only', 'States', 'can', 'afford', 'is', 'going', 'on', '.']\n",
      "['I', 'will'] => take\n",
      "['I', 'will', 'take'] => his\n",
      "['I', 'will', 'take', 'his'] => comment\n",
      "['I', 'will', 'take', 'his', 'comment'] => as\n",
      "['I', 'will', 'take', 'his', 'comment', 'as'] => confirming\n",
      "['will', 'take'] => his\n",
      "['will', 'take', 'his'] => comment\n",
      "['will', 'take', 'his', 'comment'] => as\n",
      "['will', 'take', 'his', 'comment', 'as'] => confirming\n",
      "['take', 'his'] => comment\n",
      "['take', 'his', 'comment'] => as\n",
      "['take', 'his', 'comment', 'as'] => confirming\n",
      "['his', 'comment'] => as\n",
      "['his', 'comment', 'as'] => confirming\n",
      "['comment', 'as'] => confirming\n",
      "['Nevertheless', ',', 'this', 'essay', 'is', 'an', 'outgrowth', 'from', ',', 'an', 'extension', 'of', ',', 'that', 'increasing', 'importance', 'of', 'cybersecurity', '.']\n",
      "['Nevertheless', ','] => this\n",
      "['Nevertheless', ',', 'this'] => essay\n",
      "['Nevertheless', ',', 'this', 'essay'] => is\n",
      "['Nevertheless', ',', 'this', 'essay', 'is'] => an\n",
      "['Nevertheless', ',', 'this', 'essay', 'is', 'an'] => outgrowth\n",
      "[',', 'this'] => essay\n",
      "[',', 'this', 'essay'] => is\n",
      "[',', 'this', 'essay', 'is'] => an\n",
      "[',', 'this', 'essay', 'is', 'an'] => outgrowth\n",
      "['this', 'essay'] => is\n",
      "['this', 'essay', 'is'] => an\n",
      "['this', 'essay', 'is', 'an'] => outgrowth\n",
      "['essay', 'is'] => an\n",
      "['essay', 'is', 'an'] => outgrowth\n",
      "['is', 'an'] => outgrowth\n",
      "['With', 'the', 'humility', 'of', 'which', 'I', 'spoke', ',', 'I', 'do', 'not', 'claim', 'that', 'I', 'have', 'the', 'last', 'word', '.']\n",
      "['With', 'the'] => humility\n",
      "['With', 'the', 'humility'] => of\n",
      "['With', 'the', 'humility', 'of'] => which\n",
      "['With', 'the', 'humility', 'of', 'which'] => I\n",
      "['With', 'the', 'humility', 'of', 'which', 'I'] => spoke\n",
      "['the', 'humility'] => of\n",
      "['the', 'humility', 'of'] => which\n",
      "['the', 'humility', 'of', 'which'] => I\n",
      "['the', 'humility', 'of', 'which', 'I'] => spoke\n",
      "['humility', 'of'] => which\n",
      "['humility', 'of', 'which'] => I\n",
      "['humility', 'of', 'which', 'I'] => spoke\n",
      "['of', 'which'] => I\n",
      "['of', 'which', 'I'] => spoke\n",
      "['which', 'I'] => spoke\n",
      "['What', 'I', 'do', 'claim', 'is', 'that', 'when', 'we', 'speak', 'about', 'cybersecurity', 'policy', 'we', 'are', 'no', 'longer', 'engaging', 'in', 'some', 'sort', 'of', 'parlor', 'game', '.']\n",
      "['What', 'I'] => do\n",
      "['What', 'I', 'do'] => claim\n",
      "['What', 'I', 'do', 'claim'] => is\n",
      "['What', 'I', 'do', 'claim', 'is'] => that\n",
      "['What', 'I', 'do', 'claim', 'is', 'that'] => when\n",
      "['I', 'do'] => claim\n",
      "['I', 'do', 'claim'] => is\n",
      "['I', 'do', 'claim', 'is'] => that\n",
      "['I', 'do', 'claim', 'is', 'that'] => when\n",
      "['do', 'claim'] => is\n",
      "['do', 'claim', 'is'] => that\n",
      "['do', 'claim', 'is', 'that'] => when\n",
      "['claim', 'is'] => that\n",
      "['claim', 'is', 'that'] => when\n",
      "['is', 'that'] => when\n",
      "['I', 'claim', 'that', 'policy', 'matters', 'are', 'now', 'the', 'most', 'important', 'matters', ',', 'that', 'once', 'a', 'topic', 'area', ',', 'like', 'cybersecurity', ',', 'becomes', 'interlaced', 'with', 'nearly', 'every', 'aspect', 'of', 'life', 'for', 'nearly', 'everybody', ',', 'the', 'outcome', 'differential', 'between', 'good', 'policies', 'and', 'bad', 'policies', 'broadens', ',', 'and', 'the', 'ease', 'of', 'finding', 'answers', 'falls', '.']\n",
      "['I', 'claim'] => that\n",
      "['I', 'claim', 'that'] => policy\n",
      "['I', 'claim', 'that', 'policy'] => matters\n",
      "['I', 'claim', 'that', 'policy', 'matters'] => are\n",
      "['I', 'claim', 'that', 'policy', 'matters', 'are'] => now\n",
      "['claim', 'that'] => policy\n",
      "['claim', 'that', 'policy'] => matters\n",
      "['claim', 'that', 'policy', 'matters'] => are\n",
      "['claim', 'that', 'policy', 'matters', 'are'] => now\n",
      "['that', 'policy'] => matters\n",
      "['that', 'policy', 'matters'] => are\n",
      "['that', 'policy', 'matters', 'are'] => now\n",
      "['policy', 'matters'] => are\n",
      "['policy', 'matters', 'are'] => now\n",
      "['matters', 'are'] => now\n",
      "['As', 'H.L', '.']\n",
      "['As', 'H.L'] => .\n",
      "['Mencken', 'so', 'trenchantly', 'put', 'it', ',', '``', 'For', 'every', 'complex', 'problem', 'there', 'is', 'a', 'solution', 'that', 'is', 'clear', ',', 'simple', ',', 'and', 'wrong', '.', \"''\"]\n",
      "['Mencken', 'so'] => trenchantly\n",
      "['Mencken', 'so', 'trenchantly'] => put\n",
      "['Mencken', 'so', 'trenchantly', 'put'] => it\n",
      "['Mencken', 'so', 'trenchantly', 'put', 'it'] => ,\n",
      "['Mencken', 'so', 'trenchantly', 'put', 'it', ','] => ``\n",
      "['so', 'trenchantly'] => put\n",
      "['so', 'trenchantly', 'put'] => it\n",
      "['so', 'trenchantly', 'put', 'it'] => ,\n",
      "['so', 'trenchantly', 'put', 'it', ','] => ``\n",
      "['trenchantly', 'put'] => it\n",
      "['trenchantly', 'put', 'it'] => ,\n",
      "['trenchantly', 'put', 'it', ','] => ``\n",
      "['put', 'it'] => ,\n",
      "['put', 'it', ','] => ``\n",
      "['it', ','] => ``\n",
      "['The', 'four', 'verities', 'of', 'government', 'are', 'these', ':', '.']\n",
      "['The', 'four'] => verities\n",
      "['The', 'four', 'verities'] => of\n",
      "['The', 'four', 'verities', 'of'] => government\n",
      "['The', 'four', 'verities', 'of', 'government'] => are\n",
      "['The', 'four', 'verities', 'of', 'government', 'are'] => these\n",
      "['four', 'verities'] => of\n",
      "['four', 'verities', 'of'] => government\n",
      "['four', 'verities', 'of', 'government'] => are\n",
      "['four', 'verities', 'of', 'government', 'are'] => these\n",
      "['verities', 'of'] => government\n",
      "['verities', 'of', 'government'] => are\n",
      "['verities', 'of', 'government', 'are'] => these\n",
      "['of', 'government'] => are\n",
      "['of', 'government', 'are'] => these\n",
      "['government', 'are'] => these\n",
      "['Most', 'important', 'ideas', 'are', 'unappealing', '.']\n",
      "['Most', 'important'] => ideas\n",
      "['Most', 'important', 'ideas'] => are\n",
      "['Most', 'important', 'ideas', 'are'] => unappealing\n",
      "['Most', 'important', 'ideas', 'are', 'unappealing'] => .\n",
      "['important', 'ideas'] => are\n",
      "['important', 'ideas', 'are'] => unappealing\n",
      "['important', 'ideas', 'are', 'unappealing'] => .\n",
      "['ideas', 'are'] => unappealing\n",
      "['ideas', 'are', 'unappealing'] => .\n",
      "['are', 'unappealing'] => .\n",
      "['Most', 'appealing', 'ideas', 'are', 'unimportant', '.']\n",
      "['Most', 'appealing'] => ideas\n",
      "['Most', 'appealing', 'ideas'] => are\n",
      "['Most', 'appealing', 'ideas', 'are'] => unimportant\n",
      "['Most', 'appealing', 'ideas', 'are', 'unimportant'] => .\n",
      "['appealing', 'ideas'] => are\n",
      "['appealing', 'ideas', 'are'] => unimportant\n",
      "['appealing', 'ideas', 'are', 'unimportant'] => .\n",
      "['ideas', 'are'] => unimportant\n",
      "['ideas', 'are', 'unimportant'] => .\n",
      "['are', 'unimportant'] => .\n",
      "['Not', 'every', 'problem', 'has', 'a', 'good', 'solution', '.']\n",
      "['Not', 'every'] => problem\n",
      "['Not', 'every', 'problem'] => has\n",
      "['Not', 'every', 'problem', 'has'] => a\n",
      "['Not', 'every', 'problem', 'has', 'a'] => good\n",
      "['Not', 'every', 'problem', 'has', 'a', 'good'] => solution\n",
      "['every', 'problem'] => has\n",
      "['every', 'problem', 'has'] => a\n",
      "['every', 'problem', 'has', 'a'] => good\n",
      "['every', 'problem', 'has', 'a', 'good'] => solution\n",
      "['problem', 'has'] => a\n",
      "['problem', 'has', 'a'] => good\n",
      "['problem', 'has', 'a', 'good'] => solution\n",
      "['has', 'a'] => good\n",
      "['has', 'a', 'good'] => solution\n",
      "['a', 'good'] => solution\n",
      "['Every', 'solution', 'has', 'side', 'effects']\n",
      "['Every', 'solution'] => has\n",
      "['Every', 'solution', 'has'] => side\n",
      "['Every', 'solution', 'has', 'side'] => effects\n",
      "['solution', 'has'] => side\n",
      "['solution', 'has', 'side'] => effects\n",
      "['has', 'side'] => effects\n"
     ]
    }
   ],
   "source": [
    "from nltk import word_tokenize\n",
    "wordTokenizedSentence=[]\n",
    "for sentence in sentences:\n",
    "    wordTokenizedSentence.append(word_tokenize(sentence))\n",
    "\n",
    "x=[]\n",
    "y=[]\n",
    "for sentence in wordTokenizedSentence:\n",
    "    print(sentence)\n",
    "    for i in range(len(sentence)):\n",
    "        j=i+1\n",
    "        while j <= 5:\n",
    "            try:\n",
    "                y.append(sentence[j])\n",
    "                x.append(sentence[i:j])\n",
    "                j+=1\n",
    "                print(sentence[i:j],'=>',sentence[j])\n",
    "            except:\n",
    "                j+=1\n",
    "                continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "5f4d95f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([['['],\n",
       "  ['[', 'nominal'],\n",
       "  ['[', 'nominal', 'delivery'],\n",
       "  ['[', 'nominal', 'delivery', 'draft'],\n",
       "  ['[', 'nominal', 'delivery', 'draft', ',']],\n",
       " ['nominal', 'delivery', 'draft', ',', '6'])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:5],y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f2872bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "emeddingModel=Word2Vec(wordTokenizedSentence, vector_size=15, window=10, min_count=1, workers=4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "e9eab346",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.06246194, -0.049209  ,  0.00407102, -0.02026014, -0.04346866,\n",
       "       -0.00748973, -0.0356756 ,  0.06222412, -0.03854244,  0.02709549,\n",
       "        0.00292689,  0.03292041,  0.01779463,  0.06369314,  0.00115686],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emeddingModel.wv['[']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "3f413da6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.06246194, -0.049209  ,  0.00407102, -0.02026014, -0.04346866,\n",
       "        -0.00748973, -0.0356756 ,  0.06222412, -0.03854244,  0.02709549,\n",
       "         0.00292689,  0.03292041,  0.01779463,  0.06369314,  0.00115686]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "embeddings_x = []\n",
    "embeddings_y = []\n",
    "\n",
    "for sentence in x:\n",
    "    embeddings = []\n",
    "    for word in sentence:\n",
    "        try:\n",
    "            embeddings.append(emeddingModel.wv[word])  # Get the word2vec embedding\n",
    "        except:\n",
    "            continue\n",
    "    embeddings_x.append(np.array(embeddings))\n",
    "\n",
    "embeddings_x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "96c49d12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "459 {'that': 1, 'of': 2, 'is': 3, 'the': 4, 'i': 5, 'are': 6, 'it': 7, 'a': 8, 'to': 9, 'has': 10, 'not': 11, 'will': 12, 'and': 13, 'my': 14, 'black': 15, 'cyber': 16, 'for': 17, 'security': 18, 'in': 19, 'me': 20, 'can': 21, 'good': 22, 'as': 23, 'this': 24, 'all': 25, 'when': 26, 'being': 27, 'tell': 28, 'from': 29, 'be': 30, 'an': 31, 'hat': 32, 'am': 33, 'tool': 34, '6': 35, 'taking': 36, 'which': 37, 'discern': 38, 'beat': 39, 'again': 40, 'laws': 41, 'nothing': 42, 'keep': 43, 'advice': 44, 'truism': 45, 'nsa': 46, 'were': 47, 'cybersecurity': 48, 'those': 49, 'works': 50, 'claim': 51, 'talk': 52, 'let': 53, 'about': 54, 'matters': 55, 'ideas': 56, 'safety': 57, 'order': 58, 'have': 59, 'timidity': 60, 'proposals': 61, 'saying': 62, 'insult': 63, 'seen': 64, 'could': 65, 'reached': 66, 'product': 67, 'change': 68, 'material': 69, 'majority': 70, 'stems': 71, 'retired': 72, 'comment': 73, 'government': 74, 'unappealing': 75, 'unimportant': 76, 'effects': 77, 'wish': 78, 'now': 79, 'possible': 80, 'who': 81, 'policy': 82, 'you': 83, 'eye': 84, 'say': 85, 'talking': 86, 'use': 87, 'draft': 88, 'do': 89, 'professions': 90, 'mean': 91, 'means': 92, 'needed': 93, 'at': 94, 'tried': 95, 'technological': 96, 'ask': 97, 'matter': 98, 'marketing': 99, 'answer': 100, 'feeling': 101, 'recently': 102, 'his': 103, 'essay': 104, 'put': 105, 'side': 106, 'humility': 107, 'every': 108, \"n't\": 109, 'us': 110, 'we': 111, 'how': 112, 'does': 113, 'myself': 114, 'if': 115, 'certainly': 116, 'problem': 117, 'delivery': 118, 'clarity': 119, 'three': 120, 'two': 121, 'only': 122, 'people': 123, 'see': 124, 'large': 125, 'definition': 126, 'take': 127, 'trenchantly': 128, 'verities': 129, 'important': 130, 'or': 131, 'dual': 132, 'ai': 133, 'solution': 134, 'what': 135, 'simple': 136, 'practice': 137, 'but': 138, 'any': 139, 'area': 140, 'specialization': 141, 'nominal': 142, 'with': 143, 'plaintext': 144, 'they': 145, 'expect': 146, 'rate': 147, 'younger': 148, 'most': 149, 'looking': 150, 'suspect': 151, 'your': 152, 'inglis': 153, 'h': 154, 'l': 155, 'so': 156, 'four': 157, 'appealing': 158, 'some': 159, 'their': 160, 'person': 161, 'one': 162, 'know': 163, 'on': 164, 'up': 165, 'technology': 166, 'been': 167, 'policies': 168, 'may': 169, 'into': 170, 'well': 171, 'more': 172, 'taken': 173, 'going': 174, 'nearly': 175, 'then': 176, 'game': 177, 'offense': 178, 'speak': 179, 'today': 180, 'while': 181, 'later': 182, 'used': 183, 'get': 184, 'others': 185, 'there': 186, 'follow': 187, 'presented': 188, 'rather': 189, 'held': 190, 'belief': 191, 'wrong': 192, 'mind': 193, 'issue': 194, 'many': 195, 'than': 196, 'field': 197, 'topic': 198, 'seriously': 199, 'like': 200, 'act': 201, 'perhaps': 202, 'even': 203, 'make': 204, 'last': 205, 'would': 206, 'less': 207, 'keeping': 208, 'highest': 209, 'grasp': 210, 'part': 211, 'enough': 212, 'no': 213, 'way': 214, 'why': 215, 'things': 216, 'once': 217, 'chosen': 218, 'tools': 219, 'these': 220, 'score': 221, 'confirming': 222, 'august': 223, '2014': 224, 'realpolitik': 225, 'dan': 226, 'geer': 227, 'morning': 228, 'thank': 229, 'invitation': 230, 'made': 231, 'available': 232, 'organizers': 233, 'questions': 234, 'welcome': 235, 'contact': 236, 'reply': 237, 'repeat': 238, 'abstract': 239, 'power': 240, 'exists': 241, 'least': 242, 'worst': 243, 'thing': 244, 'fill': 245, 'vacuum': 246, 'wishful': 247, 'thinking': 248, 'practitioners': 249, 'state': 250, 'farming': 251, 'weather': 252, 'forecasting': 253, 'such': 254, 'assure': 255, 'recommendations': 256, 'strongly': 257, 'proven': 258, 'humble': 259, 'changes': 260, 'result': 261, 'considerable': 262, 'push': 263, 'back': 264, 'changing': 265, 'though': 266, 'speech': 267, 'riveting': 268, 'concern': 269, 'top': 270, 'venues': 271, 'note': 272, 'speaker': 273, 'writer': 274, 'practitioner': 275, 'wished': 276, 'its': 277, 'gotten': 278, 'same': 279, 'usefully': 280, 'coherently': 281, 'lastingly': 282, 'whether': 283, 'digital': 284, 'millenium': 285, 'copyright': 286, 'computer': 287, 'fraud': 288, 'abuse': 289, 'non': 290, 'lawmaking': 291, 'significant': 292, 'actions': 293, 'executive': 294, 'agencies': 295, 'undertaking': 296, 'never': 297, 'forefront': 298, \"ain't\": 299, 'yet': 300, 'still': 301, 'hold': 302, 'big': 303, 'picture': 304, 'firmly': 305, \"mind's\": 306, 'track': 307, 'everything': 308, 'our': 309, 'few': 310, 'sins': 311, 'omission': 312, 'phase': 313, 'passed': 314, 'sometime': 315, 'six': 316, 'years': 317, 'candid': 318, 'own': 319, 'country': 320, 'much': 321, 'countries': 322, 'levels': 323, 'attention': 324, 'spread': 325, 'corner': 326, 'height': 327, 'width': 328, 'footprint': 329, 'surpassed': 330, 'should': 331, 'study': 332, 'career': 333, 'advise': 334, 'early': 335, 'managed': 336, 'retain': 337, 'over': 338, 'arching': 339, 'generalist': 340, 'knowledge': 341, \"can't\": 342, 'replaced': 343, 'very': 344, 'easily': 345, 'because': 346, 'absorbing': 347, 'new': 348, 'information': 349, 'time': 350, 'began': 351, 'starting': 352, 'scratch': 353, 'serial': 354, 'done': 355, 'practical': 356, 'just': 357, 'program': 358, 'confirm': 359, 'really': 360, 'topics': 361, 'here': 362, 'requires': 363, 'shutting': 364, 'out': 365, 'demands': 366, 'speaking': 367, 'interested': 368, 'advantages': 369, 'disadvantages': 370, 'bit': 371, 'unless': 372, 'whenever': 373, 'tells': 374, 'adopting': 375, 'makes': 376, 'remember': 377, 'george': 378, 'santayana': 379, 'said': 380, 'scepticism': 381, 'chastity': 382, 'intellect': 383, 'shameful': 384, 'give': 385, 'too': 386, 'soon': 387, 'first': 388, 'comer': 389, 'similar': 390, 'skepticism': 391, \"it's\": 392, 'magic': 393, 'ever': 394, 'accept': 395, 'by': 396, 'something': 397, 'particular': 398, 'mechanisms': 399, 'them': 400, 'long': 401, 'substantiated': 402, 'scalpel': 403, 'hammer': 404, 'gas': 405, 'ill': 406, 'inherent': 407, 'wide': 408, 'suggest': 409, 'set': 410, 'favors': 411, 'days': 412, 'chris': 413, 'deputy': 414, 'director': 415, 'remarked': 416, 'soccer': 417, 'tally': 418, '462': 419, '456': 420, 'twenty': 421, 'minutes': 422, 'ci': 423, 'e': 424, 'level': 425, 'nature': 426, 'also': 427, 'where': 428, 'innovations': 429, 'states': 430, 'afford': 431, 'nevertheless': 432, 'outgrowth': 433, 'extension': 434, 'increasing': 435, 'importance': 436, 'spoke': 437, 'word': 438, 'longer': 439, 'engaging': 440, 'sort': 441, 'parlor': 442, 'becomes': 443, 'interlaced': 444, 'aspect': 445, 'life': 446, 'everybody': 447, 'outcome': 448, 'differential': 449, 'between': 450, 'bad': 451, 'broadens': 452, 'ease': 453, 'finding': 454, 'answers': 455, 'falls': 456, 'mencken': 457, 'complex': 458, 'clear': 459}\n"
     ]
    }
   ],
   "source": [
    "tokenizer.fit_on_texts(y)\n",
    "print(len(tokenizer.word_index),tokenizer.word_index)\n",
    "for word in y:\n",
    "    try:\n",
    "        e=tokenizer.texts_to_sequences([word])[0][0]\n",
    "    except:\n",
    "        e=0\n",
    "    embeddings_y.append(e)\n",
    "embeddings_y=np.array(embeddings_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "eb564244",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "743"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "27cde558",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.06246194, -0.049209  ,  0.00407102, -0.02026014, -0.04346866,\n",
       "        -0.00748973, -0.0356756 ,  0.06222412, -0.03854244,  0.02709549,\n",
       "         0.00292689,  0.03292041,  0.01779463,  0.06369314,  0.00115686]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "e904164e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.06246194, -0.049209  ,  0.00407102, -0.02026014, -0.04346866,\n",
       "        -0.00748973, -0.0356756 ,  0.06222412, -0.03854244,  0.02709549,\n",
       "         0.00292689,  0.03292041,  0.01779463,  0.06369314,  0.00115686],\n",
       "       [-0.05683396,  0.05229538, -0.05341402,  0.0306057 ,  0.06263665,\n",
       "         0.03840695,  0.04100427,  0.05531496,  0.02296231, -0.0471125 ,\n",
       "         0.03942722, -0.05425759, -0.03720862,  0.03856581, -0.05377772]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_x[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "9bec3813",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.06246194, -0.049209  ,  0.00407102, -0.02026014, -0.04346866,\n",
       "        -0.00748973, -0.0356756 ,  0.06222412, -0.03854244,  0.02709549,\n",
       "         0.00292689,  0.03292041,  0.01779463,  0.06369314,  0.00115686],\n",
       "       [-0.05683396,  0.05229538, -0.05341402,  0.0306057 ,  0.06263665,\n",
       "         0.03840695,  0.04100427,  0.05531496,  0.02296231, -0.0471125 ,\n",
       "         0.03942722, -0.05425759, -0.03720862,  0.03856581, -0.05377772],\n",
       "       [-0.03969079, -0.02383095,  0.02410348,  0.03382367,  0.01345079,\n",
       "         0.0347387 , -0.01769079,  0.02956779, -0.04704267, -0.01040189,\n",
       "        -0.05036606,  0.00243362,  0.03236112,  0.03101156, -0.03196787]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_x[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "dc877359",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.06246194, -0.049209  ,  0.00407102, -0.02026014, -0.04346866,\n",
       "         -0.00748973, -0.0356756 ,  0.06222412, -0.03854244,  0.02709549,\n",
       "          0.00292689,  0.03292041,  0.01779463,  0.06369314,  0.00115686],\n",
       "        [-0.05683396,  0.05229538, -0.05341402,  0.0306057 ,  0.06263665,\n",
       "          0.03840695,  0.04100427,  0.05531496,  0.02296231, -0.0471125 ,\n",
       "          0.03942722, -0.05425759, -0.03720862,  0.03856581, -0.05377772],\n",
       "        [-0.03969079, -0.02383095,  0.02410348,  0.03382367,  0.01345079,\n",
       "          0.0347387 , -0.01769079,  0.02956779, -0.04704267, -0.01040189,\n",
       "         -0.05036606,  0.00243362,  0.03236112,  0.03101156, -0.03196787],\n",
       "        [ 0.01106247,  0.05192446, -0.03524574, -0.02650766, -0.00426547,\n",
       "         -0.03063049,  0.05779214,  0.05081302,  0.06144317,  0.06326098,\n",
       "         -0.05483432, -0.0015293 , -0.04956562, -0.03316838, -0.06006755]],\n",
       "       dtype=float32),\n",
       " 0)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_x[3],embeddings_y[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "b80bdcb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxsize=[]\n",
    "for i in embeddings_x:\n",
    "    maxsize.append(i.shape[0])\n",
    "max(maxsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d61020ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 15)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_x[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "a48b6e4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.06246194, -0.049209  ,  0.00407102, ...,  0.01779463,\n",
       "          0.06369314,  0.00115686]],\n",
       "\n",
       "       [[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.06246194, -0.049209  ,  0.00407102, ...,  0.01779463,\n",
       "          0.06369314,  0.00115686],\n",
       "        [-0.05683396,  0.05229538, -0.05341402, ..., -0.03720862,\n",
       "          0.03856581, -0.05377772]],\n",
       "\n",
       "       [[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.06246194, -0.049209  ,  0.00407102, ...,  0.01779463,\n",
       "          0.06369314,  0.00115686],\n",
       "        [-0.05683396,  0.05229538, -0.05341402, ..., -0.03720862,\n",
       "          0.03856581, -0.05377772],\n",
       "        [-0.03969079, -0.02383095,  0.02410348, ...,  0.03236112,\n",
       "          0.03101156, -0.03196787]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [-0.00091926, -0.02648852, -0.03698023, ...,  0.05022385,\n",
       "         -0.0236564 ,  0.04158781]],\n",
       "\n",
       "       [[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [-0.00091926, -0.02648852, -0.03698023, ...,  0.05022385,\n",
       "         -0.0236564 ,  0.04158781],\n",
       "        [ 0.01310604,  0.01614948,  0.03378637, ..., -0.04875587,\n",
       "          0.03600669, -0.02195277]],\n",
       "\n",
       "       [[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.01310604,  0.01614948,  0.03378637, ..., -0.04875587,\n",
       "          0.03600669, -0.02195277]]], dtype=float32)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_sequences_padded_x = pad_sequences(\n",
    "    embeddings_x,\n",
    "    maxlen=5,\n",
    "    dtype='float32',\n",
    "    padding='pre'\n",
    ")\n",
    "embedding_sequences_padded_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "aeecd459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(5, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(4, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(3, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n",
      "(2, 15) (5, 15)\n",
      "(1, 15) (5, 15)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(embedding_sequences_padded_x)):\n",
    "    print(embeddings_x[i].shape, embedding_sequences_padded_x[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "afda4c00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1229, (743, 5, 15))"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emeddingModel.corpus_total_words,embedding_sequences_padded_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "dee6f5f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\DeepLearning\\Code\\env\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_9\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_9\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ gru (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">15,552</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,408</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">744</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">24,552</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ gru (\u001b[38;5;33mGRU\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │        \u001b[38;5;34m15,552\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru_1 (\u001b[38;5;33mGRU\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m9,408\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m744\u001b[0m)            │        \u001b[38;5;34m24,552\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">49,512</span> (193.41 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m49,512\u001b[0m (193.41 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">49,512</span> (193.41 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m49,512\u001b[0m (193.41 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    GRU(64,activation='relu', input_shape=(5, 15),return_sequences=True),\n",
    "    Dropout(0.05),\n",
    "    GRU(32,activation='relu'),\n",
    "    Dense(744,activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "197dc0c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((743, 5, 15), (743,))"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_sequences_padded_x.shape,embeddings_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "6470aa3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8151 - loss: 0.4938\n",
      "Epoch 2/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8184 - loss: 0.4426\n",
      "Epoch 3/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8287 - loss: 0.4633\n",
      "Epoch 4/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8207 - loss: 0.4719\n",
      "Epoch 5/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8053 - loss: 0.5212\n",
      "Epoch 6/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8386 - loss: 0.4516\n",
      "Epoch 7/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8046 - loss: 0.4860\n",
      "Epoch 8/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8251 - loss: 0.4701\n",
      "Epoch 9/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8208 - loss: 0.4978\n",
      "Epoch 10/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8404 - loss: 0.4567\n",
      "Epoch 11/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8356 - loss: 0.4750\n",
      "Epoch 12/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8296 - loss: 0.4692\n",
      "Epoch 13/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8225 - loss: 0.4778\n",
      "Epoch 14/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8284 - loss: 0.4878\n",
      "Epoch 15/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8485 - loss: 0.4272\n",
      "Epoch 16/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8543 - loss: 0.4169\n",
      "Epoch 17/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8423 - loss: 0.4446\n",
      "Epoch 18/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8413 - loss: 0.4442\n",
      "Epoch 19/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8162 - loss: 0.4477\n",
      "Epoch 20/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8519 - loss: 0.4381\n",
      "Epoch 21/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8527 - loss: 0.4013\n",
      "Epoch 22/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8624 - loss: 0.3874\n",
      "Epoch 23/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8249 - loss: 0.4767\n",
      "Epoch 24/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8393 - loss: 0.4465\n",
      "Epoch 25/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8387 - loss: 0.4394\n",
      "Epoch 26/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8174 - loss: 0.4607\n",
      "Epoch 27/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8364 - loss: 0.4645\n",
      "Epoch 28/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8332 - loss: 0.4285\n",
      "Epoch 29/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8632 - loss: 0.4096\n",
      "Epoch 30/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8293 - loss: 0.4203\n",
      "Epoch 31/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8264 - loss: 0.4345\n",
      "Epoch 32/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8528 - loss: 0.4032\n",
      "Epoch 33/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8416 - loss: 0.4169\n",
      "Epoch 34/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8241 - loss: 0.4484\n",
      "Epoch 35/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8219 - loss: 0.4799\n",
      "Epoch 36/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8409 - loss: 0.4438\n",
      "Epoch 37/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8293 - loss: 0.4921\n",
      "Epoch 38/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8136 - loss: 0.4877\n",
      "Epoch 39/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8385 - loss: 0.4310\n",
      "Epoch 40/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8405 - loss: 0.4318\n",
      "Epoch 41/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8164 - loss: 0.4847\n",
      "Epoch 42/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8288 - loss: 0.4720\n",
      "Epoch 43/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8129 - loss: 0.5314\n",
      "Epoch 44/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8162 - loss: 0.4356\n",
      "Epoch 45/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8446 - loss: 0.3969\n",
      "Epoch 46/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8398 - loss: 0.4137\n",
      "Epoch 47/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8409 - loss: 0.4384\n",
      "Epoch 48/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8258 - loss: 0.4266\n",
      "Epoch 49/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8423 - loss: 0.4326\n",
      "Epoch 50/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8204 - loss: 0.4899\n",
      "Epoch 51/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8498 - loss: 0.3884\n",
      "Epoch 52/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8414 - loss: 0.4028\n",
      "Epoch 53/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8412 - loss: 0.4261\n",
      "Epoch 54/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8371 - loss: 0.4177\n",
      "Epoch 55/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8221 - loss: 0.4771\n",
      "Epoch 56/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8326 - loss: 0.4856\n",
      "Epoch 57/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8239 - loss: 0.4636\n",
      "Epoch 58/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8535 - loss: 0.4143\n",
      "Epoch 59/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8217 - loss: 0.4487\n",
      "Epoch 60/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8325 - loss: 0.4349\n",
      "Epoch 61/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8410 - loss: 0.4339\n",
      "Epoch 62/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8376 - loss: 0.4156\n",
      "Epoch 63/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8269 - loss: 0.4546\n",
      "Epoch 64/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8414 - loss: 0.3877\n",
      "Epoch 65/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8392 - loss: 0.3846\n",
      "Epoch 66/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8316 - loss: 0.4336\n",
      "Epoch 67/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8448 - loss: 0.4016\n",
      "Epoch 68/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8262 - loss: 0.4450\n",
      "Epoch 69/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8495 - loss: 0.4022\n",
      "Epoch 70/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8429 - loss: 0.4033\n",
      "Epoch 71/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8234 - loss: 0.4553\n",
      "Epoch 72/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8536 - loss: 0.4144\n",
      "Epoch 73/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8142 - loss: 0.4623\n",
      "Epoch 74/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8499 - loss: 0.3997\n",
      "Epoch 75/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8453 - loss: 0.4558\n",
      "Epoch 76/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8239 - loss: 0.4506\n",
      "Epoch 77/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8526 - loss: 0.3630\n",
      "Epoch 78/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8433 - loss: 0.4292\n",
      "Epoch 79/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8305 - loss: 0.4387\n",
      "Epoch 80/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8563 - loss: 0.3732\n",
      "Epoch 81/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8527 - loss: 0.3691\n",
      "Epoch 82/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8303 - loss: 0.4333\n",
      "Epoch 83/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8372 - loss: 0.4272\n",
      "Epoch 84/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8378 - loss: 0.4448\n",
      "Epoch 85/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8279 - loss: 0.4445\n",
      "Epoch 86/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8516 - loss: 0.3950\n",
      "Epoch 87/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8578 - loss: 0.3951\n",
      "Epoch 88/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8543 - loss: 0.3775\n",
      "Epoch 89/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8470 - loss: 0.4038\n",
      "Epoch 90/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8359 - loss: 0.4630\n",
      "Epoch 91/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8572 - loss: 0.3595\n",
      "Epoch 92/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8740 - loss: 0.3909\n",
      "Epoch 93/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8160 - loss: 0.4585\n",
      "Epoch 94/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8559 - loss: 0.3816\n",
      "Epoch 95/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8677 - loss: 0.3355\n",
      "Epoch 96/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8271 - loss: 0.3973\n",
      "Epoch 97/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8476 - loss: 0.3905\n",
      "Epoch 98/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8703 - loss: 0.3437\n",
      "Epoch 99/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8449 - loss: 0.3796\n",
      "Epoch 100/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8593 - loss: 0.3694\n",
      "Epoch 101/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8500 - loss: 0.3675\n",
      "Epoch 102/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8422 - loss: 0.4106\n",
      "Epoch 103/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8353 - loss: 0.4397\n",
      "Epoch 104/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8446 - loss: 0.3944\n",
      "Epoch 105/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8712 - loss: 0.3616\n",
      "Epoch 106/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8332 - loss: 0.4173\n",
      "Epoch 107/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8560 - loss: 0.3820\n",
      "Epoch 108/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8519 - loss: 0.3934\n",
      "Epoch 109/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8563 - loss: 0.3597\n",
      "Epoch 110/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8503 - loss: 0.4156\n",
      "Epoch 111/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8429 - loss: 0.3834\n",
      "Epoch 112/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8464 - loss: 0.3916\n",
      "Epoch 113/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8514 - loss: 0.4216\n",
      "Epoch 114/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8347 - loss: 0.4392\n",
      "Epoch 115/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8488 - loss: 0.3605\n",
      "Epoch 116/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8571 - loss: 0.4055\n",
      "Epoch 117/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8656 - loss: 0.3730\n",
      "Epoch 118/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8568 - loss: 0.3726\n",
      "Epoch 119/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8403 - loss: 0.3973\n",
      "Epoch 120/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8458 - loss: 0.4052\n",
      "Epoch 121/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8477 - loss: 0.3640\n",
      "Epoch 122/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8501 - loss: 0.3746\n",
      "Epoch 123/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8604 - loss: 0.3953\n",
      "Epoch 124/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8300 - loss: 0.3857\n",
      "Epoch 125/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8595 - loss: 0.3795\n",
      "Epoch 126/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8283 - loss: 0.4570\n",
      "Epoch 127/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8576 - loss: 0.3724\n",
      "Epoch 128/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8409 - loss: 0.4336\n",
      "Epoch 129/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8198 - loss: 0.4392\n",
      "Epoch 130/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8747 - loss: 0.3744\n",
      "Epoch 131/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8740 - loss: 0.3467\n",
      "Epoch 132/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8589 - loss: 0.3628\n",
      "Epoch 133/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8621 - loss: 0.3571\n",
      "Epoch 134/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8588 - loss: 0.4110\n",
      "Epoch 135/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8534 - loss: 0.3658\n",
      "Epoch 136/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8546 - loss: 0.3612\n",
      "Epoch 137/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8470 - loss: 0.3645\n",
      "Epoch 138/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8671 - loss: 0.3829\n",
      "Epoch 139/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8163 - loss: 0.4514\n",
      "Epoch 140/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8251 - loss: 0.4005\n",
      "Epoch 141/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8651 - loss: 0.3372\n",
      "Epoch 142/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8397 - loss: 0.4166\n",
      "Epoch 143/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8268 - loss: 0.4215\n",
      "Epoch 144/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8563 - loss: 0.3772\n",
      "Epoch 145/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8474 - loss: 0.3976\n",
      "Epoch 146/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8475 - loss: 0.3767\n",
      "Epoch 147/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8528 - loss: 0.3888\n",
      "Epoch 148/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8545 - loss: 0.3544\n",
      "Epoch 149/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8692 - loss: 0.3395\n",
      "Epoch 150/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8586 - loss: 0.3521\n",
      "Epoch 151/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8579 - loss: 0.3503\n",
      "Epoch 152/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8681 - loss: 0.3422\n",
      "Epoch 153/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8659 - loss: 0.3556\n",
      "Epoch 154/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8729 - loss: 0.3413\n",
      "Epoch 155/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8590 - loss: 0.3637\n",
      "Epoch 156/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8770 - loss: 0.3223\n",
      "Epoch 157/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8477 - loss: 0.3621\n",
      "Epoch 158/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8547 - loss: 0.4242\n",
      "Epoch 159/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8563 - loss: 0.3636\n",
      "Epoch 160/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8378 - loss: 0.3932\n",
      "Epoch 161/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8618 - loss: 0.3486\n",
      "Epoch 162/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8674 - loss: 0.3566\n",
      "Epoch 163/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8647 - loss: 0.3586\n",
      "Epoch 164/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8510 - loss: 0.3686\n",
      "Epoch 165/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8604 - loss: 0.3763\n",
      "Epoch 166/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8446 - loss: 0.3976\n",
      "Epoch 167/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8488 - loss: 0.3796\n",
      "Epoch 168/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8496 - loss: 0.4067\n",
      "Epoch 169/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8640 - loss: 0.3688\n",
      "Epoch 170/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8795 - loss: 0.3422\n",
      "Epoch 171/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8573 - loss: 0.3568\n",
      "Epoch 172/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8411 - loss: 0.3854\n",
      "Epoch 173/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8654 - loss: 0.3541\n",
      "Epoch 174/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8693 - loss: 0.3559\n",
      "Epoch 175/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8393 - loss: 0.3701\n",
      "Epoch 176/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8554 - loss: 0.3902\n",
      "Epoch 177/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8513 - loss: 0.3622\n",
      "Epoch 178/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8535 - loss: 0.3557\n",
      "Epoch 179/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8291 - loss: 0.3892\n",
      "Epoch 180/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8667 - loss: 0.3255\n",
      "Epoch 181/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8403 - loss: 0.3966\n",
      "Epoch 182/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8661 - loss: 0.3252\n",
      "Epoch 183/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8794 - loss: 0.3084\n",
      "Epoch 184/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8676 - loss: 0.3467\n",
      "Epoch 185/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8406 - loss: 0.3704\n",
      "Epoch 186/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8671 - loss: 0.3303\n",
      "Epoch 187/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8657 - loss: 0.3583\n",
      "Epoch 188/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8594 - loss: 0.3413\n",
      "Epoch 189/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8625 - loss: 0.3475\n",
      "Epoch 190/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8880 - loss: 0.2980\n",
      "Epoch 191/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8473 - loss: 0.3644\n",
      "Epoch 192/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8715 - loss: 0.3527\n",
      "Epoch 193/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8454 - loss: 0.3837\n",
      "Epoch 194/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8493 - loss: 0.3344\n",
      "Epoch 195/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8675 - loss: 0.3351\n",
      "Epoch 196/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8623 - loss: 0.3426\n",
      "Epoch 197/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8800 - loss: 0.3219\n",
      "Epoch 198/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8546 - loss: 0.3670\n",
      "Epoch 199/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8712 - loss: 0.3091\n",
      "Epoch 200/200\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8788 - loss: 0.3122\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x168ccf2c500>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "earlystopping=EarlyStopping(monitor='val_loss',patience=20,restore_best_weights=True)\n",
    "model.fit(embedding_sequences_padded_x, embeddings_y , batch_size=32, epochs=200, callbacks=[earlystopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e076e15f",
   "metadata": {},
   "source": [
    "- Those of us who are backing out our remaining dependencies on digital goods and services are being entirely rational and are likely to survive.\n",
    "- I say that because the root cause of risk is dependence, and most especially dependence on expectations of system state.\n",
    "- If I don't use my trademark, then my rights go over to those who use what was and could have remained mine.\n",
    "- For better or poorer, the only two products not covered by product liability today are religion and software, and software should not escape for much longer.\n",
    "\n",
    "<bR><br>\n",
    "\n",
    "- There are three professions that beat their practitioners into a state of humility: farming, weather forecasting, and cyber security. I practice two of those, and, as such, let me assure you that the recommendations which follow are presented in all humility.  Humility does not mean timidity.  Rather, it means that when a strongly held belief is proven wrong, that the humble person changes their mind. I expect that my proposals will result in considerable push-back, and changing my mind may well follow.  Though I will say it again later, this speech is me talking for myself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "cdb0510c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Whether we are talking about laws\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "Top predictions:\n",
      "the: 1.0000\n",
      "are: 0.0000\n",
      "<UNK>: 0.0000\n",
      "it: 0.0000\n",
      "i: 0.0000\n",
      "\n",
      " Whether we are talking about\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "Top predictions:\n",
      "laws: 1.0000\n",
      "good: 0.0000\n",
      "<UNK>: 0.0000\n",
      "has: 0.0000\n",
      "a: 0.0000\n",
      "\n",
      " Whether we are talking\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "Top predictions:\n",
      "about: 0.9994\n",
      "<UNK>: 0.0006\n",
      "that: 0.0000\n",
      "is: 0.0000\n",
      "professions: 0.0000\n",
      "\n",
      " Whether we are\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "Top predictions:\n",
      "talking: 0.9693\n",
      "unappealing: 0.0206\n",
      "unimportant: 0.0100\n",
      "three: 0.0001\n",
      "<UNK>: 0.0000\n",
      "\n",
      " Whether we\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "Top predictions:\n",
      "are: 0.9941\n",
      "of: 0.0032\n",
      "this: 0.0011\n",
      "my: 0.0005\n",
      "<UNK>: 0.0004\n",
      "\n",
      " Whether\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "Top predictions:\n",
      "we: 0.9460\n",
      "a: 0.0206\n",
      "is: 0.0175\n",
      "i: 0.0102\n",
      "of: 0.0019\n",
      "\n",
      " like the Digital Millenium\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "Top predictions:\n",
      "that: 0.9964\n",
      "claim: 0.0016\n",
      "<UNK>: 0.0015\n",
      "about: 0.0003\n",
      "a: 0.0001\n",
      "\n",
      " like the Digital\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "Top predictions:\n",
      "i: 0.7364\n",
      "of: 0.2628\n",
      "that: 0.0008\n",
      "saying: 0.0000\n",
      "and: 0.0000\n"
     ]
    }
   ],
   "source": [
    "input=[\"Whether we are talking about laws\",\"Whether we are talking about\",\"Whether we are talking\",\"Whether we are\",\"Whether we\",\"Whether\",\"like the Digital Millenium\",\"like the Digital\"]\n",
    "for line in input:\n",
    "    print('\\n',line)\n",
    "    input=line.split(' ')\n",
    "    embeddings=[]\n",
    "    if len(input) >=5:\n",
    "        for word in input[len(input)-5:]:\n",
    "            e=emeddingModel.wv[word]\n",
    "            embeddings.append(e)\n",
    "    else:\n",
    "        for word in input:\n",
    "            e=emeddingModel.wv[word]\n",
    "            embeddings.append(e)\n",
    "\n",
    "    embeddings=np.array(embeddings)\n",
    "    \n",
    "    if embeddings.shape[0] < 5:  # If embeddings has shape as (3,15)\n",
    "        diff=5-embeddings.shape[0]\n",
    "        arr=np.zeros((diff,15))\n",
    "        embeddings=np.vstack((arr,embeddings))\n",
    "\n",
    "\n",
    "    embeddings=embeddings.reshape(1, 5, 15)  # Had to reshape since the training shape was (743, 5, 15) for embedding_sequences_padded_x\n",
    "\n",
    "    prediction = model.predict(embeddings)\n",
    "    top_n = 5\n",
    "    top_indices = prediction[0].argsort()[-top_n:][::-1]\n",
    "    top_words = [(tokenizer.index_word.get(i, \"<UNK>\"), prediction[0][i]) for i in top_indices]\n",
    "\n",
    "    print(\"Top predictions:\")\n",
    "    for word, score in top_words:\n",
    "        print(f\"{word}: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "f4506d9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 5, 15)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7f50a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4328b440",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc1ea24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2afc94d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
