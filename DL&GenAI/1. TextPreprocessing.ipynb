{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0994be39",
   "metadata": {},
   "source": [
    "- Tokenization\n",
    "- Stemming\n",
    "- Lemmatization\n",
    "- Stop words\n",
    "- POS Tagging\n",
    "- Named Entity Regognition/tags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289099da",
   "metadata": {},
   "source": [
    "<Br><Br><Br><Br><Br><Br>\n",
    "\n",
    "# Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "131f3727",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to C:\\Users\\Ansh\n",
      "[nltk_data]     Vaid\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Ansh\n",
      "[nltk_data]     Vaid\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\Ansh\n",
      "[nltk_data]     Vaid\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\Ansh Vaid\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker_tab to C:\\Users\\Ansh\n",
      "[nltk_data]     Vaid\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker_tab is already up-to-date!\n",
      "[nltk_data] Downloading package words to C:\\Users\\Ansh\n",
      "[nltk_data]     Vaid\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger_eng')\n",
    "nltk.download('maxent_ne_chunker_tab')\n",
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus=\"\"\"\n",
    "Cybersecurity is the practice of protecting digital systems, networks, and sensitive information from unauthorized access, theft, damage, or disruption. \n",
    "With the rapid growth of the internet and the increasing reliance on digital technologies, cybersecurity has become a critical concern for businesses, \n",
    "governments, and individuals alike. It involves a combination of strategies, tools, and best practices designed to secure software, \n",
    "hardware, and data. These include encryption, firewalls, multi-factor authentication, and regular security audits. As cyber threats evolve, \n",
    "cybersecurity professionals must stay ahead of hackers and malware, working to anticipate vulnerabilities and mitigate risks. In an era where \n",
    "data breaches and cyberattacks are becoming more frequent and sophisticated, investing in robust cybersecurity measures is essential to safeguarding \n",
    "privacy and maintaining trust in the digital world.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nCybersecurity is the practice of protecting digital systems, networks, and sensitive information from unauthorized access, theft, damage, or disruption. \\nWith the rapid growth of the internet and the increasing reliance on digital technologies, cybersecurity has become a critical concern for businesses, \\ngovernments, and individuals alike. It involves a combination of strategies, tools, and best practices designed to secure software, \\nhardware, and data. These include encryption, firewalls, multi-factor authentication, and regular security audits. As cyber threats evolve, \\ncybersecurity professionals must stay ahead of hackers and malware, working to anticipate vulnerabilities and mitigate risks. In an era where \\ndata breaches and cyberattacks are becoming more frequent and sophisticated, investing in robust cybersecurity measures is essential to safeguarding \\nprivacy and maintaining trust in the digital world.\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\nCybersecurity is the practice of protecting digital systems, networks, and sensitive information from unauthorized access, theft, damage, or disruption.',\n",
       " 'With the rapid growth of the internet and the increasing reliance on digital technologies, cybersecurity has become a critical concern for businesses, \\ngovernments, and individuals alike.',\n",
       " 'It involves a combination of strategies, tools, and best practices designed to secure software, \\nhardware, and data.',\n",
       " 'These include encryption, firewalls, multi-factor authentication, and regular security audits.',\n",
       " 'As cyber threats evolve, \\ncybersecurity professionals must stay ahead of hackers and malware, working to anticipate vulnerabilities and mitigate risks.',\n",
       " 'In an era where \\ndata breaches and cyberattacks are becoming more frequent and sophisticated, investing in robust cybersecurity measures is essential to safeguarding \\nprivacy and maintaining trust in the digital world.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_tokenize(corpus)  # Para to sentences (tokenization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8c01d00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs=sent_tokenize(corpus)\n",
    "type(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7cc888de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ef3210d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Cybersecurity',\n",
       " 'is',\n",
       " 'the',\n",
       " 'practice',\n",
       " 'of',\n",
       " 'protecting',\n",
       " 'digital',\n",
       " 'systems',\n",
       " ',',\n",
       " 'networks',\n",
       " ',',\n",
       " 'and',\n",
       " 'sensitive',\n",
       " 'information',\n",
       " 'from',\n",
       " 'unauthorized',\n",
       " 'access',\n",
       " ',',\n",
       " 'theft',\n",
       " ',',\n",
       " 'damage',\n",
       " ',',\n",
       " 'or',\n",
       " 'disruption',\n",
       " '.',\n",
       " 'With',\n",
       " 'the',\n",
       " 'rapid',\n",
       " 'growth',\n",
       " 'of',\n",
       " 'the',\n",
       " 'internet',\n",
       " 'and',\n",
       " 'the',\n",
       " 'increasing',\n",
       " 'reliance',\n",
       " 'on',\n",
       " 'digital',\n",
       " 'technologies',\n",
       " ',',\n",
       " 'cybersecurity',\n",
       " 'has',\n",
       " 'become',\n",
       " 'a',\n",
       " 'critical',\n",
       " 'concern',\n",
       " 'for',\n",
       " 'businesses',\n",
       " ',',\n",
       " 'governments',\n",
       " ',',\n",
       " 'and',\n",
       " 'individuals',\n",
       " 'alike',\n",
       " '.',\n",
       " 'It',\n",
       " 'involves',\n",
       " 'a',\n",
       " 'combination',\n",
       " 'of',\n",
       " 'strategies',\n",
       " ',',\n",
       " 'tools',\n",
       " ',',\n",
       " 'and',\n",
       " 'best',\n",
       " 'practices',\n",
       " 'designed',\n",
       " 'to',\n",
       " 'secure',\n",
       " 'software',\n",
       " ',',\n",
       " 'hardware',\n",
       " ',',\n",
       " 'and',\n",
       " 'data',\n",
       " '.',\n",
       " 'These',\n",
       " 'include',\n",
       " 'encryption',\n",
       " ',',\n",
       " 'firewalls',\n",
       " ',',\n",
       " 'multi-factor',\n",
       " 'authentication',\n",
       " ',',\n",
       " 'and',\n",
       " 'regular',\n",
       " 'security',\n",
       " 'audits',\n",
       " '.',\n",
       " 'As',\n",
       " 'cyber',\n",
       " 'threats',\n",
       " 'evolve',\n",
       " ',',\n",
       " 'cybersecurity',\n",
       " 'professionals',\n",
       " 'must',\n",
       " 'stay',\n",
       " 'ahead',\n",
       " 'of',\n",
       " 'hackers',\n",
       " 'and',\n",
       " 'malware',\n",
       " ',',\n",
       " 'working',\n",
       " 'to',\n",
       " 'anticipate',\n",
       " 'vulnerabilities',\n",
       " 'and',\n",
       " 'mitigate',\n",
       " 'risks',\n",
       " '.',\n",
       " 'In',\n",
       " 'an',\n",
       " 'era',\n",
       " 'where',\n",
       " 'data',\n",
       " 'breaches',\n",
       " 'and',\n",
       " 'cyberattacks',\n",
       " 'are',\n",
       " 'becoming',\n",
       " 'more',\n",
       " 'frequent',\n",
       " 'and',\n",
       " 'sophisticated',\n",
       " ',',\n",
       " 'investing',\n",
       " 'in',\n",
       " 'robust',\n",
       " 'cybersecurity',\n",
       " 'measures',\n",
       " 'is',\n",
       " 'essential',\n",
       " 'to',\n",
       " 'safeguarding',\n",
       " 'privacy',\n",
       " 'and',\n",
       " 'maintaining',\n",
       " 'trust',\n",
       " 'in',\n",
       " 'the',\n",
       " 'digital',\n",
       " 'world',\n",
       " '.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8858298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Cybersecurity', 'is', 'the', 'practice', 'of', 'protecting', 'digital', 'systems', ',', 'networks', ',', 'and', 'sensitive', 'information', 'from', 'unauthorized', 'access', ',', 'theft', ',', 'damage', ',', 'or', 'disruption', '.']\n",
      "['With', 'the', 'rapid', 'growth', 'of', 'the', 'internet', 'and', 'the', 'increasing', 'reliance', 'on', 'digital', 'technologies', ',', 'cybersecurity', 'has', 'become', 'a', 'critical', 'concern', 'for', 'businesses', ',', 'governments', ',', 'and', 'individuals', 'alike', '.']\n",
      "['It', 'involves', 'a', 'combination', 'of', 'strategies', ',', 'tools', ',', 'and', 'best', 'practices', 'designed', 'to', 'secure', 'software', ',', 'hardware', ',', 'and', 'data', '.']\n",
      "['These', 'include', 'encryption', ',', 'firewalls', ',', 'multi-factor', 'authentication', ',', 'and', 'regular', 'security', 'audits', '.']\n",
      "['As', 'cyber', 'threats', 'evolve', ',', 'cybersecurity', 'professionals', 'must', 'stay', 'ahead', 'of', 'hackers', 'and', 'malware', ',', 'working', 'to', 'anticipate', 'vulnerabilities', 'and', 'mitigate', 'risks', '.']\n",
      "['In', 'an', 'era', 'where', 'data', 'breaches', 'and', 'cyberattacks', 'are', 'becoming', 'more', 'frequent', 'and', 'sophisticated', ',', 'investing', 'in', 'robust', 'cybersecurity', 'measures', 'is', 'essential', 'to', 'safeguarding', 'privacy', 'and', 'maintaining', 'trust', 'in', 'the', 'digital', 'world', '.']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for sentence in docs:\n",
    "    print(word_tokenize(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8f681cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import wordpunct_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "300fd94c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Cybersecurity',\n",
       " 'is',\n",
       " 'the',\n",
       " 'practice',\n",
       " 'of',\n",
       " 'protecting',\n",
       " 'digital',\n",
       " 'systems',\n",
       " ',',\n",
       " 'networks',\n",
       " ',',\n",
       " 'and',\n",
       " 'sensitive',\n",
       " 'information',\n",
       " 'from',\n",
       " 'unauthorized',\n",
       " 'access',\n",
       " ',',\n",
       " 'theft',\n",
       " ',',\n",
       " 'damage',\n",
       " ',',\n",
       " 'or',\n",
       " 'disruption',\n",
       " '.',\n",
       " 'With',\n",
       " 'the',\n",
       " 'rapid',\n",
       " 'growth',\n",
       " 'of',\n",
       " 'the',\n",
       " 'internet',\n",
       " 'and',\n",
       " 'the',\n",
       " 'increasing',\n",
       " 'reliance',\n",
       " 'on',\n",
       " 'digital',\n",
       " 'technologies',\n",
       " ',',\n",
       " 'cybersecurity',\n",
       " 'has',\n",
       " 'become',\n",
       " 'a',\n",
       " 'critical',\n",
       " 'concern',\n",
       " 'for',\n",
       " 'businesses',\n",
       " ',',\n",
       " 'governments',\n",
       " ',',\n",
       " 'and',\n",
       " 'individuals',\n",
       " 'alike',\n",
       " '.',\n",
       " 'It',\n",
       " 'involves',\n",
       " 'a',\n",
       " 'combination',\n",
       " 'of',\n",
       " 'strategies',\n",
       " ',',\n",
       " 'tools',\n",
       " ',',\n",
       " 'and',\n",
       " 'best',\n",
       " 'practices',\n",
       " 'designed',\n",
       " 'to',\n",
       " 'secure',\n",
       " 'software',\n",
       " ',',\n",
       " 'hardware',\n",
       " ',',\n",
       " 'and',\n",
       " 'data',\n",
       " '.',\n",
       " 'These',\n",
       " 'include',\n",
       " 'encryption',\n",
       " ',',\n",
       " 'firewalls',\n",
       " ',',\n",
       " 'multi',\n",
       " '-',\n",
       " 'factor',\n",
       " 'authentication',\n",
       " ',',\n",
       " 'and',\n",
       " 'regular',\n",
       " 'security',\n",
       " 'audits',\n",
       " '.',\n",
       " 'As',\n",
       " 'cyber',\n",
       " 'threats',\n",
       " 'evolve',\n",
       " ',',\n",
       " 'cybersecurity',\n",
       " 'professionals',\n",
       " 'must',\n",
       " 'stay',\n",
       " 'ahead',\n",
       " 'of',\n",
       " 'hackers',\n",
       " 'and',\n",
       " 'malware',\n",
       " ',',\n",
       " 'working',\n",
       " 'to',\n",
       " 'anticipate',\n",
       " 'vulnerabilities',\n",
       " 'and',\n",
       " 'mitigate',\n",
       " 'risks',\n",
       " '.',\n",
       " 'In',\n",
       " 'an',\n",
       " 'era',\n",
       " 'where',\n",
       " 'data',\n",
       " 'breaches',\n",
       " 'and',\n",
       " 'cyberattacks',\n",
       " 'are',\n",
       " 'becoming',\n",
       " 'more',\n",
       " 'frequent',\n",
       " 'and',\n",
       " 'sophisticated',\n",
       " ',',\n",
       " 'investing',\n",
       " 'in',\n",
       " 'robust',\n",
       " 'cybersecurity',\n",
       " 'measures',\n",
       " 'is',\n",
       " 'essential',\n",
       " 'to',\n",
       " 'safeguarding',\n",
       " 'privacy',\n",
       " 'and',\n",
       " 'maintaining',\n",
       " 'trust',\n",
       " 'in',\n",
       " 'the',\n",
       " 'digital',\n",
       " 'world',\n",
       " '.']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordpunct_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "509956b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import TreebankWordTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90e2bbeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Cybersecurity',\n",
       " 'is',\n",
       " 'the',\n",
       " 'practice',\n",
       " 'of',\n",
       " 'protecting',\n",
       " 'digital',\n",
       " 'systems',\n",
       " ',',\n",
       " 'networks',\n",
       " ',',\n",
       " 'and',\n",
       " 'sensitive',\n",
       " 'information',\n",
       " 'from',\n",
       " 'unauthorized',\n",
       " 'access',\n",
       " ',',\n",
       " 'theft',\n",
       " ',',\n",
       " 'damage',\n",
       " ',',\n",
       " 'or',\n",
       " 'disruption.',\n",
       " 'With',\n",
       " 'the',\n",
       " 'rapid',\n",
       " 'growth',\n",
       " 'of',\n",
       " 'the',\n",
       " 'internet',\n",
       " 'and',\n",
       " 'the',\n",
       " 'increasing',\n",
       " 'reliance',\n",
       " 'on',\n",
       " 'digital',\n",
       " 'technologies',\n",
       " ',',\n",
       " 'cybersecurity',\n",
       " 'has',\n",
       " 'become',\n",
       " 'a',\n",
       " 'critical',\n",
       " 'concern',\n",
       " 'for',\n",
       " 'businesses',\n",
       " ',',\n",
       " 'governments',\n",
       " ',',\n",
       " 'and',\n",
       " 'individuals',\n",
       " 'alike.',\n",
       " 'It',\n",
       " 'involves',\n",
       " 'a',\n",
       " 'combination',\n",
       " 'of',\n",
       " 'strategies',\n",
       " ',',\n",
       " 'tools',\n",
       " ',',\n",
       " 'and',\n",
       " 'best',\n",
       " 'practices',\n",
       " 'designed',\n",
       " 'to',\n",
       " 'secure',\n",
       " 'software',\n",
       " ',',\n",
       " 'hardware',\n",
       " ',',\n",
       " 'and',\n",
       " 'data.',\n",
       " 'These',\n",
       " 'include',\n",
       " 'encryption',\n",
       " ',',\n",
       " 'firewalls',\n",
       " ',',\n",
       " 'multi-factor',\n",
       " 'authentication',\n",
       " ',',\n",
       " 'and',\n",
       " 'regular',\n",
       " 'security',\n",
       " 'audits.',\n",
       " 'As',\n",
       " 'cyber',\n",
       " 'threats',\n",
       " 'evolve',\n",
       " ',',\n",
       " 'cybersecurity',\n",
       " 'professionals',\n",
       " 'must',\n",
       " 'stay',\n",
       " 'ahead',\n",
       " 'of',\n",
       " 'hackers',\n",
       " 'and',\n",
       " 'malware',\n",
       " ',',\n",
       " 'working',\n",
       " 'to',\n",
       " 'anticipate',\n",
       " 'vulnerabilities',\n",
       " 'and',\n",
       " 'mitigate',\n",
       " 'risks.',\n",
       " 'In',\n",
       " 'an',\n",
       " 'era',\n",
       " 'where',\n",
       " 'data',\n",
       " 'breaches',\n",
       " 'and',\n",
       " 'cyberattacks',\n",
       " 'are',\n",
       " 'becoming',\n",
       " 'more',\n",
       " 'frequent',\n",
       " 'and',\n",
       " 'sophisticated',\n",
       " ',',\n",
       " 'investing',\n",
       " 'in',\n",
       " 'robust',\n",
       " 'cybersecurity',\n",
       " 'measures',\n",
       " 'is',\n",
       " 'essential',\n",
       " 'to',\n",
       " 'safeguarding',\n",
       " 'privacy',\n",
       " 'and',\n",
       " 'maintaining',\n",
       " 'trust',\n",
       " 'in',\n",
       " 'the',\n",
       " 'digital',\n",
       " 'world',\n",
       " '.']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t=TreebankWordTokenizer() # (.) in paras is trated as part of words\n",
    "t.tokenize(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b463dbc6",
   "metadata": {},
   "source": [
    "<Br><Br><Br><Br><Br><Br>\n",
    "\n",
    "# Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f10781bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [\n",
    "    \"running\", \"ran\", \"runs\", \n",
    "    \"playing\", \"played\", \"plays\", \n",
    "    \"dancing\", \"danced\", \"dances\", \n",
    "    \"writing\", \"wrote\", \"written\", \"writes\", \n",
    "    \"jumping\", \"jumped\", \"jumps\", \n",
    "    \"studying\", \"studied\", \"studies\", \n",
    "    \"cooking\", \"cooked\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9234ad12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prter Stemmer\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "s1=PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0489a285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running => run\n",
      "ran => ran\n",
      "runs => run\n",
      "playing => play\n",
      "played => play\n",
      "plays => play\n",
      "dancing => danc\n",
      "danced => danc\n",
      "dances => danc\n",
      "writing => write\n",
      "wrote => wrote\n",
      "written => written\n",
      "writes => write\n",
      "jumping => jump\n",
      "jumped => jump\n",
      "jumps => jump\n",
      "studying => studi\n",
      "studied => studi\n",
      "studies => studi\n",
      "cooking => cook\n",
      "cooked => cook\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word,'=>',s1.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bf78ef02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regex Stemmer Class\n",
    "\n",
    "from nltk.stem import RegexpStemmer\n",
    "s2=RegexpStemmer('ing$|s$|e$|able$', min=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9ae919a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running => runn\n",
      "ran => ran\n",
      "runs => run\n",
      "playing => play\n",
      "played => played\n",
      "plays => play\n",
      "dancing => danc\n",
      "danced => danced\n",
      "dances => dance\n",
      "writing => writ\n",
      "wrote => wrot\n",
      "written => written\n",
      "writes => write\n",
      "jumping => jump\n",
      "jumped => jumped\n",
      "jumps => jump\n",
      "studying => study\n",
      "studied => studied\n",
      "studies => studie\n",
      "cooking => cook\n",
      "cooked => cooked\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word,'=>',s2.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "75cfb540",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Snowball stemmer\n",
    "\n",
    "from nltk.stem import SnowballStemmer\n",
    "s3=SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f9c5f6d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running => run , runn , run\n",
      "ran => ran , ran , ran\n",
      "runs => run , run , run\n",
      "playing => play , play , play\n",
      "played => play , played , play\n",
      "plays => play , play , play\n",
      "dancing => danc , danc , danc\n",
      "danced => danc , danced , danc\n",
      "dances => danc , dance , danc\n",
      "writing => write , writ , write\n",
      "wrote => wrote , wrot , wrote\n",
      "written => written , written , written\n",
      "writes => write , write , write\n",
      "jumping => jump , jump , jump\n",
      "jumped => jump , jumped , jump\n",
      "jumps => jump , jump , jump\n",
      "studying => studi , study , studi\n",
      "studied => studi , studied , studi\n",
      "studies => studi , studie , studi\n",
      "cooking => cook , cook , cook\n",
      "cooked => cook , cooked , cook\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word,'=>',s3.stem(word),',',s2.stem(word),',',s1.stem(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c735fb7",
   "metadata": {},
   "source": [
    "<Br><Br><Br><Br><Br><Br>\n",
    "\n",
    "# Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9884239c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wordnet Lemmatizer (POS tag for noun, pronoun, adverb etc.)\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "l=WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ef53daa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running => running\n",
      "ran => ran\n",
      "runs => run\n",
      "playing => playing\n",
      "played => played\n",
      "plays => play\n",
      "dancing => dancing\n",
      "danced => danced\n",
      "dances => dance\n",
      "writing => writing\n",
      "wrote => wrote\n",
      "written => written\n",
      "writes => writes\n",
      "jumping => jumping\n",
      "jumped => jumped\n",
      "jumps => jump\n",
      "studying => studying\n",
      "studied => studied\n",
      "studies => study\n",
      "cooking => cooking\n",
      "cooked => cooked\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word,'=>',l.lemmatize(word)) # Noun based lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "93d19f1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running => run\n",
      "ran => run\n",
      "runs => run\n",
      "playing => play\n",
      "played => play\n",
      "plays => play\n",
      "dancing => dance\n",
      "danced => dance\n",
      "dances => dance\n",
      "writing => write\n",
      "wrote => write\n",
      "written => write\n",
      "writes => write\n",
      "jumping => jump\n",
      "jumped => jump\n",
      "jumps => jump\n",
      "studying => study\n",
      "studied => study\n",
      "studies => study\n",
      "cooking => cook\n",
      "cooked => cook\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word,'=>',l.lemmatize(word,pos='v')) #Verb based lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f8e92b",
   "metadata": {},
   "source": [
    "<Br><Br><Br><Br><Br><Br>\n",
    "\n",
    "# Stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f19e9040",
   "metadata": {},
   "outputs": [],
   "source": [
    "review=\"\"\"\n",
    "I recently tried the pizza from Dominoz, and I must say, it was an incredible experience. The crust was perfectly crispy on the outside while soft and chewy on the \n",
    "inside—just the way I love it. I went for the classic Margherita, and the balance of fresh mozzarella, tangy tomato sauce, and fragrant basil was spot on. The flavors \n",
    "blended harmoniously, and each bite was a burst of freshness. What really stood out was the sauce. It wasn’t overly sweet or acidic, which often happens with some pizzas. \n",
    "Instead, it had a rich, savory depth that complemented the toppings perfectly. The cheese was generous without being overwhelming, and it melted beautifully into every slice.\n",
    "Another highlight was the fast delivery time; my pizza arrived piping hot, which made the whole experience even better. The staff was friendly and the packaging ensured \n",
    "that the pizza stayed in great condition all the way home. I also loved the extra touches, like the option to customize your toppings, and they really didn’t skimp on \n",
    "ingredients. If you’re craving a great pizza, this place is definitely worth checking out!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "060e333c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d8c6934f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " \"he'd\",\n",
       " \"he'll\",\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " \"he's\",\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " \"i'd\",\n",
       " 'if',\n",
       " \"i'll\",\n",
       " \"i'm\",\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it'd\",\n",
       " \"it'll\",\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " \"i've\",\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she'd\",\n",
       " \"she'll\",\n",
       " \"she's\",\n",
       " 'should',\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " \"should've\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " \"they'd\",\n",
       " \"they'll\",\n",
       " \"they're\",\n",
       " \"they've\",\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " \"we'd\",\n",
       " \"we'll\",\n",
       " \"we're\",\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " \"we've\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " 'your',\n",
       " \"you're\",\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " \"you've\"]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6bbdd385",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer=PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "13fc26bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences=nltk.sent_tokenize(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "384b6f01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['recent tri pizza dominoz , must say , incred experi .',\n",
       " 'crust perfectli crispi outsid soft chewi inside—just way love .',\n",
       " 'went classic margherita , balanc fresh mozzarella , tangi tomato sauc , fragrant basil spot .',\n",
       " 'flavor blend harmoni , bite burst fresh .',\n",
       " 'realli stood sauc .',\n",
       " '’ overli sweet acid , often happen pizza .',\n",
       " 'instead , rich , savori depth complement top perfectli .',\n",
       " 'chees gener without overwhelm , melt beauti everi slice .',\n",
       " 'anoth highlight fast deliveri time ; pizza arriv pipe hot , made whole experi even better .',\n",
       " 'staff friendli packag ensur pizza stay great condit way home .',\n",
       " 'also love extra touch , like option custom top , realli ’ skimp ingredi .',\n",
       " '’ crave great pizza , place definit worth check !']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results=[]\n",
    "for sentence in sentences:\n",
    "    processedSentence=[]\n",
    "    words=nltk.word_tokenize(sentence)\n",
    "    for word in words:\n",
    "        if word.lower() not in stopwords.words('english'):\n",
    "            processedSentence.append(stemmer.stem(word))\n",
    "    results.append(' '.join(processedSentence))\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8797796b",
   "metadata": {},
   "source": [
    "<Br><Br><Br><Br><Br><Br>\n",
    "\n",
    "# POS Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4728b3e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\nI recently tried the pizza from Dominoz, and I must say, it was an incredible experience.',\n",
       " 'The crust was perfectly crispy on the outside while soft and chewy on the \\ninside—just the way I love it.',\n",
       " 'I went for the classic Margherita, and the balance of fresh mozzarella, tangy tomato sauce, and fragrant basil was spot on.',\n",
       " 'The flavors \\nblended harmoniously, and each bite was a burst of freshness.',\n",
       " 'What really stood out was the sauce.',\n",
       " 'It wasn’t overly sweet or acidic, which often happens with some pizzas.',\n",
       " 'Instead, it had a rich, savory depth that complemented the toppings perfectly.',\n",
       " 'The cheese was generous without being overwhelming, and it melted beautifully into every slice.',\n",
       " 'Another highlight was the fast delivery time; my pizza arrived piping hot, which made the whole experience even better.',\n",
       " 'The staff was friendly and the packaging ensured \\nthat the pizza stayed in great condition all the way home.',\n",
       " 'I also loved the extra touches, like the option to customize your toppings, and they really didn’t skimp on \\ningredients.',\n",
       " 'If you’re craving a great pizza, this place is definitely worth checking out!']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences=nltk.sent_tokenize(review)\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8314f57a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('recent', 'JJ'), ('tri', 'NN'), ('pizza', 'NN'), ('dominoz', 'NN'), (',', ','), ('must', 'MD'), ('say', 'VB'), (',', ','), ('incred', 'JJ'), ('experi', 'NN'), ('.', '.')]\n",
      "[('crust', 'NN'), ('perfectli', 'NN'), ('crispi', 'NN'), ('outsid', 'NN'), ('soft', 'JJ'), ('chewi', 'NN'), ('inside—just', 'JJ'), ('way', 'NN'), ('love', 'NN'), ('.', '.')]\n",
      "[('went', 'VBD'), ('classic', 'JJ'), ('margherita', 'NN'), (',', ','), ('balanc', 'NN'), ('fresh', 'JJ'), ('mozzarella', 'NN'), (',', ','), ('tangi', 'EX'), ('tomato', 'NN'), ('sauc', 'NN'), (',', ','), ('fragrant', 'JJ'), ('basil', 'NN'), ('spot', 'NN'), ('.', '.')]\n",
      "[('flavor', 'NN'), ('blend', 'NN'), ('harmoni', 'NN'), (',', ','), ('bite', 'JJ'), ('burst', 'NN'), ('fresh', 'NN'), ('.', '.')]\n",
      "[('realli', 'NN'), ('stood', 'VBD'), ('sauc', 'NN'), ('.', '.')]\n",
      "[('’', 'JJ'), ('overli', 'JJ'), ('sweet', 'JJ'), ('acid', 'NN'), (',', ','), ('often', 'RB'), ('happen', 'JJ'), ('pizza', 'NN'), ('.', '.')]\n",
      "[('instead', 'RB'), (',', ','), ('rich', 'JJ'), (',', ','), ('savori', 'JJ'), ('depth', 'JJ'), ('complement', 'NN'), ('top', 'JJ'), ('perfectli', 'NN'), ('.', '.')]\n",
      "[('chees', 'NNS'), ('gener', 'VBP'), ('without', 'IN'), ('overwhelm', 'NN'), (',', ','), ('melt', 'VBD'), ('beauti', 'JJ'), ('everi', 'JJ'), ('slice', 'NN'), ('.', '.')]\n",
      "[('anoth', 'DT'), ('highlight', 'VBD'), ('fast', 'RB'), ('deliveri', 'JJ'), ('time', 'NN'), (';', ':'), ('pizza', 'CC'), ('arriv', 'VB'), ('pipe', 'NN'), ('hot', 'JJ'), (',', ','), ('made', 'VBN'), ('whole', 'JJ'), ('experi', 'NN'), ('even', 'RB'), ('better', 'RBR'), ('.', '.')]\n",
      "[('staff', 'NN'), ('friendli', 'NN'), ('packag', 'NN'), ('ensur', 'NN'), ('pizza', 'NN'), ('stay', 'NN'), ('great', 'JJ'), ('condit', 'NN'), ('way', 'NN'), ('home', 'NN'), ('.', '.')]\n",
      "[('also', 'RB'), ('love', 'VBP'), ('extra', 'JJ'), ('touch', 'NN'), (',', ','), ('like', 'IN'), ('option', 'NN'), ('custom', 'NN'), ('top', 'NN'), (',', ','), ('realli', 'VB'), ('’', 'NNP'), ('skimp', 'NN'), ('ingredi', 'NN'), ('.', '.')]\n",
      "[('’', 'NNS'), ('crave', 'VBP'), ('great', 'JJ'), ('pizza', 'NN'), (',', ','), ('place', 'NN'), ('definit', 'NN'), ('worth', 'JJ'), ('check', 'NN'), ('!', '.')]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for sentence in sentences:\n",
    "    processedSentence=[]\n",
    "    words=nltk.word_tokenize(sentence)\n",
    "    for word in words:\n",
    "        if word.lower() not in stopwords.words('english'):\n",
    "            processedSentence.append(stemmer.stem(word))\n",
    "    print(nltk.pos_tag(processedSentence))\n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16159dd",
   "metadata": {},
   "source": [
    "<Br><Br><Br><Br><Br><Br>\n",
    "\n",
    "# Named Entity Regognition/tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c04e628c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nI recently tried the pizza from Dominoz, and I must say, it was an incredible experience. The crust was perfectly crispy on the outside while soft and chewy on the \\ninside—just the way I love it. I went for the classic Margherita, and the balance of fresh mozzarella, tangy tomato sauce, and fragrant basil was spot on. The flavors \\nblended harmoniously, and each bite was a burst of freshness. What really stood out was the sauce. It wasn’t overly sweet or acidic, which often happens with some pizzas. \\nInstead, it had a rich, savory depth that complemented the toppings perfectly. The cheese was generous without being overwhelming, and it melted beautifully into every slice.\\nAnother highlight was the fast delivery time; my pizza arrived piping hot, which made the whole experience even better. The staff was friendly and the packaging ensured \\nthat the pizza stayed in great condition all the way home. I also loved the extra touches, like the option to customize your toppings, and they really didn’t skimp on \\ningredients. If you’re craving a great pizza, this place is definitely worth checking out!\\n'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7a1d1b61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I',\n",
       " 'recently',\n",
       " 'tried',\n",
       " 'the',\n",
       " 'pizza',\n",
       " 'from',\n",
       " 'Dominoz',\n",
       " ',',\n",
       " 'and',\n",
       " 'I',\n",
       " 'must',\n",
       " 'say',\n",
       " ',',\n",
       " 'it',\n",
       " 'was',\n",
       " 'an',\n",
       " 'incredible',\n",
       " 'experience',\n",
       " '.',\n",
       " 'The',\n",
       " 'crust',\n",
       " 'was',\n",
       " 'perfectly',\n",
       " 'crispy',\n",
       " 'on',\n",
       " 'the',\n",
       " 'outside',\n",
       " 'while',\n",
       " 'soft',\n",
       " 'and',\n",
       " 'chewy',\n",
       " 'on',\n",
       " 'the',\n",
       " 'inside—just',\n",
       " 'the',\n",
       " 'way',\n",
       " 'I',\n",
       " 'love',\n",
       " 'it',\n",
       " '.',\n",
       " 'I',\n",
       " 'went',\n",
       " 'for',\n",
       " 'the',\n",
       " 'classic',\n",
       " 'Margherita',\n",
       " ',',\n",
       " 'and',\n",
       " 'the',\n",
       " 'balance',\n",
       " 'of',\n",
       " 'fresh',\n",
       " 'mozzarella',\n",
       " ',',\n",
       " 'tangy',\n",
       " 'tomato',\n",
       " 'sauce',\n",
       " ',',\n",
       " 'and',\n",
       " 'fragrant',\n",
       " 'basil',\n",
       " 'was',\n",
       " 'spot',\n",
       " 'on',\n",
       " '.',\n",
       " 'The',\n",
       " 'flavors',\n",
       " 'blended',\n",
       " 'harmoniously',\n",
       " ',',\n",
       " 'and',\n",
       " 'each',\n",
       " 'bite',\n",
       " 'was',\n",
       " 'a',\n",
       " 'burst',\n",
       " 'of',\n",
       " 'freshness',\n",
       " '.',\n",
       " 'What',\n",
       " 'really',\n",
       " 'stood',\n",
       " 'out',\n",
       " 'was',\n",
       " 'the',\n",
       " 'sauce',\n",
       " '.',\n",
       " 'It',\n",
       " 'wasn',\n",
       " '’',\n",
       " 't',\n",
       " 'overly',\n",
       " 'sweet',\n",
       " 'or',\n",
       " 'acidic',\n",
       " ',',\n",
       " 'which',\n",
       " 'often',\n",
       " 'happens',\n",
       " 'with',\n",
       " 'some',\n",
       " 'pizzas',\n",
       " '.',\n",
       " 'Instead',\n",
       " ',',\n",
       " 'it',\n",
       " 'had',\n",
       " 'a',\n",
       " 'rich',\n",
       " ',',\n",
       " 'savory',\n",
       " 'depth',\n",
       " 'that',\n",
       " 'complemented',\n",
       " 'the',\n",
       " 'toppings',\n",
       " 'perfectly',\n",
       " '.',\n",
       " 'The',\n",
       " 'cheese',\n",
       " 'was',\n",
       " 'generous',\n",
       " 'without',\n",
       " 'being',\n",
       " 'overwhelming',\n",
       " ',',\n",
       " 'and',\n",
       " 'it',\n",
       " 'melted',\n",
       " 'beautifully',\n",
       " 'into',\n",
       " 'every',\n",
       " 'slice',\n",
       " '.',\n",
       " 'Another',\n",
       " 'highlight',\n",
       " 'was',\n",
       " 'the',\n",
       " 'fast',\n",
       " 'delivery',\n",
       " 'time',\n",
       " ';',\n",
       " 'my',\n",
       " 'pizza',\n",
       " 'arrived',\n",
       " 'piping',\n",
       " 'hot',\n",
       " ',',\n",
       " 'which',\n",
       " 'made',\n",
       " 'the',\n",
       " 'whole',\n",
       " 'experience',\n",
       " 'even',\n",
       " 'better',\n",
       " '.',\n",
       " 'The',\n",
       " 'staff',\n",
       " 'was',\n",
       " 'friendly',\n",
       " 'and',\n",
       " 'the',\n",
       " 'packaging',\n",
       " 'ensured',\n",
       " 'that',\n",
       " 'the',\n",
       " 'pizza',\n",
       " 'stayed',\n",
       " 'in',\n",
       " 'great',\n",
       " 'condition',\n",
       " 'all',\n",
       " 'the',\n",
       " 'way',\n",
       " 'home',\n",
       " '.',\n",
       " 'I',\n",
       " 'also',\n",
       " 'loved',\n",
       " 'the',\n",
       " 'extra',\n",
       " 'touches',\n",
       " ',',\n",
       " 'like',\n",
       " 'the',\n",
       " 'option',\n",
       " 'to',\n",
       " 'customize',\n",
       " 'your',\n",
       " 'toppings',\n",
       " ',',\n",
       " 'and',\n",
       " 'they',\n",
       " 'really',\n",
       " 'didn',\n",
       " '’',\n",
       " 't',\n",
       " 'skimp',\n",
       " 'on',\n",
       " 'ingredients',\n",
       " '.',\n",
       " 'If',\n",
       " 'you',\n",
       " '’',\n",
       " 're',\n",
       " 'craving',\n",
       " 'a',\n",
       " 'great',\n",
       " 'pizza',\n",
       " ',',\n",
       " 'this',\n",
       " 'place',\n",
       " 'is',\n",
       " 'definitely',\n",
       " 'worth',\n",
       " 'checking',\n",
       " 'out',\n",
       " '!']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_words=nltk.word_tokenize(review)\n",
    "review_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6a57b9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "nltk.ne_chunk(nltk.pos_tag(review_words)).draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1834562",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4bff00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019bf94f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b51eb13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9a2f09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e69a2ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
